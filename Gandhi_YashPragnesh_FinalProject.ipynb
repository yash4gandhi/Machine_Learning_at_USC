{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import preprocessing\n",
    "import keras\n",
    "from tensorflow.keras.layers import Embedding,Dense, Dropout, LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1. Text Classification\n",
    "It is highly recommended that you complete this project using Keras1 and Python.\n",
    "<br><br>(a) In this problem, we are trying to build a classifier to analyze the sentiment of\n",
    "reviews. You are provided with text data in two folders: one folder involves\n",
    "positive reviews, and one folder involves negative reviews.\n",
    "(<br><br>b) Data Exploration and Pre-processing\n",
    "<br>i. You can use binary encoding for the sentiments , i.e y = 1 for positive sentiments and y = âˆ’1 for negative sentiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '../data/pos'\n",
    "rev = [] \n",
    "sent = []\n",
    "for filename in os.listdir(directory):\n",
    "    f = os.path.join(directory, filename)\n",
    "    if os.path.isfile(f):\n",
    "#         print(f)\n",
    "        with open(f) as fp:\n",
    "            v = fp.read()\n",
    "        rev.append(v)\n",
    "        sent.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '../data/neg'\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    f = os.path.join(directory, filename)\n",
    "    if os.path.isfile(f):\n",
    "#         print(f)\n",
    "        with open(f) as fp:\n",
    "            v = fp.read()\n",
    "        rev.append(v)\n",
    "        sent.append(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'reviews' : rev, 'sentiment' : sent}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(d, columns=['reviews','sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>ii. The data are pretty clean. Remove the punctuation and numbers from the\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reviews'] = df['reviews'].str.replace(r'[^\\w\\s]+', '')\n",
    "df['reviews'] = df['reviews'].str.replace('\\d+', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>iii. The name of each text file starts with cv number. Use text files 0-699 in each\n",
    "class for training and 700-999 for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = df.iloc[:700]\n",
    "train2 = df.iloc[1000:1700]\n",
    "test1 = df.iloc[700:1000]\n",
    "test2 = df.iloc[1700:2000]\n",
    "train = pd.concat([train1,train2])\n",
    "test = pd.concat([test1,test2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test:  (600, 2)\n",
      "train:  (1400, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"test: \",test.shape)\n",
    "print(\"train: \",train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>iv. Count the number of unique words in the whole dataset (train + test) and\n",
    "print it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "t  = Tokenizer()\n",
    "t.fit_on_texts(df['reviews'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Unique word count : 46737\n"
     ]
    }
   ],
   "source": [
    "wordcount = t.word_counts\n",
    "print('Total Unique word count :',len(wordcount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'was': 1495,\n",
       "             'starters': 8,\n",
       "             'dark': 212,\n",
       "             'richardson': 20,\n",
       "             'thats': 553,\n",
       "             'whores': 2,\n",
       "             'filthy': 4,\n",
       "             'goulds': 3,\n",
       "             'roles': 243,\n",
       "             'dreamy': 8,\n",
       "             'copious': 6,\n",
       "             'like': 1470,\n",
       "             'her': 1112,\n",
       "             'completely': 353,\n",
       "             'song': 97,\n",
       "             'includes': 100,\n",
       "             'she': 890,\n",
       "             'find': 577,\n",
       "             'campbell': 45,\n",
       "             'crack': 35,\n",
       "             'attempt': 226,\n",
       "             'case': 314,\n",
       "             'though': 636,\n",
       "             'original': 421,\n",
       "             'for': 1922,\n",
       "             'crazy': 72,\n",
       "             'big': 611,\n",
       "             'chooses': 37,\n",
       "             'language': 102,\n",
       "             'look': 605,\n",
       "             'blindly': 5,\n",
       "             'print': 23,\n",
       "             'whistling': 1,\n",
       "             'will': 1070,\n",
       "             'half': 295,\n",
       "             'violent': 114,\n",
       "             'where': 914,\n",
       "             'scenes': 770,\n",
       "             'all': 1587,\n",
       "             'accent': 86,\n",
       "             'investigate': 45,\n",
       "             'mysterious': 109,\n",
       "             'dont': 789,\n",
       "             'could': 872,\n",
       "             'peaks': 11,\n",
       "             'really': 868,\n",
       "             'starting': 56,\n",
       "             'carwho': 1,\n",
       "             'slay': 2,\n",
       "             'hidden': 68,\n",
       "             'dalmatians': 8,\n",
       "             'whether': 193,\n",
       "             'british': 103,\n",
       "             'precision': 11,\n",
       "             'brought': 140,\n",
       "             'society': 113,\n",
       "             'albert': 30,\n",
       "             'another': 789,\n",
       "             'see': 968,\n",
       "             'steve': 113,\n",
       "             'named': 288,\n",
       "             'guttenberg': 4,\n",
       "             'cant': 497,\n",
       "             'jews': 16,\n",
       "             'blame': 78,\n",
       "             'good': 1151,\n",
       "             'performance': 593,\n",
       "             'carrot': 7,\n",
       "             'creepy': 77,\n",
       "             'footnotes': 2,\n",
       "             'through': 816,\n",
       "             'make': 1003,\n",
       "             'its': 1662,\n",
       "             'reasons': 119,\n",
       "             'whole': 391,\n",
       "             'ghost': 34,\n",
       "             'remind': 28,\n",
       "             'well': 1005,\n",
       "             'blow': 48,\n",
       "             'deming': 1,\n",
       "             'carving': 5,\n",
       "             'have': 1631,\n",
       "             'is': 1995,\n",
       "             'godley': 1,\n",
       "             'horribly': 42,\n",
       "             'cloaking': 1,\n",
       "             'marilyn': 14,\n",
       "             'he': 1630,\n",
       "             'set': 446,\n",
       "             'been': 1086,\n",
       "             'vertical': 4,\n",
       "             'rafael': 5,\n",
       "             'identity': 70,\n",
       "             'captures': 35,\n",
       "             'drug': 86,\n",
       "             'toward': 87,\n",
       "             'but': 1899,\n",
       "             'unsuccessfully': 9,\n",
       "             'looks': 363,\n",
       "             'englishman': 4,\n",
       "             'if': 1349,\n",
       "             'much': 1128,\n",
       "             'hayes': 6,\n",
       "             'surprise': 183,\n",
       "             'screenwriters': 69,\n",
       "             'irish': 26,\n",
       "             'word': 185,\n",
       "             'helped': 53,\n",
       "             'little': 916,\n",
       "             'better': 679,\n",
       "             'ably': 10,\n",
       "             'unique': 102,\n",
       "             'r': 133,\n",
       "             'supporting': 246,\n",
       "             'finger': 21,\n",
       "             'absinthe': 2,\n",
       "             'crimes': 29,\n",
       "             'jack': 139,\n",
       "             'you': 1407,\n",
       "             'police': 183,\n",
       "             'no': 1189,\n",
       "             'unfortunate': 60,\n",
       "             'jackson': 57,\n",
       "             'bleak': 46,\n",
       "             'long': 588,\n",
       "             'theyre': 291,\n",
       "             'pales': 5,\n",
       "             'hollow': 36,\n",
       "             'winner': 56,\n",
       "             'book': 206,\n",
       "             'peter': 188,\n",
       "             'it': 1934,\n",
       "             'childs': 18,\n",
       "             'riddle': 1,\n",
       "             'alan': 72,\n",
       "             'series': 315,\n",
       "             'secret': 149,\n",
       "             'a': 1996,\n",
       "             'surroundings': 15,\n",
       "             'success': 187,\n",
       "             'befriends': 25,\n",
       "             'now': 675,\n",
       "             'at': 1718,\n",
       "             'oscar': 150,\n",
       "             'flashbacks': 56,\n",
       "             'abberline': 1,\n",
       "             'even': 1289,\n",
       "             'has': 1606,\n",
       "             'worry': 34,\n",
       "             'stonecutters': 1,\n",
       "             'michael': 272,\n",
       "             'briefed': 1,\n",
       "             'appearance': 113,\n",
       "             'do': 1069,\n",
       "             'production': 239,\n",
       "             'planet': 125,\n",
       "             'great': 695,\n",
       "             'killer': 151,\n",
       "             'point': 492,\n",
       "             'comparison': 64,\n",
       "             'blackandwhite': 8,\n",
       "             'getting': 335,\n",
       "             'stiff': 22,\n",
       "             'graham': 27,\n",
       "             'i': 1524,\n",
       "             'mad': 63,\n",
       "             'menace': 51,\n",
       "             'wont': 237,\n",
       "             'dreariness': 2,\n",
       "             'holm': 13,\n",
       "             'nothing': 589,\n",
       "             'level': 204,\n",
       "             'rables': 2,\n",
       "             'holds': 74,\n",
       "             'nearly': 260,\n",
       "             'psychopath': 13,\n",
       "             'electric': 14,\n",
       "             'as': 1917,\n",
       "             'bother': 45,\n",
       "             'street': 107,\n",
       "             'pages': 21,\n",
       "             'saying': 157,\n",
       "             'world': 571,\n",
       "             'they': 1440,\n",
       "             'the': 1999,\n",
       "             'not': 1672,\n",
       "             'so': 1468,\n",
       "             'time': 1224,\n",
       "             'until': 377,\n",
       "             'direct': 64,\n",
       "             'seems': 686,\n",
       "             'surgeon': 9,\n",
       "             'color': 74,\n",
       "             'allen': 64,\n",
       "             'to': 1997,\n",
       "             'ripper': 2,\n",
       "             'from': 1702,\n",
       "             'thoroughly': 67,\n",
       "             'features': 174,\n",
       "             'are': 1781,\n",
       "             'of': 1998,\n",
       "             'typically': 24,\n",
       "             'be': 1770,\n",
       "             'sooty': 1,\n",
       "             'music': 309,\n",
       "             'burton': 29,\n",
       "             'keeping': 81,\n",
       "             'london': 45,\n",
       "             'and': 1998,\n",
       "             'violence': 214,\n",
       "             'locals': 14,\n",
       "             'part': 525,\n",
       "             'comic': 262,\n",
       "             'crime': 128,\n",
       "             'acts': 66,\n",
       "             'strong': 218,\n",
       "             'kids': 224,\n",
       "             'stomach': 23,\n",
       "             'me': 758,\n",
       "             'consist': 9,\n",
       "             'both': 620,\n",
       "             'think': 585,\n",
       "             'saw': 207,\n",
       "             'shakespeare': 25,\n",
       "             'called': 292,\n",
       "             'isnt': 615,\n",
       "             'made': 729,\n",
       "             'days': 255,\n",
       "             'surprising': 91,\n",
       "             'novel': 174,\n",
       "             'nervous': 34,\n",
       "             'gruesome': 24,\n",
       "             'log': 4,\n",
       "             'source': 57,\n",
       "             'killing': 110,\n",
       "             'content': 70,\n",
       "             'created': 151,\n",
       "             'would': 1113,\n",
       "             'subject': 141,\n",
       "             'martin': 111,\n",
       "             'moore': 51,\n",
       "             'more': 1469,\n",
       "             'watch': 467,\n",
       "             'batman': 72,\n",
       "             'geniuses': 8,\n",
       "             'deftly': 7,\n",
       "             'who': 1726,\n",
       "             'past': 279,\n",
       "             'les': 13,\n",
       "             'amounts': 33,\n",
       "             'thing': 584,\n",
       "             'calls': 94,\n",
       "             'simpsons': 8,\n",
       "             'top': 242,\n",
       "             'terry': 36,\n",
       "             'interesting': 479,\n",
       "             'enough': 665,\n",
       "             'comments': 52,\n",
       "             'quell': 3,\n",
       "             'medium': 21,\n",
       "             'how': 909,\n",
       "             'when': 1449,\n",
       "             'inspector': 28,\n",
       "             'words': 186,\n",
       "             'hells': 4,\n",
       "             'books': 64,\n",
       "             'almost': 586,\n",
       "             'upon': 246,\n",
       "             'other': 1100,\n",
       "             'this': 1895,\n",
       "             'heather': 24,\n",
       "             'onto': 112,\n",
       "             'hughes': 28,\n",
       "             'kelly': 47,\n",
       "             'film': 1725,\n",
       "             'might': 486,\n",
       "             'proceeds': 27,\n",
       "             'or': 1377,\n",
       "             'about': 1460,\n",
       "             'an': 1783,\n",
       "             'sleepy': 16,\n",
       "             'superheroes': 8,\n",
       "             'graphic': 76,\n",
       "             'joe': 121,\n",
       "             'get': 1084,\n",
       "             'ghetto': 15,\n",
       "             'coltrane': 3,\n",
       "             'first': 1019,\n",
       "             'indians': 10,\n",
       "             'itll': 24,\n",
       "             'theory': 35,\n",
       "             'actually': 574,\n",
       "             'block': 38,\n",
       "             'new': 760,\n",
       "             's': 602,\n",
       "             'one': 1741,\n",
       "             'frederick': 6,\n",
       "             'dreams': 95,\n",
       "             'sense': 406,\n",
       "             'profession': 31,\n",
       "             'depp': 20,\n",
       "             'tries': 314,\n",
       "             'yglesias': 2,\n",
       "             'after': 1064,\n",
       "             'mouth': 84,\n",
       "             'say': 586,\n",
       "             'love': 642,\n",
       "             'turning': 77,\n",
       "             'mid': 11,\n",
       "             'cringed': 3,\n",
       "             'crowd': 65,\n",
       "             'victorianera': 1,\n",
       "             'before': 726,\n",
       "             'sexuality': 32,\n",
       "             'copper': 5,\n",
       "             'opium': 2,\n",
       "             'ludicrous': 41,\n",
       "             'spawn': 17,\n",
       "             'ians': 1,\n",
       "             'handling': 24,\n",
       "             'directors': 134,\n",
       "             'him': 1129,\n",
       "             'needs': 197,\n",
       "             'can': 1205,\n",
       "             'place': 471,\n",
       "             'twin': 31,\n",
       "             'casting': 110,\n",
       "             'back': 718,\n",
       "             'films': 1040,\n",
       "             'acting': 529,\n",
       "             'cinematographer': 63,\n",
       "             'anything': 500,\n",
       "             'solid': 155,\n",
       "             'arthouse': 7,\n",
       "             'that': 1957,\n",
       "             'ending': 296,\n",
       "             'casper': 17,\n",
       "             'widower': 7,\n",
       "             'up': 1412,\n",
       "             'mis': 4,\n",
       "             'very': 967,\n",
       "             'hell': 211,\n",
       "             'flashy': 39,\n",
       "             'their': 1294,\n",
       "             'bad': 762,\n",
       "             'imagining': 5,\n",
       "             'surgical': 2,\n",
       "             'star': 401,\n",
       "             'limit': 10,\n",
       "             'tim': 96,\n",
       "             'johnny': 45,\n",
       "             'dismiss': 14,\n",
       "             'theres': 620,\n",
       "             'funny': 502,\n",
       "             'viewers': 166,\n",
       "             'in': 1994,\n",
       "             'prophetic': 5,\n",
       "             'question': 240,\n",
       "             'researched': 1,\n",
       "             'than': 1272,\n",
       "             'however': 653,\n",
       "             'unfortunates': 2,\n",
       "             'over': 865,\n",
       "             'mary': 81,\n",
       "             'londons': 4,\n",
       "             'watchmen': 1,\n",
       "             'adapted': 44,\n",
       "             'here': 751,\n",
       "             'finalized': 2,\n",
       "             'brothers': 134,\n",
       "             'go': 734,\n",
       "             'had': 899,\n",
       "             'opened': 39,\n",
       "             'anyone': 357,\n",
       "             'particulars': 6,\n",
       "             'violencegore': 3,\n",
       "             'job': 413,\n",
       "             'committing': 13,\n",
       "             'ghastly': 9,\n",
       "             'certainly': 294,\n",
       "             'because': 915,\n",
       "             'apes': 18,\n",
       "             'into': 1307,\n",
       "             'superman': 13,\n",
       "             'arriving': 17,\n",
       "             'times': 453,\n",
       "             'east': 24,\n",
       "             'manson': 8,\n",
       "             'capable': 63,\n",
       "             'such': 794,\n",
       "             'never': 849,\n",
       "             'prague': 1,\n",
       "             'behind': 300,\n",
       "             'plenty': 110,\n",
       "             'design': 76,\n",
       "             'did': 530,\n",
       "             'with': 1944,\n",
       "             'on': 1858,\n",
       "             'geared': 13,\n",
       "             'robbie': 15,\n",
       "             'whitechapel': 1,\n",
       "             'end': 738,\n",
       "             'ii': 91,\n",
       "             'finished': 34,\n",
       "             'turns': 337,\n",
       "             'course': 495,\n",
       "             'by': 1776,\n",
       "             'eddie': 69,\n",
       "             'stumbling': 15,\n",
       "             'wasnt': 247,\n",
       "             'odd': 97,\n",
       "             'studios': 50,\n",
       "             'sitcom': 45,\n",
       "             'low': 95,\n",
       "             'stinker': 8,\n",
       "             'lot': 502,\n",
       "             'washington': 41,\n",
       "             'max': 54,\n",
       "             'sting': 8,\n",
       "             'gets': 651,\n",
       "             'why': 582,\n",
       "             'fun': 421,\n",
       "             'hype': 42,\n",
       "             'each': 462,\n",
       "             'formed': 15,\n",
       "             'flick': 161,\n",
       "             'carver': 8,\n",
       "             'few': 697,\n",
       "             'since': 558,\n",
       "             'likely': 148,\n",
       "             'tracy': 11,\n",
       "             'parent': 23,\n",
       "             'character': 1013,\n",
       "             'gymnasium': 2,\n",
       "             'witherspoon': 17,\n",
       "             'fact': 577,\n",
       "             'were': 821,\n",
       "             'way': 1008,\n",
       "             'tensions': 9,\n",
       "             'reviewers': 17,\n",
       "             'suppose': 86,\n",
       "             'directly': 70,\n",
       "             'everybodys': 8,\n",
       "             'then': 856,\n",
       "             'most': 1183,\n",
       "             'hes': 613,\n",
       "             'makes': 721,\n",
       "             'run': 241,\n",
       "             'popularbutslow': 1,\n",
       "             'role': 608,\n",
       "             'hadnt': 37,\n",
       "             'glowing': 17,\n",
       "             'know': 749,\n",
       "             'indication': 11,\n",
       "             'single': 194,\n",
       "             'rushmore': 11,\n",
       "             'plot': 876,\n",
       "             'deserves': 108,\n",
       "             'amount': 118,\n",
       "             'strengths': 16,\n",
       "             'explicitly': 11,\n",
       "             'two': 1025,\n",
       "             'jessica': 23,\n",
       "             'existed': 9,\n",
       "             'extraordinary': 50,\n",
       "             'screenplay': 235,\n",
       "             'yet': 473,\n",
       "             'bueller': 2,\n",
       "             'airy': 6,\n",
       "             'mount': 7,\n",
       "             'should': 644,\n",
       "             'newcomer': 31,\n",
       "             'broderick': 22,\n",
       "             'studio': 103,\n",
       "             'teenagers': 66,\n",
       "             'reason': 360,\n",
       "             'expect': 187,\n",
       "             'potential': 148,\n",
       "             'off': 896,\n",
       "             'high': 343,\n",
       "             'george': 138,\n",
       "             'performances': 369,\n",
       "             'playing': 294,\n",
       "             'mark': 141,\n",
       "             'clubs': 16,\n",
       "             'several': 334,\n",
       "             'many': 788,\n",
       "             'what': 1348,\n",
       "             'throw': 86,\n",
       "             'current': 69,\n",
       "             'ferris': 12,\n",
       "             'number': 181,\n",
       "             'tonal': 1,\n",
       "             'every': 672,\n",
       "             'reese': 23,\n",
       "             'male': 87,\n",
       "             'distract': 17,\n",
       "             'side': 261,\n",
       "             'comes': 581,\n",
       "             'which': 1318,\n",
       "             'released': 169,\n",
       "             'costs': 22,\n",
       "             'early': 247,\n",
       "             'similarities': 22,\n",
       "             'life': 778,\n",
       "             'perhaps': 369,\n",
       "             'starring': 158,\n",
       "             'once': 482,\n",
       "             'payne': 9,\n",
       "             'details': 108,\n",
       "             'm': 64,\n",
       "             'right': 580,\n",
       "             'contributed': 12,\n",
       "             'campbells': 5,\n",
       "             'win': 100,\n",
       "             'going': 625,\n",
       "             'my': 766,\n",
       "             'probably': 424,\n",
       "             'ive': 287,\n",
       "             'murray': 31,\n",
       "             'expectations': 70,\n",
       "             'rooney': 3,\n",
       "             'election': 19,\n",
       "             'movie': 1524,\n",
       "             'overachiever': 2,\n",
       "             'mtv': 36,\n",
       "             'speech': 74,\n",
       "             'caught': 113,\n",
       "             'becomes': 414,\n",
       "             'negative': 38,\n",
       "             'revelation': 34,\n",
       "             'having': 439,\n",
       "             'revenge': 79,\n",
       "             'months': 92,\n",
       "             'less': 351,\n",
       "             'coming': 229,\n",
       "             'hand': 270,\n",
       "             'points': 141,\n",
       "             'disappointing': 81,\n",
       "             'does': 964,\n",
       "             'rely': 33,\n",
       "             'elements': 199,\n",
       "             'logical': 22,\n",
       "             'story': 1062,\n",
       "             'jumps': 41,\n",
       "             'antisocial': 5,\n",
       "             'youre': 268,\n",
       "             'contrast': 59,\n",
       "             'nosedive': 3,\n",
       "             'year': 457,\n",
       "             'determination': 15,\n",
       "             'student': 85,\n",
       "             'nihilistic': 8,\n",
       "             'seen': 636,\n",
       "             'aware': 58,\n",
       "             'there': 1290,\n",
       "             'bee': 7,\n",
       "             'darling': 4,\n",
       "             'involved': 211,\n",
       "             'frankly': 55,\n",
       "             'alexander': 23,\n",
       "             'relationship': 270,\n",
       "             'play': 330,\n",
       "             'any': 956,\n",
       "             'add': 165,\n",
       "             'between': 669,\n",
       "             'fischer': 7,\n",
       "             'home': 400,\n",
       "             'bothering': 7,\n",
       "             'pauls': 6,\n",
       "             'clout': 9,\n",
       "             'example': 262,\n",
       "             'tension': 120,\n",
       "             'bill': 121,\n",
       "             'school': 223,\n",
       "             'personal': 148,\n",
       "             'sexdriven': 2,\n",
       "             'decides': 175,\n",
       "             'encourages': 7,\n",
       "             'genre': 201,\n",
       "             'light': 165,\n",
       "             'mr': 163,\n",
       "             'bumbling': 31,\n",
       "             'race': 87,\n",
       "             'stings': 2,\n",
       "             'tracys': 2,\n",
       "             'matthew': 86,\n",
       "             'sick': 58,\n",
       "             'jock': 17,\n",
       "             'stuff': 177,\n",
       "             'adult': 89,\n",
       "             'takes': 533,\n",
       "             'ruined': 32,\n",
       "             'fully': 81,\n",
       "             'extramarital': 3,\n",
       "             'tammy': 3,\n",
       "             'happened': 147,\n",
       "             'deceptively': 5,\n",
       "             'earlier': 131,\n",
       "             'drive': 80,\n",
       "             'megalomaniac': 6,\n",
       "             'staggering': 12,\n",
       "             'lifted': 22,\n",
       "             'simple': 230,\n",
       "             'pursues': 9,\n",
       "             'baggage': 5,\n",
       "             'raised': 42,\n",
       "             'help': 430,\n",
       "             'week': 70,\n",
       "             'contain': 39,\n",
       "             'elections': 5,\n",
       "             'studentteacher': 1,\n",
       "             'money': 352,\n",
       "             'teacher': 71,\n",
       "             'suspect': 78,\n",
       "             'contains': 105,\n",
       "             'starts': 265,\n",
       "             'different': 342,\n",
       "             'disappointment': 61,\n",
       "             'quality': 163,\n",
       "             'anybody': 37,\n",
       "             'fantastic': 71,\n",
       "             'screws': 11,\n",
       "             'live': 268,\n",
       "             'nomination': 50,\n",
       "             'enthusiastic': 18,\n",
       "             'comedy': 488,\n",
       "             'significant': 47,\n",
       "             'reviews': 73,\n",
       "             'critical': 56,\n",
       "             'doesnt': 824,\n",
       "             'paul': 163,\n",
       "             'tighten': 2,\n",
       "             'president': 64,\n",
       "             'geeks': 4,\n",
       "             'along': 441,\n",
       "             'sleeper': 13,\n",
       "             'his': 1756,\n",
       "             'affair': 75,\n",
       "             'individual': 66,\n",
       "             'sister': 94,\n",
       "             'won': 68,\n",
       "             'havent': 135,\n",
       "             'owner': 74,\n",
       "             'store': 100,\n",
       "             'helmed': 15,\n",
       "             'come': 595,\n",
       "             'adding': 34,\n",
       "             'familyrun': 1,\n",
       "             'fail': 61,\n",
       "             'order': 236,\n",
       "             'bitter': 48,\n",
       "             'same': 632,\n",
       "             'alot': 8,\n",
       "             'out': 1507,\n",
       "             'fox': 62,\n",
       "             'predictable': 157,\n",
       "             'internet': 32,\n",
       "             'attractive': 68,\n",
       "             'true': 306,\n",
       "             'nice': 263,\n",
       "             'scene': 777,\n",
       "             'kelley': 6,\n",
       "             'complete': 178,\n",
       "             'stars': 329,\n",
       "             'hanks': 36,\n",
       "             'entire': 327,\n",
       "             'goes': 520,\n",
       "             'real': 591,\n",
       "             'got': 357,\n",
       "             'discount': 9,\n",
       "             'them': 1038,\n",
       "             'discovers': 103,\n",
       "             'important': 176,\n",
       "             'body': 209,\n",
       "             'again': 505,\n",
       "             'quite': 473,\n",
       "             'mere': 44,\n",
       "             'youve': 153,\n",
       "             'something': 718,\n",
       "             'small': 330,\n",
       "             'left': 364,\n",
       "             'contemporary': 44,\n",
       "             'collect': 18,\n",
       "             'cute': 100,\n",
       "             'extremely': 210,\n",
       "             'previous': 155,\n",
       "             'neither': 150,\n",
       "             'kathleen': 22,\n",
       "             'rivals': 12,\n",
       "             'concepts': 23,\n",
       "             'happiness': 31,\n",
       "             'profits': 6,\n",
       "             'plays': 586,\n",
       "             'filled': 148,\n",
       "             'manipulative': 35,\n",
       "             'insanely': 11,\n",
       "             'ryan': 87,\n",
       "             'joy': 58,\n",
       "             'enjoyable': 148,\n",
       "             'reshoot': 5,\n",
       "             'only': 1305,\n",
       "             'already': 258,\n",
       "             'bone': 27,\n",
       "             'meg': 31,\n",
       "             'defies': 15,\n",
       "             'pure': 82,\n",
       "             'share': 103,\n",
       "             'liked': 137,\n",
       "             'screen': 503,\n",
       "             'figured': 28,\n",
       "             'subplots': 58,\n",
       "             'persons': 28,\n",
       "             'doubt': 154,\n",
       "             'hours': 203,\n",
       "             'online': 11,\n",
       "             'filmmaking': 94,\n",
       "             'inventive': 49,\n",
       "             'corner': 45,\n",
       "             'across': 194,\n",
       "             'twists': 96,\n",
       "             'chain': 41,\n",
       "             'become': 411,\n",
       "             'ryanhanks': 1,\n",
       "             'couldnt': 170,\n",
       "             'rest': 369,\n",
       "             'smiling': 14,\n",
       "             'around': 677,\n",
       "             'likeable': 38,\n",
       "             'cliched': 63,\n",
       "             'tom': 157,\n",
       "             'opening': 247,\n",
       "             'backdrop': 29,\n",
       "             'mildly': 42,\n",
       "             'main': 330,\n",
       "             'teaming': 8,\n",
       "             'childrens': 45,\n",
       "             'sure': 412,\n",
       "             'business': 153,\n",
       "             'theater': 180,\n",
       "             'work': 713,\n",
       "             'evokes': 10,\n",
       "             'woman': 354,\n",
       "             'storyline': 100,\n",
       "             'hated': 35,\n",
       "             'utter': 39,\n",
       "             'foreseeable': 2,\n",
       "             'overly': 59,\n",
       "             'mention': 109,\n",
       "             'shop': 40,\n",
       "             'homage': 48,\n",
       "             'oh': 170,\n",
       "             'cuteness': 10,\n",
       "             'works': 309,\n",
       "             'some': 1364,\n",
       "             'climax': 110,\n",
       "             'basically': 174,\n",
       "             'mushy': 4,\n",
       "             'directing': 105,\n",
       "             'terribly': 53,\n",
       "             'party': 109,\n",
       "             'leads': 209,\n",
       "             'welldone': 10,\n",
       "             'manipulation': 16,\n",
       "             'absolutely': 166,\n",
       "             'proprietor': 6,\n",
       "             'lack': 208,\n",
       "             'sleepless': 8,\n",
       "             'damn': 77,\n",
       "             'soon': 327,\n",
       "             'knows': 242,\n",
       "             'mail': 21,\n",
       "             'modern': 120,\n",
       "             'seattle': 16,\n",
       "             'must': 475,\n",
       "             'popular': 159,\n",
       "             'against': 300,\n",
       "             'sentimental': 38,\n",
       "             'cast': 547,\n",
       "             'essentially': 57,\n",
       "             'serve': 71,\n",
       "             'nicknamed': 11,\n",
       "             'shots': 160,\n",
       "             'leave': 198,\n",
       "             'rolled': 18,\n",
       "             'america': 128,\n",
       "             'complex': 121,\n",
       "             'movies': 818,\n",
       "             'angles': 36,\n",
       "             'warns': 20,\n",
       "             'scars': 8,\n",
       "             'station': 65,\n",
       "             'feel': 370,\n",
       "             'scheider': 2,\n",
       "             'redford': 7,\n",
       "             'we': 1011,\n",
       "             'three': 424,\n",
       "             'shows': 352,\n",
       "             'away': 512,\n",
       "             'fired': 31,\n",
       "             'dethroned': 1,\n",
       "             'primal': 14,\n",
       "             'produced': 109,\n",
       "             'ominous': 26,\n",
       "             'exact': 59,\n",
       "             'horror': 217,\n",
       "             'act': 226,\n",
       "             'shaken': 9,\n",
       "             'just': 1327,\n",
       "             'husband': 151,\n",
       "             'forgotten': 65,\n",
       "             'imagery': 36,\n",
       "             'faced': 40,\n",
       "             'keen': 15,\n",
       "             'ever': 549,\n",
       "             'spielbergs': 22,\n",
       "             'chomped': 1,\n",
       "             'shark': 13,\n",
       "             'nemesis': 22,\n",
       "             'mankinds': 5,\n",
       "             'roy': 12,\n",
       "             'refuses': 56,\n",
       "             'ship': 95,\n",
       "             'institute': 7,\n",
       "             'swarms': 5,\n",
       "             'unprotected': 2,\n",
       "             'digital': 41,\n",
       "             'writihing': 1,\n",
       "             'show': 452,\n",
       "             'middle': 174,\n",
       "             'whats': 201,\n",
       "             'footage': 78,\n",
       "             'decrepit': 4,\n",
       "             'sympathetic': 75,\n",
       "             'marine': 14,\n",
       "             'played': 547,\n",
       "             'beaches': 1,\n",
       "             'truly': 230,\n",
       "             'lets': 180,\n",
       "             'fourth': 35,\n",
       "             'built': 61,\n",
       "             'taking': 202,\n",
       "             'merely': 137,\n",
       "             'search': 96,\n",
       "             'workings': 6,\n",
       "             'duddy': 1,\n",
       "             'machismo': 6,\n",
       "             'theatrical': 44,\n",
       "             'caricature': 20,\n",
       "             'office': 138,\n",
       "             'ahab': 1,\n",
       "             'hitchcocks': 15,\n",
       "             'shaws': 3,\n",
       "             'presence': 165,\n",
       "             'taken': 201,\n",
       "             'precursor': 4,\n",
       "             'stop': 213,\n",
       "             'sinch': 1,\n",
       "             'hunt': 45,\n",
       "             'bored': 77,\n",
       "             'beautiful': 223,\n",
       "             'vicious': 36,\n",
       "             'overcame': 4,\n",
       "             'outstanding': 68,\n",
       "             'ocean': 45,\n",
       "             'sequences': 247,\n",
       "             'mayor': 19,\n",
       "             'deck': 16,\n",
       "             'borders': 18,\n",
       "             'cinematic': 122,\n",
       "             'pacing': 61,\n",
       "             'gave': 130,\n",
       "             'whose': 363,\n",
       "             'finally': 295,\n",
       "             'hits': 84,\n",
       "             'dinosaurs': 13,\n",
       "             'someone': 314,\n",
       "             'box': 124,\n",
       "             'ten': 137,\n",
       "             'limitations': 7,\n",
       "             'mature': 44,\n",
       "             'effects': 347,\n",
       "             'eating': 41,\n",
       "             'including': 285,\n",
       "             'gun': 105,\n",
       "             'finest': 49,\n",
       "             'eyes': 230,\n",
       "             'fascination': 17,\n",
       "             'technology': 58,\n",
       "             'running': 268,\n",
       "             'steven': 97,\n",
       "             'relents': 1,\n",
       "             'bordering': 6,\n",
       "             'bruce': 104,\n",
       "             'crown': 13,\n",
       "             'obstacles': 19,\n",
       "             'resort': 19,\n",
       "             'fascinated': 22,\n",
       "             'refused': 14,\n",
       "             'whites': 14,\n",
       "             'builds': 34,\n",
       "             'brody': 6,\n",
       "             'drawn': 68,\n",
       "             'delivers': 115,\n",
       "             'guaranteed': 19,\n",
       "             'lead': 225,\n",
       "             'graffiti': 4,\n",
       "             'york': 164,\n",
       "             'slightly': 134,\n",
       "             'editing': 92,\n",
       "             'bit': 419,\n",
       "             'teeth': 36,\n",
       "             'gives': 387,\n",
       "             'inevitably': 35,\n",
       "             'shot': 245,\n",
       "             'soggy': 5,\n",
       "             'old': 515,\n",
       "             'amity': 1,\n",
       "             'boat': 54,\n",
       "             'incredible': 88,\n",
       "             'navy': 13,\n",
       "             'epitome': 13,\n",
       "             'restraint': 24,\n",
       "             'audience': 619,\n",
       "             'father': 302,\n",
       "             'simply': 328,\n",
       "             'black': 282,\n",
       "             'hairraising': 3,\n",
       "             'engine': 10,\n",
       "             'overshadowed': 16,\n",
       "             'floating': 24,\n",
       "             'hamilton': 8,\n",
       "             'sorely': 13,\n",
       "             'attacked': 28,\n",
       "             'obsolete': 5,\n",
       "             'instead': 455,\n",
       "             'spielberg': 36,\n",
       "             'characterization': 64,\n",
       "             'vaughn': 10,\n",
       "             'grizzled': 3,\n",
       "             'wonder': 217,\n",
       "             'underwater': 19,\n",
       "             'none': 208,\n",
       "             'waterworld': 9,\n",
       "             'deranged': 15,\n",
       "             'matt': 66,\n",
       "             'hooper': 1,\n",
       "             'water': 131,\n",
       "             'forced': 190,\n",
       "             'grip': 19,\n",
       "             'score': 173,\n",
       "             'building': 96,\n",
       "             'dreyfuss': 8,\n",
       "             'american': 321,\n",
       "             'actual': 125,\n",
       "             'large': 149,\n",
       "             'tale': 182,\n",
       "             'summer': 197,\n",
       "             'crusty': 4,\n",
       "             'storm': 41,\n",
       "             'swim': 12,\n",
       "             'slowly': 115,\n",
       "             'japanese': 45,\n",
       "             'filmmakers': 176,\n",
       "             'your': 553,\n",
       "             'bars': 16,\n",
       "             'williams': 117,\n",
       "             'five': 199,\n",
       "             'humor': 287,\n",
       "             'unceremoniously': 5,\n",
       "             'parody': 60,\n",
       "             'notes': 51,\n",
       "             'hollywood': 365,\n",
       "             'knowledge': 65,\n",
       "             'mechanical': 21,\n",
       "             'chief': 59,\n",
       "             'survived': 18,\n",
       "             'richard': 110,\n",
       "             'telling': 114,\n",
       "             'political': 91,\n",
       "             'nature': 147,\n",
       "             'ready': 100,\n",
       "             'england': 49,\n",
       "             'infamous': 42,\n",
       "             'cop': 109,\n",
       "             'threat': 46,\n",
       "             'relinquishes': 1,\n",
       "             'insatiable': 4,\n",
       "             'overkill': 11,\n",
       "             'suggests': 49,\n",
       "             'larry': 41,\n",
       "             'fictitious': 8,\n",
       "             'previously': 62,\n",
       "             'academy': 83,\n",
       "             'draw': 64,\n",
       "             'nevertheless': 58,\n",
       "             'quagmire': 2,\n",
       "             'deal': 187,\n",
       "             'universal': 37,\n",
       "             'determined': 73,\n",
       "             ...})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.word_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>v. Calculate the average review length and the standard deviation of review\n",
    "lengths. Report the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reviews_word_count'] = df['reviews'].str.split().str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        679\n",
      "1        650\n",
      "2        416\n",
      "3        997\n",
      "4        644\n",
      "        ... \n",
      "1995    1366\n",
      "1996    1009\n",
      "1997     396\n",
      "1998     521\n",
      "1999     503\n",
      "Name: reviews_word_count, Length: 2000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['reviews_word_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Deviation of word_count 285.0513950898525\n"
     ]
    }
   ],
   "source": [
    "print('Standard Deviation of word_count',df['reviews_word_count'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of word_count 644.3575\n"
     ]
    }
   ],
   "source": [
    "print('Average of word_count',df['reviews_word_count'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>vi. Plot the histogram of review lengths.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'reviews_word_count'}>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.hist(column = 'reviews_word_count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>vii. To represent each text (= data point), there are many ways. In NLP/Deep\n",
    "Learning terminology, this task is called tokenization. It is common to represent text using popularity/ rank of words in text. The most common word\n",
    "in the text will be represented as 1, the second most common word will be\n",
    "represented as 2, etc. Tokenize each text document using this method.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = t.texts_to_sequences(df['reviews'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sequence'] = sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>reviews_word_count</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>films adapted from comic books have had plenty...</td>\n",
       "      <td>1</td>\n",
       "      <td>679</td>\n",
       "      <td>[67, 2745, 29, 355, 1634, 32, 90, 1047, 4, 627...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>every now and then a movie comes along from a ...</td>\n",
       "      <td>1</td>\n",
       "      <td>650</td>\n",
       "      <td>[150, 144, 3, 102, 2, 27, 199, 264, 29, 2, 151...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>youve got mail works alot better than it deser...</td>\n",
       "      <td>1</td>\n",
       "      <td>416</td>\n",
       "      <td>[729, 287, 3642, 379, 9979, 153, 58, 9, 1213, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jaws  is a rare film that grabs your attenti...</td>\n",
       "      <td>1</td>\n",
       "      <td>997</td>\n",
       "      <td>[3244, 6, 2, 1400, 15, 8, 6920, 171, 559, 142,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>moviemaking is a lot like being the general ma...</td>\n",
       "      <td>1</td>\n",
       "      <td>644</td>\n",
       "      <td>[4789, 6, 2, 211, 39, 109, 1, 834, 3095, 4, 24...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  sentiment  \\\n",
       "0  films adapted from comic books have had plenty...          1   \n",
       "1  every now and then a movie comes along from a ...          1   \n",
       "2  youve got mail works alot better than it deser...          1   \n",
       "3    jaws  is a rare film that grabs your attenti...          1   \n",
       "4  moviemaking is a lot like being the general ma...          1   \n",
       "\n",
       "   reviews_word_count                                           sequence  \n",
       "0                 679  [67, 2745, 29, 355, 1634, 32, 90, 1047, 4, 627...  \n",
       "1                 650  [150, 144, 3, 102, 2, 27, 199, 264, 29, 2, 151...  \n",
       "2                 416  [729, 287, 3642, 379, 9979, 153, 58, 9, 1213, ...  \n",
       "3                 997  [3244, 6, 2, 1400, 15, 8, 6920, 171, 559, 142,...  \n",
       "4                 644  [4789, 6, 2, 211, 39, 109, 1, 834, 3095, 4, 24...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>viii. Select a review length L that 70% of the reviews have a length below it. If\n",
    "you feel more adventurous, set the threshold to 90%.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review Length at 70%:  737.0\n"
     ]
    }
   ],
   "source": [
    "L = df['reviews_word_count'].quantile(0.7)\n",
    "print('Review Length at 70%: ', L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>ix. Truncate reviews longer than L words and zero-pad reviews shorter than L\n",
    "so that all texts (= data points) are of length L."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['padding'] = preprocessing.sequence.pad_sequences(df['sequence'],maxlen = int(L)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>reviews_word_count</th>\n",
       "      <th>sequence</th>\n",
       "      <th>padding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>films adapted from comic books have had plenty...</td>\n",
       "      <td>1</td>\n",
       "      <td>679</td>\n",
       "      <td>[67, 2745, 29, 355, 1634, 32, 90, 1047, 4, 627...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>every now and then a movie comes along from a ...</td>\n",
       "      <td>1</td>\n",
       "      <td>650</td>\n",
       "      <td>[150, 144, 3, 102, 2, 27, 199, 264, 29, 2, 151...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>youve got mail works alot better than it deser...</td>\n",
       "      <td>1</td>\n",
       "      <td>416</td>\n",
       "      <td>[729, 287, 3642, 379, 9979, 153, 58, 9, 1213, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jaws  is a rare film that grabs your attenti...</td>\n",
       "      <td>1</td>\n",
       "      <td>997</td>\n",
       "      <td>[3244, 6, 2, 1400, 15, 8, 6920, 171, 559, 142,...</td>\n",
       "      <td>[1613, 5772, 2342, 9981, 114, 252, 5, 2865, 16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>moviemaking is a lot like being the general ma...</td>\n",
       "      <td>1</td>\n",
       "      <td>644</td>\n",
       "      <td>[4789, 6, 2, 211, 39, 109, 1, 834, 3095, 4, 24...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  sentiment  \\\n",
       "0  films adapted from comic books have had plenty...          1   \n",
       "1  every now and then a movie comes along from a ...          1   \n",
       "2  youve got mail works alot better than it deser...          1   \n",
       "3    jaws  is a rare film that grabs your attenti...          1   \n",
       "4  moviemaking is a lot like being the general ma...          1   \n",
       "\n",
       "   reviews_word_count                                           sequence  \\\n",
       "0                 679  [67, 2745, 29, 355, 1634, 32, 90, 1047, 4, 627...   \n",
       "1                 650  [150, 144, 3, 102, 2, 27, 199, 264, 29, 2, 151...   \n",
       "2                 416  [729, 287, 3642, 379, 9979, 153, 58, 9, 1213, ...   \n",
       "3                 997  [3244, 6, 2, 1400, 15, 8, 6920, 171, 559, 142,...   \n",
       "4                 644  [4789, 6, 2, 211, 39, 109, 1, 834, 3095, 4, 24...   \n",
       "\n",
       "                                             padding  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3  [1613, 5772, 2342, 9981, 114, 252, 5, 2865, 16...  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>(c) Word Embeddings\n",
    "<br><br>i. One can use tokenized text as inputs to a deep neural network. However, a recent breakthrough in NLP suggests that more sophisticated representations of\n",
    "text yield better results. These sophisticated representations are called word\n",
    "embeddings. â€œWord embedding is a term used for representation of words\n",
    "for text analysis, typically in the form of a real-valued vector that encodes\n",
    "the meaning of the word such that the words that are closer in the vector\n",
    "space are expected to be similar in meaning.â€4\n",
    ". Most deep learning modules\n",
    "(including Keras) provide a convenient way to convert positive integer representations of words into a word embedding by an â€œEmbedding layer.â€ The\n",
    "layer accepts arguments that define the mapping of words into embeddings,(c) Word Embeddings\n",
    "i. One can use tokenized text as inputs to a deep neural network. However, a re\u0002cent breakthrough in NLP suggests that more sophisticated representations of\n",
    "text yield better results. These sophisticated representations are called word\n",
    "embeddings. â€œWord embedding is a term used for representation of words\n",
    "for text analysis, typically in the form of a real-valued vector that encodes\n",
    "the meaning of the word such that the words that are closer in the vector\n",
    "space are expected to be similar in meaning.â€4\n",
    ". Most deep learning modules\n",
    "(including Keras) provide a convenient way to convert positive integer representations of words into a word embedding by an â€œEmbedding layer.â€ The\n",
    "layer accepts arguments that define the mapping of words into embeddings,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(46738, 32, input_length=int(L)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>ii. Flatten the matrix of each document to a vector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten(input_shape=(None, 737, 32) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 737, 32)           1495616   \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 23584)             0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,495,616\n",
      "Trainable params: 1,495,616\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>(d) Multi-Layer Perceptron\n",
    "<br><br>i. Train a MLP with three (dense) hidden layers each of which has 50 ReLUs\n",
    "and one output layer with a single sigmoid neuron. Use a dropout rate of\n",
    "20% for the first layer and 50% for the other layers. Use ADAM optimizer\n",
    "and binary cross entropy loss (which is equivalent to having a softmax in the\n",
    "output). To avoid overfitting, just set the number of epochs as 2. Use a batch\n",
    "size of 10.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = df.iloc[:700]\n",
    "train2 = df.iloc[1000:1700]\n",
    "test1 = df.iloc[700:1000]\n",
    "test2 =df.iloc[1700:2000]\n",
    "train = pd.concat([train1,train2])\n",
    "test = pd.concat([test1,test2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding_test = preprocessing.sequence.pad_sequences(test['sequence'],maxlen = int(L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 737)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padding_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding = preprocessing.sequence.pad_sequences(train['sequence'],maxlen = int(L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1400, 737)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 737, 32)           1495616   \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 23584)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 50)                1179250   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 50)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 50)                2550      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 50)                2550      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,680,017\n",
      "Trainable params: 2,680,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(737,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padding[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "140/140 [==============================] - 5s 29ms/step - loss: 0.6932 - acc: 0.5364\n",
      "Epoch 2/2\n",
      "140/140 [==============================] - 4s 28ms/step - loss: 0.5618 - acc: 0.7179\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1db898f3880>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(padding, train['sentiment'], epochs=2, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>ii. Report the train and test accuracies of this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 97.214288\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(padding, train['sentiment'], verbose=0)\n",
    "print('Train Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 64.666665\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(padding_test, test['sentiment'], verbose=0)\n",
    "print('Test Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>(e) One-Dimensional Convolutional Neural Network:\n",
    "Although CNNs are mainly used for image data, they can also be applied to text\n",
    "data, as text also has adjacency information. Keras supports one-dimensional\n",
    "convolutions and pooling by the Conv1D and MaxPooling1D classes respectively.\n",
    "<br><br>i. After the embedding layer, insert a Conv1D layer. This convolutional layer\n",
    "has 32 feature maps , and each of the 32 kernels has size 3, i.e. reads embedded\n",
    "word representations 3 vector elements of the word embedding at a time. The\n",
    "convolutional layer is followed by a 1D max pooling layer with a length and\n",
    "stride of 2 that halves the size of the feature maps from the convolutional\n",
    "layer. The rest of the network is the same as the neural network above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Embedding(46738, 32, input_length=int(L)))\n",
    "model2.add(Conv1D(filters=32, kernel_size = 3, input_shape = (None, 737, 32) ))\n",
    "model2.add(MaxPooling1D(pool_size=2))\n",
    "model2.add(Dense(50, activation='relu'))\n",
    "model2.add(Dropout(0.2))\n",
    "model2.add(Dense(50, activation='relu'))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(50, activation='relu'))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(1, activation='sigmoid'))\n",
    "model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 737, 32)           1495616   \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 23584)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 50)                1179250   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 50)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 50)                2550      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 50)                2550      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,680,017\n",
      "Trainable params: 2,680,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>ii. Report the train and test accuracies of this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "140/140 [==============================] - 5s 30ms/step - loss: 0.6933 - acc: 0.4983\n",
      "Epoch 2/2\n",
      "140/140 [==============================] - 4s 30ms/step - loss: 0.6857 - acc: 0.5584\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1db9216c1f0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(padding, train['sentiment'], epochs=2, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 62.326586\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model2.evaluate(padding, train['sentiment'], verbose=0)\n",
    "print('Train Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 56.696635\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model2.evaluate(padding_test, test['sentiment'], verbose=0)\n",
    "print('Test Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>(f) Long Short-Term Memory Recurrent Neural Network:\n",
    "The structure of the LSTM we are going to use is shown in the following figure.\n",
    "<br><br>i. Each word is represented to LSTM as a vector of 32 elements and the LSTM\n",
    "is followed by a dense layer of 256 ReLUs. Use a dropout rate of 0.2 for both\n",
    "LSTM and the dense layer. Train the model using 10-50 epochs and batch\n",
    "size of 10.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Embedding(46738, 32, input_length=int(L)))\n",
    "model3.add(LSTM(32, dropout=0.2))\n",
    "model3.add(Dense(256, activation='relu'))\n",
    "model3.add(Dropout(0.2))\n",
    "model3.add(Dense(1, activation='sigmoid'))\n",
    "model3.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 737, 32)           1495616   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 32)                8320      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 256)               8448      \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,512,641\n",
      "Trainable params: 1,512,641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model3.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>ii. Report the train and test accuracies of this model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "140/140 [==============================] - 31s 205ms/step - loss: 0.6933 - acc: 0.5114\n",
      "Epoch 2/10\n",
      "140/140 [==============================] - 30s 215ms/step - loss: 0.4888 - acc: 0.7964\n",
      "Epoch 3/10\n",
      "140/140 [==============================] - 29s 207ms/step - loss: 0.1148 - acc: 0.9593\n",
      "Epoch 4/10\n",
      "140/140 [==============================] - 29s 210ms/step - loss: 0.0339 - acc: 0.9886\n",
      "Epoch 5/10\n",
      "140/140 [==============================] - 30s 212ms/step - loss: 0.0062 - acc: 0.9986\n",
      "Epoch 6/10\n",
      "140/140 [==============================] - 29s 207ms/step - loss: 2.0374e-04 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "140/140 [==============================] - 30s 215ms/step - loss: 1.3481e-04 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "140/140 [==============================] - 31s 218ms/step - loss: 7.8461e-05 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "140/140 [==============================] - 29s 210ms/step - loss: 5.5484e-05 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "140/140 [==============================] - 29s 204ms/step - loss: 4.0345e-05 - acc: 1.0000\n",
      "Epoch 1/11\n",
      "140/140 [==============================] - 30s 212ms/step - loss: 3.0367e-05 - acc: 1.0000\n",
      "Epoch 2/11\n",
      "140/140 [==============================] - 30s 210ms/step - loss: 2.3641e-05 - acc: 1.0000\n",
      "Epoch 3/11\n",
      "140/140 [==============================] - 31s 221ms/step - loss: 2.2000e-05 - acc: 1.0000\n",
      "Epoch 4/11\n",
      "140/140 [==============================] - 30s 214ms/step - loss: 1.9361e-05 - acc: 1.0000\n",
      "Epoch 5/11\n",
      "140/140 [==============================] - 31s 218ms/step - loss: 1.7082e-05 - acc: 1.0000\n",
      "Epoch 6/11\n",
      "140/140 [==============================] - 30s 211ms/step - loss: 1.3691e-05 - acc: 1.0000\n",
      "Epoch 7/11\n",
      "140/140 [==============================] - 29s 209ms/step - loss: 1.0964e-05 - acc: 1.0000\n",
      "Epoch 8/11\n",
      "140/140 [==============================] - 30s 213ms/step - loss: 9.5941e-06 - acc: 1.0000\n",
      "Epoch 9/11\n",
      "140/140 [==============================] - 30s 213ms/step - loss: 7.0325e-06 - acc: 1.0000\n",
      "Epoch 10/11\n",
      "140/140 [==============================] - 30s 216ms/step - loss: 6.8067e-06 - acc: 1.0000\n",
      "Epoch 11/11\n",
      "140/140 [==============================] - 29s 210ms/step - loss: 5.9247e-06 - acc: 1.0000\n",
      "Epoch 1/12\n",
      "140/140 [==============================] - 30s 212ms/step - loss: 5.5055e-06 - acc: 1.0000\n",
      "Epoch 2/12\n",
      "140/140 [==============================] - 30s 212ms/step - loss: 1.3547e-04 - acc: 1.0000\n",
      "Epoch 3/12\n",
      "140/140 [==============================] - 30s 217ms/step - loss: 2.4313e-05 - acc: 1.0000\n",
      "Epoch 4/12\n",
      "140/140 [==============================] - 31s 220ms/step - loss: 6.9566e-06 - acc: 1.0000\n",
      "Epoch 5/12\n",
      "140/140 [==============================] - 29s 208ms/step - loss: 6.0117e-06 - acc: 1.0000\n",
      "Epoch 6/12\n",
      "140/140 [==============================] - 30s 217ms/step - loss: 3.8014e-06 - acc: 1.0000\n",
      "Epoch 7/12\n",
      "140/140 [==============================] - 31s 225ms/step - loss: 3.4828e-06 - acc: 1.0000\n",
      "Epoch 8/12\n",
      "140/140 [==============================] - 31s 223ms/step - loss: 3.2160e-06 - acc: 1.0000\n",
      "Epoch 9/12\n",
      "140/140 [==============================] - 34s 241ms/step - loss: 2.5697e-06 - acc: 1.0000\n",
      "Epoch 10/12\n",
      "140/140 [==============================] - 37s 264ms/step - loss: 2.3611e-06 - acc: 1.0000\n",
      "Epoch 11/12\n",
      "140/140 [==============================] - 35s 249ms/step - loss: 2.1489e-06 - acc: 1.0000\n",
      "Epoch 12/12\n",
      "140/140 [==============================] - 33s 233ms/step - loss: 1.5784e-06 - acc: 1.0000\n",
      "Epoch 1/13\n",
      "140/140 [==============================] - 32s 232ms/step - loss: 1.4781e-06 - acc: 1.0000\n",
      "Epoch 2/13\n",
      "140/140 [==============================] - 30s 216ms/step - loss: 1.7600e-06 - acc: 1.0000\n",
      "Epoch 3/13\n",
      "140/140 [==============================] - 34s 239ms/step - loss: 1.0308e-06 - acc: 1.0000\n",
      "Epoch 4/13\n",
      "140/140 [==============================] - 33s 233ms/step - loss: 1.1767e-06 - acc: 1.0000\n",
      "Epoch 5/13\n",
      "140/140 [==============================] - 36s 260ms/step - loss: 1.0539e-06 - acc: 1.0000\n",
      "Epoch 6/13\n",
      "140/140 [==============================] - 42s 298ms/step - loss: 8.4183e-07 - acc: 1.0000\n",
      "Epoch 7/13\n",
      "140/140 [==============================] - 42s 297ms/step - loss: 7.2658e-07 - acc: 1.0000\n",
      "Epoch 8/13\n",
      "140/140 [==============================] - 40s 286ms/step - loss: 9.7013e-07 - acc: 1.0000\n",
      "Epoch 9/13\n",
      "140/140 [==============================] - 41s 293ms/step - loss: 7.9046e-07 - acc: 1.0000\n",
      "Epoch 10/13\n",
      "140/140 [==============================] - 41s 296ms/step - loss: 6.3440e-07 - acc: 1.0000\n",
      "Epoch 11/13\n",
      "140/140 [==============================] - 40s 289ms/step - loss: 4.3763e-07 - acc: 1.0000\n",
      "Epoch 12/13\n",
      "140/140 [==============================] - 42s 301ms/step - loss: 5.5172e-07 - acc: 1.0000\n",
      "Epoch 13/13\n",
      "140/140 [==============================] - 42s 300ms/step - loss: 4.3917e-07 - acc: 1.0000\n",
      "Epoch 1/14\n",
      "140/140 [==============================] - 42s 304ms/step - loss: 4.5318e-07 - acc: 1.0000\n",
      "Epoch 2/14\n",
      "140/140 [==============================] - 41s 294ms/step - loss: 6.0844e-07 - acc: 1.0000\n",
      "Epoch 3/14\n",
      "140/140 [==============================] - 42s 302ms/step - loss: 3.5208e-07 - acc: 1.0000\n",
      "Epoch 4/14\n",
      "140/140 [==============================] - 41s 294ms/step - loss: 3.5579e-07 - acc: 1.0000\n",
      "Epoch 5/14\n",
      "140/140 [==============================] - 42s 302ms/step - loss: 3.4523e-07 - acc: 1.0000\n",
      "Epoch 6/14\n",
      "140/140 [==============================] - 42s 300ms/step - loss: 4.2093e-07 - acc: 1.0000\n",
      "Epoch 7/14\n",
      "140/140 [==============================] - 42s 299ms/step - loss: 3.6316e-07 - acc: 1.0000\n",
      "Epoch 8/14\n",
      "140/140 [==============================] - 41s 296ms/step - loss: 3.5088e-07 - acc: 1.0000\n",
      "Epoch 9/14\n",
      "140/140 [==============================] - 42s 299ms/step - loss: 2.1770e-07 - acc: 1.0000\n",
      "Epoch 10/14\n",
      "140/140 [==============================] - 41s 296ms/step - loss: 2.3259e-07 - acc: 1.0000\n",
      "Epoch 11/14\n",
      "140/140 [==============================] - 42s 304ms/step - loss: 2.3686e-07 - acc: 1.0000\n",
      "Epoch 12/14\n",
      "140/140 [==============================] - 42s 297ms/step - loss: 7.3628e-07 - acc: 1.0000\n",
      "Epoch 13/14\n",
      "140/140 [==============================] - 41s 296ms/step - loss: 3.4396e-07 - acc: 1.0000\n",
      "Epoch 14/14\n",
      "140/140 [==============================] - 42s 299ms/step - loss: 2.6971e-07 - acc: 1.0000\n",
      "Epoch 1/15\n",
      "140/140 [==============================] - 40s 289ms/step - loss: 1.7908e-07 - acc: 1.0000\n",
      "Epoch 2/15\n",
      "140/140 [==============================] - 42s 297ms/step - loss: 1.5608e-07 - acc: 1.0000\n",
      "Epoch 3/15\n",
      "140/140 [==============================] - 41s 293ms/step - loss: 1.9134e-07 - acc: 1.0000\n",
      "Epoch 4/15\n",
      "140/140 [==============================] - 42s 300ms/step - loss: 1.3774e-07 - acc: 1.0000\n",
      "Epoch 5/15\n",
      "140/140 [==============================] - 42s 301ms/step - loss: 1.6516e-07 - acc: 1.0000\n",
      "Epoch 6/15\n",
      "140/140 [==============================] - 41s 295ms/step - loss: 1.2802e-07 - acc: 1.0000\n",
      "Epoch 7/15\n",
      "140/140 [==============================] - 42s 299ms/step - loss: 1.4192e-07 - acc: 1.0000\n",
      "Epoch 8/15\n",
      "140/140 [==============================] - 42s 302ms/step - loss: 7.9999e-08 - acc: 1.0000\n",
      "Epoch 9/15\n",
      "140/140 [==============================] - 41s 295ms/step - loss: 9.6108e-08 - acc: 1.0000\n",
      "Epoch 10/15\n",
      "140/140 [==============================] - 42s 298ms/step - loss: 8.8896e-08 - acc: 1.0000\n",
      "Epoch 11/15\n",
      "140/140 [==============================] - 43s 305ms/step - loss: 8.4788e-07 - acc: 1.0000\n",
      "Epoch 12/15\n",
      "140/140 [==============================] - 42s 299ms/step - loss: 1.2339e-07 - acc: 1.0000\n",
      "Epoch 13/15\n",
      "140/140 [==============================] - 42s 302ms/step - loss: 9.6760e-08 - acc: 1.0000\n",
      "Epoch 14/15\n",
      "140/140 [==============================] - 42s 301ms/step - loss: 1.2034e-07 - acc: 1.0000\n",
      "Epoch 15/15\n",
      "140/140 [==============================] - 42s 301ms/step - loss: 9.3495e-08 - acc: 1.0000\n",
      "Epoch 1/16\n",
      "140/140 [==============================] - 42s 298ms/step - loss: 5.9339e-08 - acc: 1.0000\n",
      "Epoch 2/16\n",
      "140/140 [==============================] - 42s 298ms/step - loss: 1.7617e-06 - acc: 1.0000\n",
      "Epoch 3/16\n",
      "140/140 [==============================] - 42s 299ms/step - loss: 0.1251 - acc: 0.9600\n",
      "Epoch 4/16\n",
      "140/140 [==============================] - 42s 298ms/step - loss: 0.0514 - acc: 0.9786\n",
      "Epoch 5/16\n",
      "140/140 [==============================] - 42s 299ms/step - loss: 0.0059 - acc: 0.9993\n",
      "Epoch 6/16\n",
      "140/140 [==============================] - 41s 294ms/step - loss: 9.2761e-04 - acc: 1.0000\n",
      "Epoch 7/16\n",
      "140/140 [==============================] - 42s 302ms/step - loss: 8.1187e-05 - acc: 1.0000\n",
      "Epoch 8/16\n",
      "140/140 [==============================] - 41s 295ms/step - loss: 3.3799e-05 - acc: 1.0000\n",
      "Epoch 9/16\n",
      "140/140 [==============================] - 41s 296ms/step - loss: 2.7996e-05 - acc: 1.0000\n",
      "Epoch 10/16\n",
      "140/140 [==============================] - 42s 301ms/step - loss: 2.3135e-05 - acc: 1.0000\n",
      "Epoch 11/16\n",
      "140/140 [==============================] - 41s 294ms/step - loss: 2.1711e-05 - acc: 1.0000\n",
      "Epoch 12/16\n",
      "140/140 [==============================] - 42s 297ms/step - loss: 2.0695e-05 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "140/140 [==============================] - 41s 296ms/step - loss: 1.6705e-05 - acc: 1.0000\n",
      "Epoch 14/16\n",
      "140/140 [==============================] - 41s 294ms/step - loss: 1.3471e-05 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "140/140 [==============================] - 42s 303ms/step - loss: 1.1966e-05 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "140/140 [==============================] - 41s 292ms/step - loss: 1.1893e-05 - acc: 1.0000\n",
      "Epoch 1/17\n",
      "140/140 [==============================] - 42s 298ms/step - loss: 9.6774e-06 - acc: 1.0000\n",
      "Epoch 2/17\n",
      "140/140 [==============================] - 42s 297ms/step - loss: 8.5296e-06 - acc: 1.0000\n",
      "Epoch 3/17\n",
      "140/140 [==============================] - 42s 299ms/step - loss: 8.2137e-06 - acc: 1.0000\n",
      "Epoch 4/17\n",
      "140/140 [==============================] - 41s 293ms/step - loss: 7.2729e-06 - acc: 1.0000\n",
      "Epoch 5/17\n",
      "140/140 [==============================] - 42s 297ms/step - loss: 7.0158e-06 - acc: 1.0000\n",
      "Epoch 6/17\n",
      "140/140 [==============================] - 42s 296ms/step - loss: 5.9311e-06 - acc: 1.0000\n",
      "Epoch 7/17\n",
      "140/140 [==============================] - 40s 289ms/step - loss: 5.5441e-06 - acc: 1.0000\n",
      "Epoch 8/17\n",
      "140/140 [==============================] - 42s 303ms/step - loss: 4.0533e-06 - acc: 1.0000\n",
      "Epoch 9/17\n",
      "140/140 [==============================] - 41s 295ms/step - loss: 4.6459e-06 - acc: 1.0000\n",
      "Epoch 10/17\n",
      "140/140 [==============================] - 42s 300ms/step - loss: 3.5949e-06 - acc: 1.0000\n",
      "Epoch 11/17\n",
      "140/140 [==============================] - 42s 297ms/step - loss: 3.5297e-06 - acc: 1.0000\n",
      "Epoch 12/17\n",
      "140/140 [==============================] - 41s 295ms/step - loss: 3.4419e-06 - acc: 1.0000\n",
      "Epoch 13/17\n",
      "140/140 [==============================] - 42s 298ms/step - loss: 3.7898e-06 - acc: 1.0000\n",
      "Epoch 14/17\n",
      "140/140 [==============================] - 41s 293ms/step - loss: 2.6998e-06 - acc: 1.0000\n",
      "Epoch 15/17\n",
      "140/140 [==============================] - 41s 296ms/step - loss: 2.1669e-06 - acc: 1.0000\n",
      "Epoch 16/17\n",
      "140/140 [==============================] - 43s 305ms/step - loss: 2.1141e-06 - acc: 1.0000\n",
      "Epoch 17/17\n",
      "140/140 [==============================] - 41s 295ms/step - loss: 2.2620e-06 - acc: 1.0000\n",
      "Epoch 1/18\n",
      "140/140 [==============================] - 42s 302ms/step - loss: 1.8068e-06 - acc: 1.0000\n",
      "Epoch 2/18\n",
      "140/140 [==============================] - 42s 300ms/step - loss: 1.6028e-06 - acc: 1.0000\n",
      "Epoch 3/18\n",
      "140/140 [==============================] - 42s 301ms/step - loss: 1.3967e-06 - acc: 1.0000\n",
      "Epoch 4/18\n",
      "140/140 [==============================] - 41s 293ms/step - loss: 1.3270e-06 - acc: 1.0000\n",
      "Epoch 5/18\n",
      "140/140 [==============================] - 42s 300ms/step - loss: 1.0357e-06 - acc: 1.0000\n",
      "Epoch 6/18\n",
      "140/140 [==============================] - 42s 296ms/step - loss: 1.2406e-06 - acc: 1.0000\n",
      "Epoch 7/18\n",
      "140/140 [==============================] - 42s 301ms/step - loss: 8.6322e-07 - acc: 1.0000\n",
      "Epoch 8/18\n",
      "140/140 [==============================] - 42s 297ms/step - loss: 8.0095e-07 - acc: 1.0000\n",
      "Epoch 9/18\n",
      "140/140 [==============================] - 41s 296ms/step - loss: 8.6042e-07 - acc: 1.0000\n",
      "Epoch 10/18\n",
      "140/140 [==============================] - 42s 301ms/step - loss: 8.2403e-07 - acc: 1.0000\n",
      "Epoch 11/18\n",
      "140/140 [==============================] - 41s 294ms/step - loss: 6.6797e-07 - acc: 1.0000\n",
      "Epoch 12/18\n",
      "140/140 [==============================] - 41s 293ms/step - loss: 6.7875e-07 - acc: 1.0000\n",
      "Epoch 13/18\n",
      "140/140 [==============================] - 41s 295ms/step - loss: 7.6014e-07 - acc: 1.0000\n",
      "Epoch 14/18\n",
      "140/140 [==============================] - 42s 299ms/step - loss: 7.6185e-07 - acc: 1.0000\n",
      "Epoch 15/18\n",
      "140/140 [==============================] - 42s 300ms/step - loss: 4.7160e-07 - acc: 1.0000\n",
      "Epoch 16/18\n",
      "140/140 [==============================] - 42s 299ms/step - loss: 5.9591e-07 - acc: 1.0000\n",
      "Epoch 17/18\n",
      "140/140 [==============================] - 42s 297ms/step - loss: 4.3208e-07 - acc: 1.0000\n",
      "Epoch 18/18\n",
      "140/140 [==============================] - 42s 299ms/step - loss: 6.5552e-07 - acc: 1.0000\n",
      "Epoch 1/19\n",
      "140/140 [==============================] - 42s 300ms/step - loss: 4.6674e-07 - acc: 1.0000\n",
      "Epoch 2/19\n",
      "140/140 [==============================] - 42s 298ms/step - loss: 3.5142e-07 - acc: 1.0000\n",
      "Epoch 3/19\n",
      "140/140 [==============================] - 42s 299ms/step - loss: 3.3791e-07 - acc: 1.0000\n",
      "Epoch 4/19\n",
      "140/140 [==============================] - 41s 296ms/step - loss: 2.9775e-07 - acc: 1.0000\n",
      "Epoch 5/19\n",
      "140/140 [==============================] - 41s 291ms/step - loss: 3.1131e-07 - acc: 1.0000\n",
      "Epoch 6/19\n",
      "140/140 [==============================] - 42s 301ms/step - loss: 2.8486e-07 - acc: 1.0000\n",
      "Epoch 7/19\n",
      "140/140 [==============================] - 41s 293ms/step - loss: 2.4307e-07 - acc: 1.0000\n",
      "Epoch 8/19\n",
      "140/140 [==============================] - 42s 300ms/step - loss: 3.1329e-07 - acc: 1.0000\n",
      "Epoch 9/19\n",
      "140/140 [==============================] - 42s 303ms/step - loss: 2.2288e-07 - acc: 1.0000\n",
      "Epoch 10/19\n",
      "140/140 [==============================] - 41s 296ms/step - loss: 1.6009e-07 - acc: 1.0000\n",
      "Epoch 11/19\n",
      "140/140 [==============================] - 42s 297ms/step - loss: 1.7451e-07 - acc: 1.0000\n",
      "Epoch 12/19\n",
      "140/140 [==============================] - 43s 306ms/step - loss: 2.8532e-07 - acc: 1.0000\n",
      "Epoch 13/19\n",
      "140/140 [==============================] - 42s 299ms/step - loss: 1.5213e-07 - acc: 1.0000\n",
      "Epoch 14/19\n",
      "140/140 [==============================] - 42s 299ms/step - loss: 1.4385e-07 - acc: 1.0000\n",
      "Epoch 15/19\n",
      "140/140 [==============================] - 42s 301ms/step - loss: 1.7271e-07 - acc: 1.0000\n",
      "Epoch 16/19\n",
      "140/140 [==============================] - 42s 300ms/step - loss: 1.6186e-07 - acc: 1.0000\n",
      "Epoch 17/19\n",
      "140/140 [==============================] - 43s 306ms/step - loss: 1.3836e-07 - acc: 1.0000\n",
      "Epoch 18/19\n",
      "140/140 [==============================] - 42s 298ms/step - loss: 1.1740e-07 - acc: 1.0000\n",
      "Epoch 19/19\n",
      "140/140 [==============================] - 41s 296ms/step - loss: 1.3809e-07 - acc: 1.0000\n",
      "Epoch 1/20\n",
      "140/140 [==============================] - 42s 297ms/step - loss: 9.4904e-08 - acc: 1.0000\n",
      "Epoch 2/20\n",
      "140/140 [==============================] - 42s 300ms/step - loss: 1.2101e-07 - acc: 1.0000\n",
      "Epoch 3/20\n",
      "140/140 [==============================] - 41s 294ms/step - loss: 1.0705e-07 - acc: 1.0000\n",
      "Epoch 4/20\n",
      "140/140 [==============================] - 42s 299ms/step - loss: 1.2341e-07 - acc: 1.0000\n",
      "Epoch 5/20\n",
      "140/140 [==============================] - 42s 301ms/step - loss: 6.6501e-08 - acc: 1.0000\n",
      "Epoch 6/20\n",
      "140/140 [==============================] - 41s 292ms/step - loss: 7.7371e-08 - acc: 1.0000\n",
      "Epoch 7/20\n",
      "140/140 [==============================] - 43s 304ms/step - loss: 6.2569e-08 - acc: 1.0000\n",
      "Epoch 8/20\n",
      "140/140 [==============================] - 42s 297ms/step - loss: 7.8498e-08 - acc: 1.0000\n",
      "Epoch 9/20\n",
      "140/140 [==============================] - 42s 299ms/step - loss: 6.0508e-08 - acc: 1.0000\n",
      "Epoch 10/20\n",
      "140/140 [==============================] - 41s 296ms/step - loss: 5.9419e-08 - acc: 1.0000\n",
      "Epoch 11/20\n",
      "140/140 [==============================] - 42s 298ms/step - loss: 1.1876e-06 - acc: 1.0000\n",
      "Epoch 12/20\n",
      "140/140 [==============================] - 42s 301ms/step - loss: 5.2934e-07 - acc: 1.0000\n",
      "Epoch 13/20\n",
      "140/140 [==============================] - 41s 294ms/step - loss: 6.6955e-07 - acc: 1.0000\n",
      "Epoch 14/20\n",
      "140/140 [==============================] - 42s 300ms/step - loss: 6.1787e-08 - acc: 1.0000\n",
      "Epoch 15/20\n",
      "140/140 [==============================] - 42s 297ms/step - loss: 1.2598e-07 - acc: 1.0000\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 41s 296ms/step - loss: 6.3628e-08 - acc: 1.0000\n",
      "Epoch 17/20\n",
      "140/140 [==============================] - 42s 303ms/step - loss: 4.7893e-08 - acc: 1.0000\n",
      "Epoch 18/20\n",
      "140/140 [==============================] - 42s 298ms/step - loss: 5.5269e-08 - acc: 1.0000\n",
      "Epoch 19/20\n",
      "140/140 [==============================] - 41s 292ms/step - loss: 5.1585e-08 - acc: 1.0000\n",
      "Epoch 20/20\n",
      "140/140 [==============================] - 41s 294ms/step - loss: 2.8922e-08 - acc: 1.0000\n",
      "Epoch 1/21\n",
      "140/140 [==============================] - 39s 282ms/step - loss: 2.5696e-08 - acc: 1.0000\n",
      "Epoch 2/21\n",
      "140/140 [==============================] - 41s 294ms/step - loss: 2.7756e-08 - acc: 1.0000\n",
      "Epoch 3/21\n",
      "140/140 [==============================] - 42s 297ms/step - loss: 2.6980e-08 - acc: 1.0000\n",
      "Epoch 4/21\n",
      "140/140 [==============================] - 41s 293ms/step - loss: 2.7124e-08 - acc: 1.0000\n",
      "Epoch 5/21\n",
      "140/140 [==============================] - 42s 298ms/step - loss: 2.8037e-08 - acc: 1.0000\n",
      "Epoch 6/21\n",
      "140/140 [==============================] - 41s 295ms/step - loss: 2.0649e-08 - acc: 1.0000\n",
      "Epoch 7/21\n",
      "140/140 [==============================] - 41s 294ms/step - loss: 1.6857e-08 - acc: 1.0000\n",
      "Epoch 8/21\n",
      "140/140 [==============================] - 41s 296ms/step - loss: 2.7210e-08 - acc: 1.0000\n",
      "Epoch 9/21\n",
      "140/140 [==============================] - 46s 327ms/step - loss: 1.4663e-08 - acc: 1.0000\n",
      "Epoch 10/21\n",
      "140/140 [==============================] - 42s 295ms/step - loss: 1.8811e-08 - acc: 1.0000\n",
      "Epoch 11/21\n",
      "140/140 [==============================] - 41s 290ms/step - loss: 1.3872e-08 - acc: 1.0000\n",
      "Epoch 12/21\n",
      "140/140 [==============================] - 46s 329ms/step - loss: 1.6060e-08 - acc: 1.0000\n",
      "Epoch 13/21\n",
      "140/140 [==============================] - 41s 293ms/step - loss: 1.1209e-08 - acc: 1.0000\n",
      "Epoch 14/21\n",
      "140/140 [==============================] - 42s 301ms/step - loss: 1.1509e-08 - acc: 1.0000\n",
      "Epoch 15/21\n",
      "140/140 [==============================] - 42s 297ms/step - loss: 6.4023e-09 - acc: 1.0000\n",
      "Epoch 16/21\n",
      "140/140 [==============================] - 41s 292ms/step - loss: 1.2405e-08 - acc: 1.0000\n",
      "Epoch 17/21\n",
      "140/140 [==============================] - 42s 301ms/step - loss: 8.8475e-09 - acc: 1.0000\n",
      "Epoch 18/21\n",
      "140/140 [==============================] - 42s 301ms/step - loss: 5.5714e-09 - acc: 1.0000\n",
      "Epoch 19/21\n",
      "140/140 [==============================] - 42s 300ms/step - loss: 1.1709e-08 - acc: 1.0000\n",
      "Epoch 20/21\n",
      "140/140 [==============================] - 40s 289ms/step - loss: 5.5738e-09 - acc: 1.0000\n",
      "Epoch 21/21\n",
      "140/140 [==============================] - 42s 297ms/step - loss: 5.3110e-09 - acc: 1.0000\n",
      "Epoch 1/22\n",
      "140/140 [==============================] - 42s 297ms/step - loss: 6.3065e-09 - acc: 1.0000\n",
      "Epoch 2/22\n",
      "140/140 [==============================] - 42s 297ms/step - loss: 4.8808e-09 - acc: 1.0000\n",
      "Epoch 3/22\n",
      "140/140 [==============================] - 42s 297ms/step - loss: 6.7726e-09 - acc: 1.0000\n",
      "Epoch 4/22\n",
      "140/140 [==============================] - 42s 297ms/step - loss: 7.6839e-09 - acc: 1.0000\n",
      "Epoch 5/22\n",
      "140/140 [==============================] - 42s 296ms/step - loss: 4.0823e-09 - acc: 1.0000\n",
      "Epoch 6/22\n",
      "140/140 [==============================] - 42s 300ms/step - loss: 3.1709e-09 - acc: 1.0000\n",
      "Epoch 7/22\n",
      "140/140 [==============================] - 42s 300ms/step - loss: 4.3798e-09 - acc: 1.0000\n",
      "Epoch 8/22\n",
      "140/140 [==============================] - 41s 296ms/step - loss: 3.3450e-09 - acc: 1.0000\n",
      "Epoch 9/22\n",
      "140/140 [==============================] - 41s 293ms/step - loss: 4.3228e-09 - acc: 1.0000\n",
      "Epoch 10/22\n",
      "140/140 [==============================] - 43s 304ms/step - loss: 2.8089e-09 - acc: 1.0000\n",
      "Epoch 11/22\n",
      "140/140 [==============================] - 42s 298ms/step - loss: 3.0507e-09 - acc: 1.0000\n",
      "Epoch 12/22\n",
      "140/140 [==============================] - 42s 297ms/step - loss: 2.1367e-09 - acc: 1.0000\n",
      "Epoch 13/22\n",
      "140/140 [==============================] - 42s 297ms/step - loss: 2.8155e-09 - acc: 1.0000\n",
      "Epoch 14/22\n",
      "140/140 [==============================] - 41s 293ms/step - loss: 2.1017e-09 - acc: 1.0000\n",
      "Epoch 15/22\n",
      "140/140 [==============================] - 42s 302ms/step - loss: 2.2432e-09 - acc: 1.0000\n",
      "Epoch 16/22\n",
      "140/140 [==============================] - 42s 302ms/step - loss: 2.2538e-09 - acc: 1.0000\n",
      "Epoch 17/22\n",
      "140/140 [==============================] - 42s 297ms/step - loss: 1.9426e-09 - acc: 1.0000\n",
      "Epoch 18/22\n",
      "140/140 [==============================] - 43s 306ms/step - loss: 1.6906e-09 - acc: 1.0000\n",
      "Epoch 19/22\n",
      "140/140 [==============================] - 42s 298ms/step - loss: 1.5679e-09 - acc: 1.0000\n",
      "Epoch 20/22\n",
      "140/140 [==============================] - 42s 299ms/step - loss: 1.9071e-09 - acc: 1.0000\n",
      "Epoch 21/22\n",
      "140/140 [==============================] - 42s 303ms/step - loss: 1.2233e-09 - acc: 1.0000\n",
      "Epoch 22/22\n",
      "140/140 [==============================] - 42s 300ms/step - loss: 1.9730e-09 - acc: 1.0000\n",
      "Epoch 1/23\n",
      "140/140 [==============================] - 42s 297ms/step - loss: 1.0372e-09 - acc: 1.0000\n",
      "Epoch 2/23\n",
      "140/140 [==============================] - 43s 304ms/step - loss: 1.1623e-09 - acc: 1.0000\n",
      "Epoch 3/23\n",
      "140/140 [==============================] - 42s 297ms/step - loss: 1.8078e-09 - acc: 1.0000\n",
      "Epoch 4/23\n",
      "140/140 [==============================] - 41s 294ms/step - loss: 1.4430e-09 - acc: 1.0000\n",
      "Epoch 5/23\n",
      "140/140 [==============================] - 42s 301ms/step - loss: 2.1747e-09 - acc: 1.0000\n",
      "Epoch 6/23\n",
      "140/140 [==============================] - 42s 302ms/step - loss: 1.8386e-09 - acc: 1.0000\n",
      "Epoch 7/23\n",
      "140/140 [==============================] - 44s 313ms/step - loss: 1.7503e-09 - acc: 1.0000\n",
      "Epoch 8/23\n",
      "140/140 [==============================] - 44s 314ms/step - loss: 1.8608e-09 - acc: 1.0000\n",
      "Epoch 9/23\n",
      "140/140 [==============================] - 44s 313ms/step - loss: 1.5448e-09 - acc: 1.0000\n",
      "Epoch 10/23\n",
      "140/140 [==============================] - 44s 311ms/step - loss: 1.4441e-09 - acc: 1.0000\n",
      "Epoch 11/23\n",
      "140/140 [==============================] - 44s 311ms/step - loss: 8.3137e-10 - acc: 1.0000\n",
      "Epoch 12/23\n",
      "140/140 [==============================] - 43s 310ms/step - loss: 9.2613e-10 - acc: 1.0000\n",
      "Epoch 13/23\n",
      "140/140 [==============================] - 44s 312ms/step - loss: 1.4112e-09 - acc: 1.0000\n",
      "Epoch 14/23\n",
      "140/140 [==============================] - 43s 309ms/step - loss: 5.0575e-10 - acc: 1.0000\n",
      "Epoch 15/23\n",
      "140/140 [==============================] - 44s 314ms/step - loss: 1.0921e-09 - acc: 1.0000\n",
      "Epoch 16/23\n",
      "140/140 [==============================] - 44s 312ms/step - loss: 8.8697e-10 - acc: 1.0000\n",
      "Epoch 17/23\n",
      "140/140 [==============================] - 43s 309ms/step - loss: 8.3354e-10 - acc: 1.0000\n",
      "Epoch 18/23\n",
      "140/140 [==============================] - 43s 308ms/step - loss: 1.0243e-09 - acc: 1.0000\n",
      "Epoch 19/23\n",
      "140/140 [==============================] - 44s 313ms/step - loss: 1.0839e-09 - acc: 1.0000\n",
      "Epoch 20/23\n",
      "140/140 [==============================] - 43s 309ms/step - loss: 8.0432e-10 - acc: 1.0000\n",
      "Epoch 21/23\n",
      "140/140 [==============================] - 44s 313ms/step - loss: 5.1312e-10 - acc: 1.0000\n",
      "Epoch 22/23\n",
      "140/140 [==============================] - 50s 356ms/step - loss: 4.4069e-10 - acc: 1.0000\n",
      "Epoch 23/23\n",
      "140/140 [==============================] - 50s 356ms/step - loss: 3.4490e-10 - acc: 1.0000\n",
      "Epoch 1/24\n",
      "140/140 [==============================] - 50s 355ms/step - loss: 6.3800e-10 - acc: 1.0000\n",
      "Epoch 2/24\n",
      "140/140 [==============================] - 49s 353ms/step - loss: 2.7148e-10 - acc: 1.0000\n",
      "Epoch 3/24\n",
      "140/140 [==============================] - 50s 354ms/step - loss: 3.0259e-10 - acc: 1.0000\n",
      "Epoch 4/24\n",
      "140/140 [==============================] - 50s 354ms/step - loss: 3.3991e-10 - acc: 1.0000\n",
      "Epoch 5/24\n",
      "140/140 [==============================] - 50s 354ms/step - loss: 3.8631e-10 - acc: 1.0000\n",
      "Epoch 6/24\n",
      "140/140 [==============================] - 50s 354ms/step - loss: 5.1551e-10 - acc: 1.0000\n",
      "Epoch 7/24\n",
      "140/140 [==============================] - 50s 355ms/step - loss: 3.8404e-10 - acc: 1.0000\n",
      "Epoch 8/24\n",
      "140/140 [==============================] - 50s 355ms/step - loss: 2.6586e-10 - acc: 1.0000\n",
      "Epoch 9/24\n",
      "140/140 [==============================] - 50s 355ms/step - loss: 5.0592e-10 - acc: 1.0000\n",
      "Epoch 10/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 49s 348ms/step - loss: 1.7992e-09 - acc: 1.0000\n",
      "Epoch 11/24\n",
      "140/140 [==============================] - 49s 351ms/step - loss: 3.4133e-10 - acc: 1.0000\n",
      "Epoch 12/24\n",
      "140/140 [==============================] - 49s 350ms/step - loss: 2.8923e-10 - acc: 1.0000\n",
      "Epoch 13/24\n",
      "140/140 [==============================] - 50s 354ms/step - loss: 5.2276e-10 - acc: 1.0000\n",
      "Epoch 14/24\n",
      "140/140 [==============================] - 50s 355ms/step - loss: 3.3045e-10 - acc: 1.0000\n",
      "Epoch 15/24\n",
      "140/140 [==============================] - 56s 400ms/step - loss: 4.4379e-10 - acc: 1.0000\n",
      "Epoch 16/24\n",
      "140/140 [==============================] - 80s 572ms/step - loss: 3.2532e-10 - acc: 1.0000\n",
      "Epoch 17/24\n",
      "140/140 [==============================] - 80s 573ms/step - loss: 1.1873e-10 - acc: 1.0000\n",
      "Epoch 18/24\n",
      "140/140 [==============================] - 81s 577ms/step - loss: 4.6552e-10 - acc: 1.0000\n",
      "Epoch 19/24\n",
      "140/140 [==============================] - 80s 574ms/step - loss: 1.9451e-10 - acc: 1.0000\n",
      "Epoch 20/24\n",
      "140/140 [==============================] - 80s 573ms/step - loss: 2.6441e-10 - acc: 1.0000\n",
      "Epoch 21/24\n",
      "140/140 [==============================] - 79s 567ms/step - loss: 0.0389 - acc: 0.9957\n",
      "Epoch 22/24\n",
      "140/140 [==============================] - 79s 567ms/step - loss: 0.0192 - acc: 0.9950\n",
      "Epoch 23/24\n",
      "140/140 [==============================] - 80s 572ms/step - loss: 0.0199 - acc: 0.9921\n",
      "Epoch 24/24\n",
      "140/140 [==============================] - 80s 573ms/step - loss: 0.0051 - acc: 0.9993\n",
      "Epoch 1/25\n",
      "140/140 [==============================] - 80s 570ms/step - loss: 9.5594e-05 - acc: 1.0000\n",
      "Epoch 2/25\n",
      "140/140 [==============================] - 79s 568ms/step - loss: 6.7906e-05 - acc: 1.0000\n",
      "Epoch 3/25\n",
      "140/140 [==============================] - 80s 570ms/step - loss: 3.0538e-05 - acc: 1.0000\n",
      "Epoch 4/25\n",
      "140/140 [==============================] - 79s 566ms/step - loss: 3.5356e-05 - acc: 1.0000\n",
      "Epoch 5/25\n",
      "140/140 [==============================] - 80s 569ms/step - loss: 1.6242e-05 - acc: 1.0000\n",
      "Epoch 6/25\n",
      "140/140 [==============================] - 79s 567ms/step - loss: 1.4284e-05 - acc: 1.0000\n",
      "Epoch 7/25\n",
      "140/140 [==============================] - 80s 568ms/step - loss: 1.3938e-05 - acc: 1.0000\n",
      "Epoch 8/25\n",
      "140/140 [==============================] - 80s 569ms/step - loss: 1.1300e-05 - acc: 1.0000\n",
      "Epoch 9/25\n",
      "140/140 [==============================] - 79s 566ms/step - loss: 1.1309e-05 - acc: 1.0000\n",
      "Epoch 10/25\n",
      "140/140 [==============================] - 80s 568ms/step - loss: 3.4919e-05 - acc: 1.0000\n",
      "Epoch 11/25\n",
      "140/140 [==============================] - 80s 568ms/step - loss: 5.5263e-06 - acc: 1.0000\n",
      "Epoch 12/25\n",
      "140/140 [==============================] - 82s 587ms/step - loss: 6.5877e-06 - acc: 1.0000\n",
      "Epoch 13/25\n",
      "140/140 [==============================] - 80s 574ms/step - loss: 4.4029e-06 - acc: 1.0000\n",
      "Epoch 14/25\n",
      "140/140 [==============================] - 81s 577ms/step - loss: 2.9382e-06 - acc: 1.0000\n",
      "Epoch 15/25\n",
      "140/140 [==============================] - 82s 586ms/step - loss: 9.8440e-06 - acc: 1.0000\n",
      "Epoch 16/25\n",
      "140/140 [==============================] - 83s 591ms/step - loss: 3.2383e-06 - acc: 1.0000\n",
      "Epoch 17/25\n",
      "140/140 [==============================] - 82s 587ms/step - loss: 3.7038e-06 - acc: 1.0000\n",
      "Epoch 18/25\n",
      "140/140 [==============================] - 82s 583ms/step - loss: 2.1814e-06 - acc: 1.0000\n",
      "Epoch 19/25\n",
      "140/140 [==============================] - 82s 583ms/step - loss: 2.4477e-06 - acc: 1.0000\n",
      "Epoch 20/25\n",
      "140/140 [==============================] - 82s 584ms/step - loss: 1.3873e-06 - acc: 1.0000\n",
      "Epoch 21/25\n",
      "140/140 [==============================] - 81s 582ms/step - loss: 2.1938e-06 - acc: 1.0000\n",
      "Epoch 22/25\n",
      "140/140 [==============================] - 82s 583ms/step - loss: 1.1025e-06 - acc: 1.0000\n",
      "Epoch 23/25\n",
      "140/140 [==============================] - 82s 583ms/step - loss: 9.4316e-07 - acc: 1.0000\n",
      "Epoch 24/25\n",
      "140/140 [==============================] - 81s 580ms/step - loss: 1.4621e-06 - acc: 1.0000\n",
      "Epoch 25/25\n",
      "140/140 [==============================] - 82s 583ms/step - loss: 1.8650e-06 - acc: 1.0000\n",
      "Epoch 1/26\n",
      "140/140 [==============================] - 81s 581ms/step - loss: 3.1233e-06 - acc: 1.0000\n",
      "Epoch 2/26\n",
      "140/140 [==============================] - 82s 585ms/step - loss: 9.2446e-07 - acc: 1.0000\n",
      "Epoch 3/26\n",
      "140/140 [==============================] - 82s 582ms/step - loss: 8.5131e-07 - acc: 1.0000\n",
      "Epoch 4/26\n",
      "140/140 [==============================] - 82s 582ms/step - loss: 5.7997e-07 - acc: 1.0000\n",
      "Epoch 5/26\n",
      "140/140 [==============================] - 82s 585ms/step - loss: 2.8415e-06 - acc: 1.0000\n",
      "Epoch 6/26\n",
      "140/140 [==============================] - 82s 583ms/step - loss: 9.2233e-07 - acc: 1.0000\n",
      "Epoch 7/26\n",
      "140/140 [==============================] - 82s 585ms/step - loss: 9.5347e-07 - acc: 1.0000\n",
      "Epoch 8/26\n",
      "140/140 [==============================] - 82s 589ms/step - loss: 8.0474e-07 - acc: 1.0000\n",
      "Epoch 9/26\n",
      "140/140 [==============================] - 81s 580ms/step - loss: 3.8803e-07 - acc: 1.0000\n",
      "Epoch 10/26\n",
      "140/140 [==============================] - 46s 329ms/step - loss: 3.8959e-07 - acc: 1.0000\n",
      "Epoch 11/26\n",
      "140/140 [==============================] - 36s 254ms/step - loss: 1.0542e-06 - acc: 1.0000\n",
      "Epoch 12/26\n",
      "140/140 [==============================] - 35s 253ms/step - loss: 6.8338e-07 - acc: 1.0000\n",
      "Epoch 13/26\n",
      "140/140 [==============================] - 35s 253ms/step - loss: 4.8752e-07 - acc: 1.0000\n",
      "Epoch 14/26\n",
      "140/140 [==============================] - 36s 255ms/step - loss: 4.6876e-07 - acc: 1.0000\n",
      "Epoch 15/26\n",
      "140/140 [==============================] - 35s 253ms/step - loss: 7.8351e-07 - acc: 1.0000\n",
      "Epoch 16/26\n",
      "140/140 [==============================] - 35s 252ms/step - loss: 1.3938e-06 - acc: 1.0000\n",
      "Epoch 17/26\n",
      "140/140 [==============================] - 35s 249ms/step - loss: 6.0287e-07 - acc: 1.0000\n",
      "Epoch 18/26\n",
      "140/140 [==============================] - 35s 252ms/step - loss: 7.9447e-07 - acc: 1.0000\n",
      "Epoch 19/26\n",
      "140/140 [==============================] - 35s 253ms/step - loss: 3.1757e-07 - acc: 1.0000\n",
      "Epoch 20/26\n",
      "140/140 [==============================] - 36s 255ms/step - loss: 2.5098e-07 - acc: 1.0000\n",
      "Epoch 21/26\n",
      "140/140 [==============================] - 35s 252ms/step - loss: 4.8535e-07 - acc: 1.0000\n",
      "Epoch 22/26\n",
      "140/140 [==============================] - 36s 254ms/step - loss: 2.8217e-07 - acc: 1.0000\n",
      "Epoch 23/26\n",
      "140/140 [==============================] - 35s 253ms/step - loss: 2.9968e-07 - acc: 1.0000\n",
      "Epoch 24/26\n",
      "140/140 [==============================] - 36s 255ms/step - loss: 2.3714e-07 - acc: 1.0000\n",
      "Epoch 25/26\n",
      "140/140 [==============================] - 36s 254ms/step - loss: 2.7778e-07 - acc: 1.0000\n",
      "Epoch 26/26\n",
      "140/140 [==============================] - 35s 253ms/step - loss: 1.4871e-07 - acc: 1.0000\n",
      "Epoch 1/27\n",
      "140/140 [==============================] - 36s 254ms/step - loss: 6.2623e-07 - acc: 1.0000\n",
      "Epoch 2/27\n",
      "140/140 [==============================] - 35s 253ms/step - loss: 2.2597e-07 - acc: 1.0000\n",
      "Epoch 3/27\n",
      "140/140 [==============================] - 35s 252ms/step - loss: 1.4833e-07 - acc: 1.0000\n",
      "Epoch 4/27\n",
      "140/140 [==============================] - 35s 253ms/step - loss: 2.9888e-07 - acc: 1.0000\n",
      "Epoch 5/27\n",
      "140/140 [==============================] - 35s 253ms/step - loss: 3.8770e-07 - acc: 1.0000\n",
      "Epoch 6/27\n",
      "140/140 [==============================] - 35s 252ms/step - loss: 1.1499e-07 - acc: 1.0000\n",
      "Epoch 7/27\n",
      "140/140 [==============================] - 36s 254ms/step - loss: 1.1278e-07 - acc: 1.0000\n",
      "Epoch 8/27\n",
      "140/140 [==============================] - 35s 252ms/step - loss: 8.7153e-08 - acc: 1.0000\n",
      "Epoch 9/27\n",
      "140/140 [==============================] - 35s 252ms/step - loss: 1.4866e-07 - acc: 1.0000\n",
      "Epoch 10/27\n",
      "140/140 [==============================] - 35s 254ms/step - loss: 1.0042e-07 - acc: 1.0000\n",
      "Epoch 11/27\n",
      "140/140 [==============================] - 35s 252ms/step - loss: 5.8986e-08 - acc: 1.0000\n",
      "Epoch 12/27\n",
      "140/140 [==============================] - 36s 255ms/step - loss: 1.1988e-07 - acc: 1.0000\n",
      "Epoch 13/27\n",
      "140/140 [==============================] - 35s 253ms/step - loss: 1.0629e-07 - acc: 1.0000\n",
      "Epoch 14/27\n",
      "140/140 [==============================] - 35s 253ms/step - loss: 8.3233e-08 - acc: 1.0000\n",
      "Epoch 15/27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 35s 250ms/step - loss: 1.1617e-07 - acc: 1.0000\n",
      "Epoch 16/27\n",
      "140/140 [==============================] - 35s 249ms/step - loss: 1.6709e-07 - acc: 1.0000\n",
      "Epoch 17/27\n",
      "140/140 [==============================] - 35s 249ms/step - loss: 7.3995e-08 - acc: 1.0000\n",
      "Epoch 18/27\n",
      "140/140 [==============================] - 35s 251ms/step - loss: 1.0064e-07 - acc: 1.0000\n",
      "Epoch 19/27\n",
      "140/140 [==============================] - 35s 250ms/step - loss: 2.1948e-07 - acc: 1.0000\n",
      "Epoch 20/27\n",
      "140/140 [==============================] - 35s 251ms/step - loss: 4.2820e-08 - acc: 1.0000\n",
      "Epoch 21/27\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 2.5561e-08 - acc: 1.0000\n",
      "Epoch 22/27\n",
      "140/140 [==============================] - 35s 250ms/step - loss: 5.2290e-08 - acc: 1.0000\n",
      "Epoch 23/27\n",
      "140/140 [==============================] - 35s 248ms/step - loss: 4.4685e-08 - acc: 1.0000\n",
      "Epoch 24/27\n",
      "140/140 [==============================] - 35s 250ms/step - loss: 3.3373e-08 - acc: 1.0000\n",
      "Epoch 25/27\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 3.7401e-08 - acc: 1.0000\n",
      "Epoch 26/27\n",
      "140/140 [==============================] - 35s 251ms/step - loss: 6.9368e-08 - acc: 1.0000\n",
      "Epoch 27/27\n",
      "140/140 [==============================] - 35s 249ms/step - loss: 1.0618e-07 - acc: 1.0000\n",
      "Epoch 1/28\n",
      "140/140 [==============================] - 35s 250ms/step - loss: 6.7297e-08 - acc: 1.0000\n",
      "Epoch 2/28\n",
      "140/140 [==============================] - 35s 252ms/step - loss: 2.8118e-08 - acc: 1.0000\n",
      "Epoch 3/28\n",
      "140/140 [==============================] - 35s 250ms/step - loss: 1.9086e-08 - acc: 1.0000\n",
      "Epoch 4/28\n",
      "140/140 [==============================] - 35s 250ms/step - loss: 2.3786e-08 - acc: 1.0000\n",
      "Epoch 5/28\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 2.6219e-08 - acc: 1.0000\n",
      "Epoch 6/28\n",
      "140/140 [==============================] - 35s 251ms/step - loss: 2.4993e-08 - acc: 1.0000\n",
      "Epoch 7/28\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 1.5397e-08 - acc: 1.0000\n",
      "Epoch 8/28\n",
      "140/140 [==============================] - 32s 228ms/step - loss: 2.8169e-08 - acc: 1.0000\n",
      "Epoch 9/28\n",
      "140/140 [==============================] - 35s 249ms/step - loss: 2.0772e-08 - acc: 1.0000\n",
      "Epoch 10/28\n",
      "140/140 [==============================] - 35s 251ms/step - loss: 4.5255e-08 - acc: 1.0000\n",
      "Epoch 11/28\n",
      "140/140 [==============================] - 35s 251ms/step - loss: 1.4389e-08 - acc: 1.0000\n",
      "Epoch 12/28\n",
      "140/140 [==============================] - 35s 249ms/step - loss: 1.4482e-08 - acc: 1.0000\n",
      "Epoch 13/28\n",
      "140/140 [==============================] - 35s 250ms/step - loss: 1.6353e-08 - acc: 1.0000\n",
      "Epoch 14/28\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 3.1662e-08 - acc: 1.0000\n",
      "Epoch 15/28\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 1.5221e-08 - acc: 1.0000\n",
      "Epoch 16/28\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 1.8927e-08 - acc: 1.0000\n",
      "Epoch 17/28\n",
      "140/140 [==============================] - 35s 248ms/step - loss: 1.8836e-08 - acc: 1.0000\n",
      "Epoch 18/28\n",
      "140/140 [==============================] - 35s 246ms/step - loss: 1.4701e-08 - acc: 1.0000\n",
      "Epoch 19/28\n",
      "140/140 [==============================] - 35s 251ms/step - loss: 8.8622e-09 - acc: 1.0000\n",
      "Epoch 20/28\n",
      "140/140 [==============================] - 35s 249ms/step - loss: 1.0668e-08 - acc: 1.0000\n",
      "Epoch 21/28\n",
      "140/140 [==============================] - 35s 250ms/step - loss: 7.0417e-09 - acc: 1.0000\n",
      "Epoch 22/28\n",
      "140/140 [==============================] - 35s 250ms/step - loss: 3.6984e-09 - acc: 1.0000\n",
      "Epoch 23/28\n",
      "140/140 [==============================] - 35s 249ms/step - loss: 4.7741e-09 - acc: 1.0000\n",
      "Epoch 24/28\n",
      "140/140 [==============================] - 35s 248ms/step - loss: 5.9241e-08 - acc: 1.0000\n",
      "Epoch 25/28\n",
      "140/140 [==============================] - 35s 250ms/step - loss: 6.6887e-09 - acc: 1.0000\n",
      "Epoch 26/28\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 5.7290e-09 - acc: 1.0000\n",
      "Epoch 27/28\n",
      "140/140 [==============================] - 35s 252ms/step - loss: 7.0622e-09 - acc: 1.0000\n",
      "Epoch 28/28\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 4.4010e-09 - acc: 1.0000\n",
      "Epoch 1/29\n",
      "140/140 [==============================] - 35s 250ms/step - loss: 7.5715e-09 - acc: 1.0000\n",
      "Epoch 2/29\n",
      "140/140 [==============================] - 35s 250ms/step - loss: 5.3730e-09 - acc: 1.0000\n",
      "Epoch 3/29\n",
      "140/140 [==============================] - 35s 248ms/step - loss: 1.6739e-09 - acc: 1.0000\n",
      "Epoch 4/29\n",
      "140/140 [==============================] - 35s 250ms/step - loss: 1.9167e-09 - acc: 1.0000\n",
      "Epoch 5/29\n",
      "140/140 [==============================] - 35s 248ms/step - loss: 2.5123e-09 - acc: 1.0000\n",
      "Epoch 6/29\n",
      "140/140 [==============================] - 35s 250ms/step - loss: 1.7062e-09 - acc: 1.0000\n",
      "Epoch 7/29\n",
      "140/140 [==============================] - 35s 248ms/step - loss: 2.9692e-09 - acc: 1.0000\n",
      "Epoch 8/29\n",
      "140/140 [==============================] - 33s 236ms/step - loss: 2.1417e-09 - acc: 1.0000\n",
      "Epoch 9/29\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 1.8977e-09 - acc: 1.0000\n",
      "Epoch 10/29\n",
      "140/140 [==============================] - 35s 250ms/step - loss: 1.3999e-09 - acc: 1.0000\n",
      "Epoch 11/29\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 1.7991e-09 - acc: 1.0000\n",
      "Epoch 12/29\n",
      "140/140 [==============================] - 35s 249ms/step - loss: 2.1225e-09 - acc: 1.0000\n",
      "Epoch 13/29\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 1.7303e-09 - acc: 1.0000\n",
      "Epoch 14/29\n",
      "140/140 [==============================] - 35s 250ms/step - loss: 3.0330e-09 - acc: 1.0000\n",
      "Epoch 15/29\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 8.2793e-10 - acc: 1.0000\n",
      "Epoch 16/29\n",
      "140/140 [==============================] - 35s 249ms/step - loss: 1.6202e-09 - acc: 1.0000\n",
      "Epoch 17/29\n",
      "140/140 [==============================] - 35s 248ms/step - loss: 1.3838e-09 - acc: 1.0000\n",
      "Epoch 18/29\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 1.7929e-09 - acc: 1.0000\n",
      "Epoch 19/29\n",
      "140/140 [==============================] - 35s 252ms/step - loss: 2.1816e-09 - acc: 1.0000\n",
      "Epoch 20/29\n",
      "140/140 [==============================] - 35s 251ms/step - loss: 2.2507e-09 - acc: 1.0000\n",
      "Epoch 21/29\n",
      "140/140 [==============================] - 35s 249ms/step - loss: 2.6718e-09 - acc: 1.0000\n",
      "Epoch 22/29\n",
      "140/140 [==============================] - 35s 248ms/step - loss: 6.2037e-10 - acc: 1.0000\n",
      "Epoch 23/29\n",
      "140/140 [==============================] - 35s 249ms/step - loss: 7.9394e-10 - acc: 1.0000\n",
      "Epoch 24/29\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 8.2677e-10 - acc: 1.0000\n",
      "Epoch 25/29\n",
      "140/140 [==============================] - 35s 250ms/step - loss: 6.5778e-10 - acc: 1.0000\n",
      "Epoch 26/29\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 3.4106e-09 - acc: 1.0000\n",
      "Epoch 27/29\n",
      "140/140 [==============================] - 35s 250ms/step - loss: 7.3095e-10 - acc: 1.0000\n",
      "Epoch 28/29\n",
      "140/140 [==============================] - 35s 251ms/step - loss: 8.2368e-10 - acc: 1.0000\n",
      "Epoch 29/29\n",
      "140/140 [==============================] - 35s 252ms/step - loss: 9.7026e-10 - acc: 1.0000\n",
      "Epoch 1/30\n",
      "140/140 [==============================] - 35s 250ms/step - loss: 7.3279e-10 - acc: 1.0000\n",
      "Epoch 2/30\n",
      "140/140 [==============================] - 35s 248ms/step - loss: 9.9202e-10 - acc: 1.0000\n",
      "Epoch 3/30\n",
      "140/140 [==============================] - 35s 251ms/step - loss: 6.8124e-10 - acc: 1.0000\n",
      "Epoch 4/30\n",
      "140/140 [==============================] - 35s 250ms/step - loss: 2.2741e-09 - acc: 1.0000\n",
      "Epoch 5/30\n",
      "140/140 [==============================] - 35s 249ms/step - loss: 3.5550e-10 - acc: 1.0000\n",
      "Epoch 6/30\n",
      "140/140 [==============================] - 35s 248ms/step - loss: 7.9026e-10 - acc: 1.0000\n",
      "Epoch 7/30\n",
      "140/140 [==============================] - 35s 251ms/step - loss: 9.0638e-10 - acc: 1.0000\n",
      "Epoch 8/30\n",
      "140/140 [==============================] - 35s 248ms/step - loss: 4.5334e-10 - acc: 1.0000\n",
      "Epoch 9/30\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 8.8505e-10 - acc: 1.0000\n",
      "Epoch 10/30\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 8.4213e-10 - acc: 1.0000\n",
      "Epoch 11/30\n",
      "140/140 [==============================] - 35s 250ms/step - loss: 4.8432e-10 - acc: 1.0000\n",
      "Epoch 12/30\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 6.2433e-10 - acc: 1.0000\n",
      "Epoch 13/30\n",
      "140/140 [==============================] - 35s 251ms/step - loss: 6.3099e-10 - acc: 1.0000\n",
      "Epoch 14/30\n",
      "140/140 [==============================] - 35s 246ms/step - loss: 4.0456e-10 - acc: 1.0000\n",
      "Epoch 15/30\n",
      "140/140 [==============================] - 33s 237ms/step - loss: 6.8540e-10 - acc: 1.0000\n",
      "Epoch 16/30\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 3.3816e-10 - acc: 1.0000\n",
      "Epoch 17/30\n",
      "140/140 [==============================] - 34s 241ms/step - loss: 2.8846e-09 - acc: 1.0000\n",
      "Epoch 18/30\n",
      "140/140 [==============================] - 33s 236ms/step - loss: 4.6323e-09 - acc: 1.0000\n",
      "Epoch 19/30\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 3.9581e-09 - acc: 1.0000\n",
      "Epoch 20/30\n",
      "140/140 [==============================] - 34s 240ms/step - loss: 5.0869e-10 - acc: 1.0000\n",
      "Epoch 21/30\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 3.6149e-09 - acc: 1.0000\n",
      "Epoch 22/30\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 1.7934e-09 - acc: 1.0000\n",
      "Epoch 23/30\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 1.1020e-09 - acc: 1.0000\n",
      "Epoch 24/30\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 9.8935e-11 - acc: 1.0000\n",
      "Epoch 25/30\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 1.4743e-10 - acc: 1.0000\n",
      "Epoch 26/30\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 1.5314e-10 - acc: 1.0000\n",
      "Epoch 27/30\n",
      "140/140 [==============================] - 34s 241ms/step - loss: 1.0813e-10 - acc: 1.0000\n",
      "Epoch 28/30\n",
      "140/140 [==============================] - 31s 223ms/step - loss: 1.3823e-10 - acc: 1.0000\n",
      "Epoch 29/30\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 1.6787e-10 - acc: 1.0000\n",
      "Epoch 30/30\n",
      "140/140 [==============================] - 35s 248ms/step - loss: 1.0911e-10 - acc: 1.0000\n",
      "Epoch 1/31\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 5.2431e-10 - acc: 1.0000\n",
      "Epoch 2/31\n",
      "140/140 [==============================] - 35s 249ms/step - loss: 8.9022e-11 - acc: 1.0000\n",
      "Epoch 3/31\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 2.1621e-10 - acc: 1.0000\n",
      "Epoch 4/31\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 1.3381e-10 - acc: 1.0000\n",
      "Epoch 5/31\n",
      "140/140 [==============================] - 30s 211ms/step - loss: 1.4559e-10 - acc: 1.0000\n",
      "Epoch 6/31\n",
      "140/140 [==============================] - 33s 233ms/step - loss: 9.1237e-11 - acc: 1.0000\n",
      "Epoch 7/31\n",
      "140/140 [==============================] - 32s 230ms/step - loss: 2.2831e-10 - acc: 1.0000\n",
      "Epoch 8/31\n",
      "140/140 [==============================] - 30s 218ms/step - loss: 1.2783e-10 - acc: 1.0000\n",
      "Epoch 9/31\n",
      "140/140 [==============================] - 33s 238ms/step - loss: 7.7199e-11 - acc: 1.0000\n",
      "Epoch 10/31\n",
      "140/140 [==============================] - 35s 248ms/step - loss: 1.1009e-10 - acc: 1.0000\n",
      "Epoch 11/31\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 7.1007e-10 - acc: 1.0000\n",
      "Epoch 12/31\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 9.5639e-11 - acc: 1.0000\n",
      "Epoch 13/31\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 3.3225e-10 - acc: 1.0000\n",
      "Epoch 14/31\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 5.7156e-11 - acc: 1.0000\n",
      "Epoch 15/31\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 7.0660e-11 - acc: 1.0000\n",
      "Epoch 16/31\n",
      "140/140 [==============================] - 35s 249ms/step - loss: 1.8122e-10 - acc: 1.0000\n",
      "Epoch 17/31\n",
      "140/140 [==============================] - 34s 240ms/step - loss: 1.5287e-10 - acc: 1.0000\n",
      "Epoch 18/31\n",
      "140/140 [==============================] - 35s 248ms/step - loss: 1.2371e-10 - acc: 1.0000\n",
      "Epoch 19/31\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 6.9720e-11 - acc: 1.0000\n",
      "Epoch 20/31\n",
      "140/140 [==============================] - 35s 248ms/step - loss: 1.5464e-10 - acc: 1.0000\n",
      "Epoch 21/31\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 9.0023e-11 - acc: 1.0000\n",
      "Epoch 22/31\n",
      "140/140 [==============================] - 35s 248ms/step - loss: 5.0495e-11 - acc: 1.0000\n",
      "Epoch 23/31\n",
      "140/140 [==============================] - 35s 248ms/step - loss: 6.0911e-11 - acc: 1.0000\n",
      "Epoch 24/31\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 4.1246e-11 - acc: 1.0000\n",
      "Epoch 25/31\n",
      "140/140 [==============================] - 35s 249ms/step - loss: 6.1608e-11 - acc: 1.0000\n",
      "Epoch 26/31\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 0.0354 - acc: 0.9936\n",
      "Epoch 27/31\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 0.0066 - acc: 0.9957\n",
      "Epoch 28/31\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 4.7874e-05 - acc: 1.0000\n",
      "Epoch 29/31\n",
      "140/140 [==============================] - 35s 250ms/step - loss: 3.9700e-05 - acc: 1.0000\n",
      "Epoch 30/31\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 1.1453e-05 - acc: 1.0000\n",
      "Epoch 31/31\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 1.8162e-05 - acc: 1.0000\n",
      "Epoch 1/32\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 5.4521e-06 - acc: 1.0000\n",
      "Epoch 2/32\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 8.6427e-06 - acc: 1.0000\n",
      "Epoch 3/32\n",
      "140/140 [==============================] - 34s 239ms/step - loss: 9.0830e-06 - acc: 1.0000\n",
      "Epoch 4/32\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 4.7435e-06 - acc: 1.0000\n",
      "Epoch 5/32\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 4.9401e-06 - acc: 1.0000\n",
      "Epoch 6/32\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 2.0010e-06 - acc: 1.0000\n",
      "Epoch 7/32\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 4.0440e-06 - acc: 1.0000\n",
      "Epoch 8/32\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 5.7886e-06 - acc: 1.0000\n",
      "Epoch 9/32\n",
      "140/140 [==============================] - 34s 241ms/step - loss: 5.5961e-06 - acc: 1.0000\n",
      "Epoch 10/32\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 9.6709e-07 - acc: 1.0000\n",
      "Epoch 11/32\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 2.6066e-06 - acc: 1.0000\n",
      "Epoch 12/32\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 2.0466e-06 - acc: 1.0000\n",
      "Epoch 13/32\n",
      "140/140 [==============================] - 35s 248ms/step - loss: 2.5715e-06 - acc: 1.0000\n",
      "Epoch 14/32\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 1.0736e-06 - acc: 1.0000\n",
      "Epoch 15/32\n",
      "140/140 [==============================] - 35s 248ms/step - loss: 2.1459e-06 - acc: 1.0000\n",
      "Epoch 16/32\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 4.5760e-07 - acc: 1.0000\n",
      "Epoch 17/32\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 1.1894e-06 - acc: 1.0000\n",
      "Epoch 18/32\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 1.6077e-06 - acc: 1.0000\n",
      "Epoch 19/32\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 5.6021e-07 - acc: 1.0000\n",
      "Epoch 20/32\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 1.0092e-06 - acc: 1.0000\n",
      "Epoch 21/32\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 4.5449e-07 - acc: 1.0000\n",
      "Epoch 22/32\n",
      "140/140 [==============================] - 34s 240ms/step - loss: 7.2151e-07 - acc: 1.0000\n",
      "Epoch 23/32\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 8.5632e-07 - acc: 1.0000\n",
      "Epoch 24/32\n",
      "140/140 [==============================] - 32s 231ms/step - loss: 6.8258e-07 - acc: 1.0000\n",
      "Epoch 25/32\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 3.4477e-07 - acc: 1.0000\n",
      "Epoch 26/32\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 5.4165e-07 - acc: 1.0000\n",
      "Epoch 27/32\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 8.5255e-07 - acc: 1.0000\n",
      "Epoch 28/32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 34s 244ms/step - loss: 3.6662e-07 - acc: 1.0000\n",
      "Epoch 29/32\n",
      "140/140 [==============================] - 35s 249ms/step - loss: 7.7416e-07 - acc: 1.0000\n",
      "Epoch 30/32\n",
      "140/140 [==============================] - 33s 239ms/step - loss: 5.9210e-07 - acc: 1.0000\n",
      "Epoch 31/32\n",
      "140/140 [==============================] - 33s 234ms/step - loss: 2.5466e-07 - acc: 1.0000\n",
      "Epoch 32/32\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 2.7044e-07 - acc: 1.0000\n",
      "Epoch 1/33\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 1.7466e-07 - acc: 1.0000\n",
      "Epoch 2/33\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 3.0906e-07 - acc: 1.0000\n",
      "Epoch 3/33\n",
      "140/140 [==============================] - 33s 237ms/step - loss: 3.2122e-07 - acc: 1.0000\n",
      "Epoch 4/33\n",
      "140/140 [==============================] - 35s 248ms/step - loss: 2.3311e-07 - acc: 1.0000\n",
      "Epoch 5/33\n",
      "140/140 [==============================] - 34s 241ms/step - loss: 2.9215e-07 - acc: 1.0000\n",
      "Epoch 6/33\n",
      "140/140 [==============================] - 34s 241ms/step - loss: 3.1695e-07 - acc: 1.0000\n",
      "Epoch 7/33\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 1.5885e-07 - acc: 1.0000\n",
      "Epoch 8/33\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 1.0791e-07 - acc: 1.0000\n",
      "Epoch 9/33\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 1.4742e-07 - acc: 1.0000\n",
      "Epoch 10/33\n",
      "140/140 [==============================] - 34s 241ms/step - loss: 1.5851e-07 - acc: 1.0000\n",
      "Epoch 11/33\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 8.5881e-08 - acc: 1.0000\n",
      "Epoch 12/33\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 2.2460e-07 - acc: 1.0000\n",
      "Epoch 13/33\n",
      "140/140 [==============================] - 34s 240ms/step - loss: 9.3125e-08 - acc: 1.0000\n",
      "Epoch 14/33\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 2.1962e-07 - acc: 1.0000\n",
      "Epoch 15/33\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 3.5161e-07 - acc: 1.0000\n",
      "Epoch 16/33\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 1.4593e-07 - acc: 1.0000\n",
      "Epoch 17/33\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 4.6120e-08 - acc: 1.0000\n",
      "Epoch 18/33\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 4.3059e-06 - acc: 1.0000\n",
      "Epoch 19/33\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 8.6596e-07 - acc: 1.0000\n",
      "Epoch 20/33\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 8.8576e-07 - acc: 1.0000\n",
      "Epoch 21/33\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 3.7931e-07 - acc: 1.0000\n",
      "Epoch 22/33\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 1.3776e-07 - acc: 1.0000\n",
      "Epoch 23/33\n",
      "140/140 [==============================] - 34s 241ms/step - loss: 8.5953e-08 - acc: 1.0000\n",
      "Epoch 24/33\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 2.8790e-08 - acc: 1.0000\n",
      "Epoch 25/33\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 5.3071e-08 - acc: 1.0000\n",
      "Epoch 26/33\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 3.5360e-08 - acc: 1.0000\n",
      "Epoch 27/33\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 6.3234e-08 - acc: 1.0000\n",
      "Epoch 28/33\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 3.6405e-08 - acc: 1.0000\n",
      "Epoch 29/33\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 3.8062e-08 - acc: 1.0000\n",
      "Epoch 30/33\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 1.4451e-07 - acc: 1.0000\n",
      "Epoch 31/33\n",
      "140/140 [==============================] - 35s 249ms/step - loss: 1.7947e-08 - acc: 1.0000\n",
      "Epoch 32/33\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 1.2044e-07 - acc: 1.0000\n",
      "Epoch 33/33\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 9.3391e-08 - acc: 1.0000\n",
      "Epoch 1/34\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 9.4178e-09 - acc: 1.0000\n",
      "Epoch 2/34\n",
      "140/140 [==============================] - 35s 248ms/step - loss: 1.2598e-08 - acc: 1.0000\n",
      "Epoch 3/34\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 5.0622e-08 - acc: 1.0000\n",
      "Epoch 4/34\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 2.9293e-08 - acc: 1.0000\n",
      "Epoch 5/34\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 1.8476e-08 - acc: 1.0000\n",
      "Epoch 6/34\n",
      "140/140 [==============================] - 35s 248ms/step - loss: 2.8614e-08 - acc: 1.0000\n",
      "Epoch 7/34\n",
      "140/140 [==============================] - 34s 241ms/step - loss: 1.0186e-08 - acc: 1.0000\n",
      "Epoch 8/34\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 1.5427e-08 - acc: 1.0000\n",
      "Epoch 9/34\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 6.6213e-09 - acc: 1.0000\n",
      "Epoch 10/34\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 1.9589e-08 - acc: 1.0000\n",
      "Epoch 11/34\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 1.2959e-08 - acc: 1.0000\n",
      "Epoch 12/34\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 3.7400e-09 - acc: 1.0000\n",
      "Epoch 13/34\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 4.1800e-09 - acc: 1.0000\n",
      "Epoch 14/34\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 6.5263e-09 - acc: 1.0000\n",
      "Epoch 15/34\n",
      "140/140 [==============================] - 35s 248ms/step - loss: 1.0378e-08 - acc: 1.0000\n",
      "Epoch 16/34\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 8.9907e-09 - acc: 1.0000\n",
      "Epoch 17/34\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 5.2586e-09 - acc: 1.0000\n",
      "Epoch 18/34\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 6.0321e-09 - acc: 1.0000\n",
      "Epoch 19/34\n",
      "140/140 [==============================] - 35s 249ms/step - loss: 4.9249e-09 - acc: 1.0000\n",
      "Epoch 20/34\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 1.3973e-08 - acc: 1.0000\n",
      "Epoch 21/34\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 6.3644e-09 - acc: 1.0000\n",
      "Epoch 22/34\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 1.6606e-08 - acc: 1.0000\n",
      "Epoch 23/34\n",
      "140/140 [==============================] - 35s 249ms/step - loss: 1.8343e-08 - acc: 1.0000\n",
      "Epoch 24/34\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 2.9802e-09 - acc: 1.0000\n",
      "Epoch 25/34\n",
      "140/140 [==============================] - 35s 252ms/step - loss: 2.2697e-08 - acc: 1.0000\n",
      "Epoch 26/34\n",
      "140/140 [==============================] - 34s 241ms/step - loss: 8.7295e-09 - acc: 1.0000\n",
      "Epoch 27/34\n",
      "140/140 [==============================] - 35s 248ms/step - loss: 2.0838e-09 - acc: 1.0000\n",
      "Epoch 28/34\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 4.1835e-09 - acc: 1.0000\n",
      "Epoch 29/34\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 3.0506e-09 - acc: 1.0000\n",
      "Epoch 30/34\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 4.8651e-09 - acc: 1.0000\n",
      "Epoch 31/34\n",
      "140/140 [==============================] - 35s 248ms/step - loss: 6.8940e-09 - acc: 1.0000\n",
      "Epoch 32/34\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 4.9536e-09 - acc: 1.0000\n",
      "Epoch 33/34\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 1.0506e-09 - acc: 1.0000\n",
      "Epoch 34/34\n",
      "140/140 [==============================] - 34s 240ms/step - loss: 1.5869e-09 - acc: 1.0000\n",
      "Epoch 1/35\n",
      "140/140 [==============================] - 33s 238ms/step - loss: 3.6474e-09 - acc: 1.0000\n",
      "Epoch 2/35\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 2.1406e-09 - acc: 1.0000\n",
      "Epoch 3/35\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 1.1707e-09 - acc: 1.0000\n",
      "Epoch 4/35\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 2.5255e-09 - acc: 1.0000\n",
      "Epoch 5/35\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 1.1301e-09 - acc: 1.0000\n",
      "Epoch 6/35\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 7.0175e-10 - acc: 1.0000\n",
      "Epoch 7/35\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 6.4306e-09 - acc: 1.0000\n",
      "Epoch 8/35\n",
      "140/140 [==============================] - 35s 248ms/step - loss: 2.7298e-09 - acc: 1.0000\n",
      "Epoch 9/35\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 4.4504e-10 - acc: 1.0000\n",
      "Epoch 10/35\n",
      "140/140 [==============================] - 35s 248ms/step - loss: 5.9918e-10 - acc: 1.0000\n",
      "Epoch 11/35\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 1.4280e-09 - acc: 1.0000\n",
      "Epoch 12/35\n",
      "140/140 [==============================] - 35s 246ms/step - loss: 1.3098e-09 - acc: 1.0000\n",
      "Epoch 13/35\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 1.7506e-09 - acc: 1.0000\n",
      "Epoch 14/35\n",
      "140/140 [==============================] - 35s 248ms/step - loss: 7.9304e-10 - acc: 1.0000\n",
      "Epoch 15/35\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 7.5081e-10 - acc: 1.0000\n",
      "Epoch 16/35\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 4.9046e-10 - acc: 1.0000\n",
      "Epoch 17/35\n",
      "140/140 [==============================] - 33s 239ms/step - loss: 6.9507e-10 - acc: 1.0000\n",
      "Epoch 18/35\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 9.3120e-10 - acc: 1.0000\n",
      "Epoch 19/35\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 1.0329e-09 - acc: 1.0000\n",
      "Epoch 20/35\n",
      "140/140 [==============================] - 35s 248ms/step - loss: 1.5086e-09 - acc: 1.0000\n",
      "Epoch 21/35\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 6.0131e-10 - acc: 1.0000\n",
      "Epoch 22/35\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 5.2044e-10 - acc: 1.0000\n",
      "Epoch 23/35\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 5.8185e-10 - acc: 1.0000\n",
      "Epoch 24/35\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 8.2549e-10 - acc: 1.0000\n",
      "Epoch 25/35\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 9.2513e-10 - acc: 1.0000\n",
      "Epoch 26/35\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 3.6465e-09 - acc: 1.0000\n",
      "Epoch 27/35\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 6.8207e-10 - acc: 1.0000\n",
      "Epoch 28/35\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 6.2710e-10 - acc: 1.0000\n",
      "Epoch 29/35\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 7.3371e-10 - acc: 1.0000\n",
      "Epoch 30/35\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 1.9078e-10 - acc: 1.0000\n",
      "Epoch 31/35\n",
      "140/140 [==============================] - 35s 249ms/step - loss: 5.2209e-10 - acc: 1.0000\n",
      "Epoch 32/35\n",
      "140/140 [==============================] - 33s 239ms/step - loss: 2.9311e-10 - acc: 1.0000\n",
      "Epoch 33/35\n",
      "140/140 [==============================] - 35s 246ms/step - loss: 5.5124e-10 - acc: 1.0000\n",
      "Epoch 34/35\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 3.7064e-10 - acc: 1.0000\n",
      "Epoch 35/35\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 1.8342e-10 - acc: 1.0000\n",
      "Epoch 1/36\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 6.0719e-10 - acc: 1.0000\n",
      "Epoch 2/36\n",
      "140/140 [==============================] - 35s 249ms/step - loss: 2.8752e-10 - acc: 1.0000\n",
      "Epoch 3/36\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 1.1391e-10 - acc: 1.0000\n",
      "Epoch 4/36\n",
      "140/140 [==============================] - 35s 248ms/step - loss: 2.0177e-10 - acc: 1.0000\n",
      "Epoch 5/36\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 2.2001e-10 - acc: 1.0000\n",
      "Epoch 6/36\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 1.2227e-10 - acc: 1.0000\n",
      "Epoch 7/36\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 8.5345e-11 - acc: 1.0000\n",
      "Epoch 8/36\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 7.2209e-10 - acc: 1.0000\n",
      "Epoch 9/36\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 3.0348e-10 - acc: 1.0000\n",
      "Epoch 10/36\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 3.1358e-10 - acc: 1.0000\n",
      "Epoch 11/36\n",
      "140/140 [==============================] - 35s 249ms/step - loss: 3.4251e-10 - acc: 1.0000\n",
      "Epoch 12/36\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 2.0660e-10 - acc: 1.0000\n",
      "Epoch 13/36\n",
      "140/140 [==============================] - 34s 247ms/step - loss: 3.3482e-10 - acc: 1.0000\n",
      "Epoch 14/36\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 2.4690e-10 - acc: 1.0000\n",
      "Epoch 15/36\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 3.2075e-10 - acc: 1.0000\n",
      "Epoch 16/36\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 1.7065e-10 - acc: 1.0000\n",
      "Epoch 17/36\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 1.6369e-10 - acc: 1.0000\n",
      "Epoch 18/36\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 9.9015e-10 - acc: 1.0000\n",
      "Epoch 19/36\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 2.0920e-10 - acc: 1.0000\n",
      "Epoch 20/36\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 2.3582e-10 - acc: 1.0000\n",
      "Epoch 21/36\n",
      "140/140 [==============================] - 35s 248ms/step - loss: 1.8732e-09 - acc: 1.0000\n",
      "Epoch 22/36\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 1.0843e-10 - acc: 1.0000\n",
      "Epoch 23/36\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 2.0147e-10 - acc: 1.0000\n",
      "Epoch 24/36\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 1.6794e-10 - acc: 1.0000\n",
      "Epoch 25/36\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 2.0725e-10 - acc: 1.0000\n",
      "Epoch 26/36\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 1.2772e-10 - acc: 1.0000\n",
      "Epoch 27/36\n",
      "140/140 [==============================] - 35s 249ms/step - loss: 1.8444e-10 - acc: 1.0000\n",
      "Epoch 28/36\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 7.6047e-11 - acc: 1.0000\n",
      "Epoch 29/36\n",
      "140/140 [==============================] - 33s 238ms/step - loss: 8.1802e-11 - acc: 1.0000\n",
      "Epoch 30/36\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 6.5621e-11 - acc: 1.0000\n",
      "Epoch 31/36\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 2.0872e-10 - acc: 1.0000\n",
      "Epoch 32/36\n",
      "140/140 [==============================] - 35s 249ms/step - loss: 2.1999e-10 - acc: 1.0000\n",
      "Epoch 33/36\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 7.3823e-11 - acc: 1.0000\n",
      "Epoch 34/36\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 1.6057e-10 - acc: 1.0000\n",
      "Epoch 35/36\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 6.2453e-11 - acc: 1.0000\n",
      "Epoch 36/36\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 5.1873e-11 - acc: 1.0000\n",
      "Epoch 1/37\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 4.7943e-11 - acc: 1.0000\n",
      "Epoch 2/37\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 1.5639e-10 - acc: 1.0000\n",
      "Epoch 3/37\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 1.1340e-10 - acc: 1.0000\n",
      "Epoch 4/37\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 1.1418e-10 - acc: 1.0000\n",
      "Epoch 5/37\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 4.9925e-10 - acc: 1.0000\n",
      "Epoch 6/37\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 3.1671e-11 - acc: 1.0000\n",
      "Epoch 7/37\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 8.9107e-11 - acc: 1.0000\n",
      "Epoch 8/37\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 2.6708e-11 - acc: 1.0000\n",
      "Epoch 9/37\n",
      "140/140 [==============================] - 34s 241ms/step - loss: 4.1742e-11 - acc: 1.0000\n",
      "Epoch 10/37\n",
      "140/140 [==============================] - 33s 237ms/step - loss: 3.1023e-10 - acc: 1.0000\n",
      "Epoch 11/37\n",
      "140/140 [==============================] - 32s 230ms/step - loss: 6.4143e-11 - acc: 1.0000\n",
      "Epoch 12/37\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 1.2633e-10 - acc: 1.0000\n",
      "Epoch 13/37\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 7.3355e-11 - acc: 1.0000\n",
      "Epoch 14/37\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 3.7457e-11 - acc: 1.0000\n",
      "Epoch 15/37\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 9.4773e-11 - acc: 1.0000\n",
      "Epoch 16/37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 35s 248ms/step - loss: 2.2586e-11 - acc: 1.0000\n",
      "Epoch 17/37\n",
      "140/140 [==============================] - 35s 248ms/step - loss: 1.3276e-10 - acc: 1.0000\n",
      "Epoch 18/37\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 9.6479e-11 - acc: 1.0000\n",
      "Epoch 19/37\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 8.1502e-11 - acc: 1.0000\n",
      "Epoch 20/37\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 4.3745e-11 - acc: 1.0000\n",
      "Epoch 21/37\n",
      "140/140 [==============================] - 35s 248ms/step - loss: 3.2979e-11 - acc: 1.0000\n",
      "Epoch 22/37\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 2.4708e-11 - acc: 1.0000\n",
      "Epoch 23/37\n",
      "140/140 [==============================] - 35s 248ms/step - loss: 4.2758e-11 - acc: 1.0000\n",
      "Epoch 24/37\n",
      "140/140 [==============================] - 35s 246ms/step - loss: 5.1866e-11 - acc: 1.0000\n",
      "Epoch 25/37\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 4.3797e-11 - acc: 1.0000\n",
      "Epoch 26/37\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 2.6458e-11 - acc: 1.0000\n",
      "Epoch 27/37\n",
      "140/140 [==============================] - 34s 247ms/step - loss: 1.7463e-10 - acc: 1.0000\n",
      "Epoch 28/37\n",
      "140/140 [==============================] - 34s 241ms/step - loss: 3.4691e-11 - acc: 1.0000\n",
      "Epoch 29/37\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 1.3199e-11 - acc: 1.0000\n",
      "Epoch 30/37\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 9.6166e-11 - acc: 1.0000\n",
      "Epoch 31/37\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 2.9461e-11 - acc: 1.0000\n",
      "Epoch 32/37\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 2.8891e-10 - acc: 1.0000\n",
      "Epoch 33/37\n",
      "140/140 [==============================] - 35s 248ms/step - loss: 3.5441e-11 - acc: 1.0000\n",
      "Epoch 34/37\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 7.7340e-11 - acc: 1.0000\n",
      "Epoch 35/37\n",
      "140/140 [==============================] - 35s 248ms/step - loss: 2.5358e-11 - acc: 1.0000\n",
      "Epoch 36/37\n",
      "140/140 [==============================] - 34s 241ms/step - loss: 7.3015e-11 - acc: 1.0000\n",
      "Epoch 37/37\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 4.5408e-11 - acc: 1.0000\n",
      "Epoch 1/38\n",
      "140/140 [==============================] - 35s 249ms/step - loss: 5.8300e-11 - acc: 1.0000\n",
      "Epoch 2/38\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 1.5866e-11 - acc: 1.0000\n",
      "Epoch 3/38\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 2.9363e-11 - acc: 1.0000\n",
      "Epoch 4/38\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 3.7587e-11 - acc: 1.0000\n",
      "Epoch 5/38\n",
      "140/140 [==============================] - 35s 248ms/step - loss: 3.5582e-11 - acc: 1.0000\n",
      "Epoch 6/38\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 1.9311e-10 - acc: 1.0000\n",
      "Epoch 7/38\n",
      "140/140 [==============================] - 35s 249ms/step - loss: 3.7857e-11 - acc: 1.0000\n",
      "Epoch 8/38\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 5.0027e-11 - acc: 1.0000\n",
      "Epoch 9/38\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 7.1340e-11 - acc: 1.0000\n",
      "Epoch 10/38\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 2.0001e-11 - acc: 1.0000\n",
      "Epoch 11/38\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 2.6196e-11 - acc: 1.0000\n",
      "Epoch 12/38\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 9.0876e-11 - acc: 1.0000\n",
      "Epoch 13/38\n",
      "140/140 [==============================] - 35s 248ms/step - loss: 1.7771e-11 - acc: 1.0000\n",
      "Epoch 14/38\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 2.0977e-11 - acc: 1.0000\n",
      "Epoch 15/38\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 2.2345e-11 - acc: 1.0000\n",
      "Epoch 16/38\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 2.1815e-11 - acc: 1.0000\n",
      "Epoch 17/38\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 8.0790e-11 - acc: 1.0000\n",
      "Epoch 18/38\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 3.3250e-11 - acc: 1.0000\n",
      "Epoch 19/38\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 1.5751e-11 - acc: 1.0000\n",
      "Epoch 20/38\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 2.8832e-11 - acc: 1.0000\n",
      "Epoch 21/38\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 2.5363e-11 - acc: 1.0000\n",
      "Epoch 22/38\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 3.5511e-11 - acc: 1.0000\n",
      "Epoch 23/38\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 4.9714e-11 - acc: 1.0000\n",
      "Epoch 24/38\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 1.2886e-10 - acc: 1.0000\n",
      "Epoch 25/38\n",
      "140/140 [==============================] - 34s 240ms/step - loss: 1.8915e-11 - acc: 1.0000\n",
      "Epoch 26/38\n",
      "140/140 [==============================] - 35s 248ms/step - loss: 3.9708e-11 - acc: 1.0000\n",
      "Epoch 27/38\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 5.7667e-11 - acc: 1.0000\n",
      "Epoch 28/38\n",
      "140/140 [==============================] - 35s 246ms/step - loss: 3.4375e-11 - acc: 1.0000\n",
      "Epoch 29/38\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 3.6434e-11 - acc: 1.0000\n",
      "Epoch 30/38\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 4.4283e-11 - acc: 1.0000\n",
      "Epoch 31/38\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 1.4891e-11 - acc: 1.0000\n",
      "Epoch 32/38\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 2.9345e-11 - acc: 1.0000\n",
      "Epoch 33/38\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 3.2303e-11 - acc: 1.0000\n",
      "Epoch 34/38\n",
      "140/140 [==============================] - 35s 248ms/step - loss: 4.1925e-11 - acc: 1.0000\n",
      "Epoch 35/38\n",
      "140/140 [==============================] - 34s 241ms/step - loss: 1.5938e-11 - acc: 1.0000\n",
      "Epoch 36/38\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 3.6652e-11 - acc: 1.0000\n",
      "Epoch 37/38\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 1.7214e-11 - acc: 1.0000\n",
      "Epoch 38/38\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 4.7724e-11 - acc: 1.0000\n",
      "Epoch 1/39\n",
      "140/140 [==============================] - 35s 246ms/step - loss: 4.0338e-11 - acc: 1.0000\n",
      "Epoch 2/39\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 4.9919e-11 - acc: 1.0000\n",
      "Epoch 3/39\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 6.5932e-11 - acc: 1.0000\n",
      "Epoch 4/39\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 4.3398e-11 - acc: 1.0000\n",
      "Epoch 5/39\n",
      "140/140 [==============================] - 35s 248ms/step - loss: 3.1907e-11 - acc: 1.0000\n",
      "Epoch 6/39\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 2.7786e-11 - acc: 1.0000\n",
      "Epoch 7/39\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 5.6357e-11 - acc: 1.0000\n",
      "Epoch 8/39\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 3.7529e-11 - acc: 1.0000\n",
      "Epoch 9/39\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 2.9075e-10 - acc: 1.0000\n",
      "Epoch 10/39\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 1.2407e-10 - acc: 1.0000\n",
      "Epoch 11/39\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 3.7542e-11 - acc: 1.0000\n",
      "Epoch 12/39\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 3.3768e-11 - acc: 1.0000\n",
      "Epoch 13/39\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 1.1905e-10 - acc: 1.0000\n",
      "Epoch 14/39\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 3.1916e-11 - acc: 1.0000\n",
      "Epoch 15/39\n",
      "140/140 [==============================] - 35s 249ms/step - loss: 8.9456e-11 - acc: 1.0000\n",
      "Epoch 16/39\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 2.3688e-10 - acc: 1.0000\n",
      "Epoch 17/39\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 2.8124e-10 - acc: 1.0000\n",
      "Epoch 18/39\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 1.4762e-11 - acc: 1.0000\n",
      "Epoch 19/39\n",
      "140/140 [==============================] - 35s 248ms/step - loss: 1.0747e-11 - acc: 1.0000\n",
      "Epoch 20/39\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 1.8178e-11 - acc: 1.0000\n",
      "Epoch 21/39\n",
      "140/140 [==============================] - 35s 250ms/step - loss: 4.6911e-11 - acc: 1.0000\n",
      "Epoch 22/39\n",
      "140/140 [==============================] - 34s 241ms/step - loss: 1.1049e-11 - acc: 1.0000\n",
      "Epoch 23/39\n",
      "140/140 [==============================] - 33s 239ms/step - loss: 2.4092e-11 - acc: 1.0000\n",
      "Epoch 24/39\n",
      "140/140 [==============================] - 35s 246ms/step - loss: 3.8063e-11 - acc: 1.0000\n",
      "Epoch 25/39\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 9.8379e-12 - acc: 1.0000\n",
      "Epoch 26/39\n",
      "140/140 [==============================] - 35s 249ms/step - loss: 5.8487e-11 - acc: 1.0000\n",
      "Epoch 27/39\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 1.1054e-11 - acc: 1.0000\n",
      "Epoch 28/39\n",
      "140/140 [==============================] - 35s 250ms/step - loss: 3.5189e-11 - acc: 1.0000\n",
      "Epoch 29/39\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 2.4342e-11 - acc: 1.0000\n",
      "Epoch 30/39\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 1.8383e-11 - acc: 1.0000\n",
      "Epoch 31/39\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 4.6818e-11 - acc: 1.0000\n",
      "Epoch 32/39\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 8.2442e-11 - acc: 1.0000\n",
      "Epoch 33/39\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 2.7582e-11 - acc: 1.0000\n",
      "Epoch 34/39\n",
      "140/140 [==============================] - 35s 248ms/step - loss: 1.0434e-11 - acc: 1.0000\n",
      "Epoch 35/39\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 8.2032e-12 - acc: 1.0000\n",
      "Epoch 36/39\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 7.5527e-12 - acc: 1.0000\n",
      "Epoch 37/39\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 1.5863e-11 - acc: 1.0000\n",
      "Epoch 38/39\n",
      "140/140 [==============================] - 35s 249ms/step - loss: 1.2372e-11 - acc: 1.0000\n",
      "Epoch 39/39\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 4.4893e-11 - acc: 1.0000\n",
      "Epoch 1/40\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 1.9020e-11 - acc: 1.0000\n",
      "Epoch 2/40\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 2.8341e-11 - acc: 1.0000\n",
      "Epoch 3/40\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 2.6747e-11 - acc: 1.0000\n",
      "Epoch 4/40\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 3.3907e-10 - acc: 1.0000\n",
      "Epoch 5/40\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 8.1754e-12 - acc: 1.0000\n",
      "Epoch 6/40\n",
      "140/140 [==============================] - 35s 250ms/step - loss: 4.9435e-11 - acc: 1.0000\n",
      "Epoch 7/40\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 1.1843e-11 - acc: 1.0000\n",
      "Epoch 8/40\n",
      "140/140 [==============================] - 35s 248ms/step - loss: 4.6052e-11 - acc: 1.0000\n",
      "Epoch 9/40\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 2.5483e-11 - acc: 1.0000\n",
      "Epoch 10/40\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 9.9351e-12 - acc: 1.0000\n",
      "Epoch 11/40\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 1.3775e-11 - acc: 1.0000\n",
      "Epoch 12/40\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 4.3024e-11 - acc: 1.0000\n",
      "Epoch 13/40\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 3.3543e-11 - acc: 1.0000\n",
      "Epoch 14/40\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 1.1502e-11 - acc: 1.0000\n",
      "Epoch 15/40\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 1.3766e-11 - acc: 1.0000\n",
      "Epoch 16/40\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 2.8311e-11 - acc: 1.0000\n",
      "Epoch 17/40\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 7.1779e-12 - acc: 1.0000\n",
      "Epoch 18/40\n",
      "140/140 [==============================] - 35s 249ms/step - loss: 9.9675e-11 - acc: 1.0000\n",
      "Epoch 19/40\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 7.5827e-12 - acc: 1.0000\n",
      "Epoch 20/40\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 1.0746e-11 - acc: 1.0000\n",
      "Epoch 21/40\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 9.0898e-12 - acc: 1.0000\n",
      "Epoch 22/40\n",
      "140/140 [==============================] - 33s 234ms/step - loss: 3.8298e-12 - acc: 1.0000\n",
      "Epoch 23/40\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 1.0274e-11 - acc: 1.0000\n",
      "Epoch 24/40\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 1.7770e-11 - acc: 1.0000\n",
      "Epoch 25/40\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 1.8955e-11 - acc: 1.0000\n",
      "Epoch 26/40\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 1.0399e-11 - acc: 1.0000\n",
      "Epoch 27/40\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 2.4855e-11 - acc: 1.0000\n",
      "Epoch 28/40\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 8.8382e-12 - acc: 1.0000\n",
      "Epoch 29/40\n",
      "140/140 [==============================] - 35s 249ms/step - loss: 8.5076e-12 - acc: 1.0000\n",
      "Epoch 30/40\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 1.5202e-10 - acc: 1.0000\n",
      "Epoch 31/40\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 2.5086e-11 - acc: 1.0000\n",
      "Epoch 32/40\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 2.8406e-11 - acc: 1.0000\n",
      "Epoch 33/40\n",
      "140/140 [==============================] - 35s 248ms/step - loss: 2.2186e-11 - acc: 1.0000\n",
      "Epoch 34/40\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 2.5711e-11 - acc: 1.0000\n",
      "Epoch 35/40\n",
      "140/140 [==============================] - 35s 248ms/step - loss: 7.5122e-12 - acc: 1.0000\n",
      "Epoch 36/40\n",
      "140/140 [==============================] - 34s 241ms/step - loss: 1.2993e-11 - acc: 1.0000\n",
      "Epoch 37/40\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 2.3072e-11 - acc: 1.0000\n",
      "Epoch 38/40\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 7.2260e-12 - acc: 1.0000\n",
      "Epoch 39/40\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 2.0293e-11 - acc: 1.0000\n",
      "Epoch 40/40\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 1.7753e-11 - acc: 1.0000\n",
      "Epoch 1/41\n",
      "140/140 [==============================] - 35s 250ms/step - loss: 6.9333e-12 - acc: 1.0000\n",
      "Epoch 2/41\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 1.6234e-11 - acc: 1.0000\n",
      "Epoch 3/41\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 5.0606e-11 - acc: 1.0000\n",
      "Epoch 4/41\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 2.7873e-11 - acc: 1.0000\n",
      "Epoch 5/41\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 1.2914e-11 - acc: 1.0000\n",
      "Epoch 6/41\n",
      "140/140 [==============================] - 35s 248ms/step - loss: 1.9969e-11 - acc: 1.0000\n",
      "Epoch 7/41\n",
      "140/140 [==============================] - 35s 246ms/step - loss: 4.6377e-11 - acc: 1.0000\n",
      "Epoch 8/41\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 3.2515e-11 - acc: 1.0000\n",
      "Epoch 9/41\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 9.6233e-11 - acc: 1.0000\n",
      "Epoch 10/41\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 1.4541e-11 - acc: 1.0000\n",
      "Epoch 11/41\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 6.7388e-11 - acc: 1.0000\n",
      "Epoch 12/41\n",
      "140/140 [==============================] - 35s 248ms/step - loss: 1.0078e-11 - acc: 1.0000\n",
      "Epoch 13/41\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 8.8402e-12 - acc: 1.0000\n",
      "Epoch 14/41\n",
      "140/140 [==============================] - 35s 248ms/step - loss: 3.0357e-12 - acc: 1.0000\n",
      "Epoch 15/41\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 8.7628e-12 - acc: 1.0000\n",
      "Epoch 16/41\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 5.0333e-12 - acc: 1.0000\n",
      "Epoch 17/41\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 4.9082e-12 - acc: 1.0000\n",
      "Epoch 18/41\n",
      "140/140 [==============================] - 35s 249ms/step - loss: 5.4545e-12 - acc: 1.0000\n",
      "Epoch 19/41\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 1.2937e-11 - acc: 1.0000\n",
      "Epoch 20/41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 34s 245ms/step - loss: 6.1589e-12 - acc: 1.0000\n",
      "Epoch 21/41\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 9.8723e-12 - acc: 1.0000\n",
      "Epoch 22/41\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 3.6754e-11 - acc: 1.0000\n",
      "Epoch 23/41\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 9.8064e-12 - acc: 1.0000\n",
      "Epoch 24/41\n",
      "140/140 [==============================] - 35s 248ms/step - loss: 2.0252e-11 - acc: 1.0000\n",
      "Epoch 25/41\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 1.3801e-11 - acc: 1.0000\n",
      "Epoch 26/41\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 3.7403e-12 - acc: 1.0000\n",
      "Epoch 27/41\n",
      "140/140 [==============================] - 35s 248ms/step - loss: 1.6228e-11 - acc: 1.0000\n",
      "Epoch 28/41\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 1.4925e-11 - acc: 1.0000\n",
      "Epoch 29/41\n",
      "140/140 [==============================] - 35s 250ms/step - loss: 2.0141e-11 - acc: 1.0000\n",
      "Epoch 30/41\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 2.5544e-11 - acc: 1.0000\n",
      "Epoch 31/41\n",
      "140/140 [==============================] - 35s 249ms/step - loss: 9.4012e-12 - acc: 1.0000\n",
      "Epoch 32/41\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 1.9911e-11 - acc: 1.0000\n",
      "Epoch 33/41\n",
      "140/140 [==============================] - 35s 249ms/step - loss: 7.3926e-12 - acc: 1.0000\n",
      "Epoch 34/41\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 6.4598e-12 - acc: 1.0000\n",
      "Epoch 35/41\n",
      "140/140 [==============================] - 35s 249ms/step - loss: 1.5448e-11 - acc: 1.0000\n",
      "Epoch 36/41\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 2.3689e-11 - acc: 1.0000\n",
      "Epoch 37/41\n",
      "140/140 [==============================] - 35s 249ms/step - loss: 1.5353e-11 - acc: 1.0000\n",
      "Epoch 38/41\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 7.2867e-12 - acc: 1.0000\n",
      "Epoch 39/41\n",
      "140/140 [==============================] - 35s 249ms/step - loss: 1.8596e-11 - acc: 1.0000\n",
      "Epoch 40/41\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 5.3666e-12 - acc: 1.0000\n",
      "Epoch 41/41\n",
      "140/140 [==============================] - 35s 248ms/step - loss: 3.6239e-11 - acc: 1.0000\n",
      "Epoch 1/42\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 2.7393e-11 - acc: 1.0000\n",
      "Epoch 2/42\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 7.4298e-11 - acc: 1.0000\n",
      "Epoch 3/42\n",
      "140/140 [==============================] - 35s 249ms/step - loss: 3.0200e-11 - acc: 1.0000\n",
      "Epoch 4/42\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 2.8086e-11 - acc: 1.0000\n",
      "Epoch 5/42\n",
      "140/140 [==============================] - 35s 248ms/step - loss: 5.2062e-11 - acc: 1.0000\n",
      "Epoch 6/42\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 8.2916e-12 - acc: 1.0000\n",
      "Epoch 7/42\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 7.7375e-12 - acc: 1.0000\n",
      "Epoch 8/42\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 5.6049e-12 - acc: 1.0000\n",
      "Epoch 9/42\n",
      "140/140 [==============================] - 35s 251ms/step - loss: 1.2902e-11 - acc: 1.0000\n",
      "Epoch 10/42\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 3.4320e-11 - acc: 1.0000\n",
      "Epoch 11/42\n",
      "140/140 [==============================] - 35s 248ms/step - loss: 1.0071e-11 - acc: 1.0000\n",
      "Epoch 12/42\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 3.9412e-12 - acc: 1.0000\n",
      "Epoch 13/42\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 9.1100e-12 - acc: 1.0000\n",
      "Epoch 14/42\n",
      "140/140 [==============================] - 34s 241ms/step - loss: 1.6140e-11 - acc: 1.0000\n",
      "Epoch 15/42\n",
      "140/140 [==============================] - 35s 249ms/step - loss: 6.3183e-11 - acc: 1.0000\n",
      "Epoch 16/42\n",
      "140/140 [==============================] - 33s 236ms/step - loss: 6.2839e-11 - acc: 1.0000\n",
      "Epoch 17/42\n",
      "140/140 [==============================] - 30s 213ms/step - loss: 2.4253e-11 - acc: 1.0000\n",
      "Epoch 18/42\n",
      "140/140 [==============================] - 32s 229ms/step - loss: 4.0105e-12 - acc: 1.0000\n",
      "Epoch 19/42\n",
      "140/140 [==============================] - 33s 236ms/step - loss: 6.4472e-12 - acc: 1.0000\n",
      "Epoch 20/42\n",
      "140/140 [==============================] - 33s 234ms/step - loss: 7.0316e-12 - acc: 1.0000\n",
      "Epoch 21/42\n",
      "140/140 [==============================] - 33s 238ms/step - loss: 1.3323e-10 - acc: 1.0000\n",
      "Epoch 22/42\n",
      "140/140 [==============================] - 32s 228ms/step - loss: 3.8195e-11 - acc: 1.0000\n",
      "Epoch 23/42\n",
      "140/140 [==============================] - 32s 230ms/step - loss: 4.6793e-12 - acc: 1.0000\n",
      "Epoch 24/42\n",
      "140/140 [==============================] - 33s 235ms/step - loss: 9.9638e-12 - acc: 1.0000\n",
      "Epoch 25/42\n",
      "140/140 [==============================] - 33s 232ms/step - loss: 2.6541e-11 - acc: 1.0000\n",
      "Epoch 26/42\n",
      "140/140 [==============================] - 33s 234ms/step - loss: 5.1996e-12 - acc: 1.0000\n",
      "Epoch 27/42\n",
      "140/140 [==============================] - 33s 236ms/step - loss: 3.6917e-12 - acc: 1.0000\n",
      "Epoch 28/42\n",
      "140/140 [==============================] - 32s 229ms/step - loss: 1.2396e-11 - acc: 1.0000\n",
      "Epoch 29/42\n",
      "140/140 [==============================] - 33s 235ms/step - loss: 9.0419e-12 - acc: 1.0000\n",
      "Epoch 30/42\n",
      "140/140 [==============================] - 32s 230ms/step - loss: 3.1171e-11 - acc: 1.0000\n",
      "Epoch 31/42\n",
      "140/140 [==============================] - 33s 235ms/step - loss: 1.2125e-11 - acc: 1.0000\n",
      "Epoch 32/42\n",
      "140/140 [==============================] - 33s 234ms/step - loss: 4.5277e-10 - acc: 1.0000\n",
      "Epoch 33/42\n",
      "140/140 [==============================] - 33s 235ms/step - loss: 9.4236e-12 - acc: 1.0000\n",
      "Epoch 34/42\n",
      "140/140 [==============================] - 33s 234ms/step - loss: 2.4123e-11 - acc: 1.0000\n",
      "Epoch 35/42\n",
      "140/140 [==============================] - 32s 227ms/step - loss: 5.0988e-11 - acc: 1.0000\n",
      "Epoch 36/42\n",
      "140/140 [==============================] - 33s 235ms/step - loss: 6.8407e-12 - acc: 1.0000\n",
      "Epoch 37/42\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 1.6611e-11 - acc: 1.0000\n",
      "Epoch 38/42\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 1.1358e-11 - acc: 1.0000\n",
      "Epoch 39/42\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 1.9584e-11 - acc: 1.0000\n",
      "Epoch 40/42\n",
      "140/140 [==============================] - 34s 241ms/step - loss: 1.5088e-11 - acc: 1.0000\n",
      "Epoch 41/42\n",
      "140/140 [==============================] - 35s 248ms/step - loss: 9.3689e-12 - acc: 1.0000\n",
      "Epoch 42/42\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 9.7385e-12 - acc: 1.0000\n",
      "Epoch 1/43\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 3.2376e-11 - acc: 1.0000\n",
      "Epoch 2/43\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 8.7045e-12 - acc: 1.0000\n",
      "Epoch 3/43\n",
      "140/140 [==============================] - 34s 241ms/step - loss: 2.5100e-11 - acc: 1.0000\n",
      "Epoch 4/43\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 5.6842e-12 - acc: 1.0000\n",
      "Epoch 5/43\n",
      "140/140 [==============================] - 33s 239ms/step - loss: 9.5705e-11 - acc: 1.0000\n",
      "Epoch 6/43\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 4.7585e-12 - acc: 1.0000\n",
      "Epoch 7/43\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 8.7548e-12 - acc: 1.0000\n",
      "Epoch 8/43\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 9.4183e-12 - acc: 1.0000\n",
      "Epoch 9/43\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 1.1729e-11 - acc: 1.0000\n",
      "Epoch 10/43\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 1.5726e-11 - acc: 1.0000\n",
      "Epoch 11/43\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 2.1288e-11 - acc: 1.0000\n",
      "Epoch 12/43\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 6.2278e-12 - acc: 1.0000\n",
      "Epoch 13/43\n",
      "140/140 [==============================] - 34s 241ms/step - loss: 1.0613e-11 - acc: 1.0000\n",
      "Epoch 14/43\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 3.6553e-12 - acc: 1.0000\n",
      "Epoch 15/43\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 2.8350e-11 - acc: 1.0000\n",
      "Epoch 16/43\n",
      "140/140 [==============================] - 35s 249ms/step - loss: 8.9329e-12 - acc: 1.0000\n",
      "Epoch 17/43\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 3.6358e-10 - acc: 1.0000\n",
      "Epoch 18/43\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 8.9201e-11 - acc: 1.0000\n",
      "Epoch 19/43\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 2.6086e-11 - acc: 1.0000\n",
      "Epoch 20/43\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 9.7255e-11 - acc: 1.0000\n",
      "Epoch 21/43\n",
      "140/140 [==============================] - 34s 241ms/step - loss: 7.0412e-10 - acc: 1.0000\n",
      "Epoch 22/43\n",
      "140/140 [==============================] - 35s 248ms/step - loss: 1.3922e-10 - acc: 1.0000\n",
      "Epoch 23/43\n",
      "140/140 [==============================] - 34s 241ms/step - loss: 8.0016e-11 - acc: 1.0000\n",
      "Epoch 24/43\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 1.0089e-10 - acc: 1.0000\n",
      "Epoch 25/43\n",
      "140/140 [==============================] - 34s 241ms/step - loss: 1.5863e-10 - acc: 1.0000\n",
      "Epoch 26/43\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 1.0208e-10 - acc: 1.0000\n",
      "Epoch 27/43\n",
      "140/140 [==============================] - 34s 241ms/step - loss: 7.2917e-11 - acc: 1.0000\n",
      "Epoch 28/43\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 1.7248e-11 - acc: 1.0000\n",
      "Epoch 29/43\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 3.1033e-11 - acc: 1.0000\n",
      "Epoch 30/43\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 1.1828e-11 - acc: 1.0000\n",
      "Epoch 31/43\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 3.2779e-11 - acc: 1.0000\n",
      "Epoch 32/43\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 9.5228e-12 - acc: 1.0000\n",
      "Epoch 33/43\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 3.0246e-11 - acc: 1.0000\n",
      "Epoch 34/43\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 4.1092e-11 - acc: 1.0000\n",
      "Epoch 35/43\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 1.5860e-11 - acc: 1.0000\n",
      "Epoch 36/43\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 6.9873e-12 - acc: 1.0000\n",
      "Epoch 37/43\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 1.6359e-11 - acc: 1.0000\n",
      "Epoch 38/43\n",
      "140/140 [==============================] - 33s 239ms/step - loss: 7.8602e-12 - acc: 1.0000\n",
      "Epoch 39/43\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 3.4542e-11 - acc: 1.0000\n",
      "Epoch 40/43\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 1.6325e-11 - acc: 1.0000\n",
      "Epoch 41/43\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 1.7486e-11 - acc: 1.0000\n",
      "Epoch 42/43\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 3.4663e-11 - acc: 1.0000\n",
      "Epoch 43/43\n",
      "140/140 [==============================] - 35s 248ms/step - loss: 2.1112e-11 - acc: 1.0000\n",
      "Epoch 1/44\n",
      "140/140 [==============================] - 34s 240ms/step - loss: 7.2526e-12 - acc: 1.0000\n",
      "Epoch 2/44\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 2.2405e-11 - acc: 1.0000\n",
      "Epoch 3/44\n",
      "140/140 [==============================] - 34s 241ms/step - loss: 1.6675e-11 - acc: 1.0000\n",
      "Epoch 4/44\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 2.2323e-11 - acc: 1.0000\n",
      "Epoch 5/44\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 1.8379e-11 - acc: 1.0000\n",
      "Epoch 6/44\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 4.2785e-11 - acc: 1.0000\n",
      "Epoch 7/44\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 1.5533e-11 - acc: 1.0000\n",
      "Epoch 8/44\n",
      "140/140 [==============================] - 34s 241ms/step - loss: 6.7189e-12 - acc: 1.0000\n",
      "Epoch 9/44\n",
      "140/140 [==============================] - 32s 227ms/step - loss: 1.6255e-11 - acc: 1.0000\n",
      "Epoch 10/44\n",
      "140/140 [==============================] - 31s 219ms/step - loss: 1.0667e-11 - acc: 1.0000\n",
      "Epoch 11/44\n",
      "140/140 [==============================] - 31s 221ms/step - loss: 9.5215e-12 - acc: 1.0000\n",
      "Epoch 12/44\n",
      "140/140 [==============================] - 32s 227ms/step - loss: 6.3946e-12 - acc: 1.0000\n",
      "Epoch 13/44\n",
      "140/140 [==============================] - 26s 183ms/step - loss: 1.3400e-11 - acc: 1.0000\n",
      "Epoch 14/44\n",
      "140/140 [==============================] - 26s 182ms/step - loss: 1.2074e-11 - acc: 1.0000\n",
      "Epoch 15/44\n",
      "140/140 [==============================] - 29s 207ms/step - loss: 1.0602e-11 - acc: 1.0000\n",
      "Epoch 16/44\n",
      "140/140 [==============================] - 34s 241ms/step - loss: 8.2190e-12 - acc: 1.0000\n",
      "Epoch 17/44\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 9.0519e-12 - acc: 1.0000\n",
      "Epoch 18/44\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 4.3504e-10 - acc: 1.0000\n",
      "Epoch 19/44\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 2.7375e-11 - acc: 1.0000\n",
      "Epoch 20/44\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 8.2534e-12 - acc: 1.0000\n",
      "Epoch 21/44\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 1.5096e-11 - acc: 1.0000\n",
      "Epoch 22/44\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 1.8782e-11 - acc: 1.0000\n",
      "Epoch 23/44\n",
      "140/140 [==============================] - 34s 241ms/step - loss: 1.0038e-11 - acc: 1.0000\n",
      "Epoch 24/44\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 7.8595e-11 - acc: 1.0000\n",
      "Epoch 25/44\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 1.2025e-11 - acc: 1.0000\n",
      "Epoch 26/44\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 7.6270e-11 - acc: 1.0000\n",
      "Epoch 27/44\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 4.0436e-11 - acc: 1.0000\n",
      "Epoch 28/44\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 2.0311e-11 - acc: 1.0000\n",
      "Epoch 29/44\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 1.2684e-11 - acc: 1.0000\n",
      "Epoch 30/44\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 1.0937e-11 - acc: 1.0000\n",
      "Epoch 31/44\n",
      "140/140 [==============================] - 35s 248ms/step - loss: 9.2854e-12 - acc: 1.0000\n",
      "Epoch 32/44\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 7.8005e-12 - acc: 1.0000\n",
      "Epoch 33/44\n",
      "140/140 [==============================] - 34s 247ms/step - loss: 8.3845e-12 - acc: 1.0000\n",
      "Epoch 34/44\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 1.3048e-11 - acc: 1.0000\n",
      "Epoch 35/44\n",
      "140/140 [==============================] - 35s 249ms/step - loss: 8.6355e-12 - acc: 1.0000\n",
      "Epoch 36/44\n",
      "140/140 [==============================] - 34s 244ms/step - loss: 4.1268e-12 - acc: 1.0000\n",
      "Epoch 37/44\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 3.9563e-11 - acc: 1.0000\n",
      "Epoch 38/44\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 6.5924e-12 - acc: 1.0000\n",
      "Epoch 39/44\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 2.4835e-11 - acc: 1.0000\n",
      "Epoch 40/44\n",
      "140/140 [==============================] - 34s 241ms/step - loss: 1.1416e-11 - acc: 1.0000\n",
      "Epoch 41/44\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 5.6836e-12 - acc: 1.0000\n",
      "Epoch 42/44\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 8.2516e-12 - acc: 1.0000\n",
      "Epoch 43/44\n",
      "140/140 [==============================] - 35s 248ms/step - loss: 5.5685e-12 - acc: 1.0000\n",
      "Epoch 44/44\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 6.7496e-12 - acc: 1.0000\n",
      "Epoch 1/45\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 1.3521e-11 - acc: 1.0000\n",
      "Epoch 2/45\n",
      "140/140 [==============================] - 34s 240ms/step - loss: 1.6546e-11 - acc: 1.0000\n",
      "Epoch 3/45\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 1.1929e-11 - acc: 1.0000\n",
      "Epoch 4/45\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 3.4856e-11 - acc: 1.0000\n",
      "Epoch 5/45\n",
      "140/140 [==============================] - 33s 238ms/step - loss: 3.3293e-11 - acc: 1.0000\n",
      "Epoch 6/45\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 8.9647e-12 - acc: 1.0000\n",
      "Epoch 7/45\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 1.0506e-11 - acc: 1.0000\n",
      "Epoch 8/45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 35s 249ms/step - loss: 1.6458e-11 - acc: 1.0000\n",
      "Epoch 9/45\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 6.4714e-12 - acc: 1.0000\n",
      "Epoch 10/45\n",
      "140/140 [==============================] - 35s 249ms/step - loss: 8.4559e-12 - acc: 1.0000\n",
      "Epoch 11/45\n",
      "140/140 [==============================] - 35s 248ms/step - loss: 1.4887e-11 - acc: 1.0000\n",
      "Epoch 12/45\n",
      "140/140 [==============================] - 35s 250ms/step - loss: 2.0447e-11 - acc: 1.0000\n",
      "Epoch 13/45\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 3.4607e-11 - acc: 1.0000\n",
      "Epoch 14/45\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 7.0374e-12 - acc: 1.0000\n",
      "Epoch 15/45\n",
      "140/140 [==============================] - 34s 246ms/step - loss: 1.8855e-11 - acc: 1.0000\n",
      "Epoch 16/45\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 1.3524e-11 - acc: 1.0000\n",
      "Epoch 17/45\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 3.7928e-11 - acc: 1.0000\n",
      "Epoch 18/45\n",
      "140/140 [==============================] - 32s 230ms/step - loss: 6.8785e-12 - acc: 1.0000\n",
      "Epoch 19/45\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 1.6245e-11 - acc: 1.0000\n",
      "Epoch 20/45\n",
      "140/140 [==============================] - 32s 229ms/step - loss: 1.0707e-11 - acc: 1.0000\n",
      "Epoch 21/45\n",
      "140/140 [==============================] - 34s 240ms/step - loss: 1.8695e-11 - acc: 1.0000\n",
      "Epoch 22/45\n",
      "140/140 [==============================] - 38s 273ms/step - loss: 8.1932e-12 - acc: 1.0000\n",
      "Epoch 23/45\n",
      "140/140 [==============================] - 41s 294ms/step - loss: 8.6739e-12 - acc: 1.0000\n",
      "Epoch 24/45\n",
      "140/140 [==============================] - 41s 292ms/step - loss: 1.0232e-11 - acc: 1.0000\n",
      "Epoch 25/45\n",
      "140/140 [==============================] - 42s 300ms/step - loss: 3.8317e-12 - acc: 1.0000\n",
      "Epoch 26/45\n",
      "140/140 [==============================] - 41s 295ms/step - loss: 3.7001e-11 - acc: 1.0000\n",
      "Epoch 27/45\n",
      "140/140 [==============================] - 42s 300ms/step - loss: 1.0992e-11 - acc: 1.0000\n",
      "Epoch 28/45\n",
      "140/140 [==============================] - 41s 297ms/step - loss: 4.3040e-12 - acc: 1.0000\n",
      "Epoch 29/45\n",
      "140/140 [==============================] - 42s 297ms/step - loss: 6.7201e-12 - acc: 1.0000\n",
      "Epoch 30/45\n",
      "140/140 [==============================] - 43s 305ms/step - loss: 6.9663e-12 - acc: 1.0000\n",
      "Epoch 31/45\n",
      "140/140 [==============================] - 42s 301ms/step - loss: 1.1901e-11 - acc: 1.0000\n",
      "Epoch 32/45\n",
      "140/140 [==============================] - 42s 303ms/step - loss: 8.6664e-12 - acc: 1.0000\n",
      "Epoch 33/45\n",
      "140/140 [==============================] - 43s 305ms/step - loss: 5.7265e-12 - acc: 1.0000\n",
      "Epoch 34/45\n",
      "140/140 [==============================] - 42s 299ms/step - loss: 1.4173e-11 - acc: 1.0000\n",
      "Epoch 35/45\n",
      "140/140 [==============================] - 42s 300ms/step - loss: 3.4140e-11 - acc: 1.0000\n",
      "Epoch 36/45\n",
      "140/140 [==============================] - 43s 304ms/step - loss: 1.6164e-11 - acc: 1.0000\n",
      "Epoch 37/45\n",
      "140/140 [==============================] - 42s 299ms/step - loss: 4.0608e-12 - acc: 1.0000\n",
      "Epoch 38/45\n",
      "140/140 [==============================] - 43s 304ms/step - loss: 3.0112e-12 - acc: 1.0000\n",
      "Epoch 39/45\n",
      "140/140 [==============================] - 43s 305ms/step - loss: 2.7935e-11 - acc: 1.0000\n",
      "Epoch 40/45\n",
      "140/140 [==============================] - 42s 297ms/step - loss: 1.6794e-11 - acc: 1.0000\n",
      "Epoch 41/45\n",
      "140/140 [==============================] - 42s 299ms/step - loss: 1.0588e-10 - acc: 1.0000\n",
      "Epoch 42/45\n",
      "140/140 [==============================] - 42s 302ms/step - loss: 2.1414e-11 - acc: 1.0000\n",
      "Epoch 43/45\n",
      "140/140 [==============================] - 42s 299ms/step - loss: 7.8390e-12 - acc: 1.0000\n",
      "Epoch 44/45\n",
      "140/140 [==============================] - 42s 297ms/step - loss: 4.6159e-12 - acc: 1.0000\n",
      "Epoch 45/45\n",
      "140/140 [==============================] - 42s 300ms/step - loss: 5.3714e-12 - acc: 1.0000\n",
      "Epoch 1/46\n",
      "140/140 [==============================] - 42s 299ms/step - loss: 1.1032e-11 - acc: 1.0000\n",
      "Epoch 2/46\n",
      "140/140 [==============================] - 42s 301ms/step - loss: 1.1836e-10 - acc: 1.0000\n",
      "Epoch 3/46\n",
      "140/140 [==============================] - 42s 299ms/step - loss: 5.3157e-12 - acc: 1.0000\n",
      "Epoch 4/46\n",
      "140/140 [==============================] - 42s 300ms/step - loss: 7.6938e-12 - acc: 1.0000\n",
      "Epoch 5/46\n",
      "140/140 [==============================] - 42s 302ms/step - loss: 7.6869e-11 - acc: 1.0000\n",
      "Epoch 6/46\n",
      "140/140 [==============================] - 41s 296ms/step - loss: 6.2156e-12 - acc: 1.0000\n",
      "Epoch 7/46\n",
      "140/140 [==============================] - 42s 297ms/step - loss: 3.8333e-12 - acc: 1.0000\n",
      "Epoch 8/46\n",
      "140/140 [==============================] - 42s 298ms/step - loss: 2.0520e-11 - acc: 1.0000\n",
      "Epoch 9/46\n",
      "140/140 [==============================] - 42s 300ms/step - loss: 4.4671e-12 - acc: 1.0000\n",
      "Epoch 10/46\n",
      "140/140 [==============================] - 42s 297ms/step - loss: 8.8697e-12 - acc: 1.0000\n",
      "Epoch 11/46\n",
      "140/140 [==============================] - 42s 301ms/step - loss: 1.5123e-11 - acc: 1.0000\n",
      "Epoch 12/46\n",
      "140/140 [==============================] - 42s 296ms/step - loss: 7.1253e-12 - acc: 1.0000\n",
      "Epoch 13/46\n",
      "140/140 [==============================] - 42s 298ms/step - loss: 2.3673e-12 - acc: 1.0000\n",
      "Epoch 14/46\n",
      "140/140 [==============================] - 40s 289ms/step - loss: 3.9560e-12 - acc: 1.0000\n",
      "Epoch 15/46\n",
      "140/140 [==============================] - 39s 276ms/step - loss: 2.4948e-11 - acc: 1.0000\n",
      "Epoch 16/46\n",
      "140/140 [==============================] - 41s 291ms/step - loss: 6.3462e-11 - acc: 1.0000\n",
      "Epoch 17/46\n",
      "140/140 [==============================] - 40s 289ms/step - loss: 6.9236e-12 - acc: 1.0000\n",
      "Epoch 18/46\n",
      "140/140 [==============================] - 40s 289ms/step - loss: 3.8274e-12 - acc: 1.0000\n",
      "Epoch 19/46\n",
      "140/140 [==============================] - 42s 299ms/step - loss: 1.4231e-11 - acc: 1.0000\n",
      "Epoch 20/46\n",
      "140/140 [==============================] - 40s 287ms/step - loss: 1.6057e-11 - acc: 1.0000\n",
      "Epoch 21/46\n",
      "140/140 [==============================] - 42s 300ms/step - loss: 1.2005e-11 - acc: 1.0000\n",
      "Epoch 22/46\n",
      "140/140 [==============================] - 29s 209ms/step - loss: 4.5258e-12 - acc: 1.0000\n",
      "Epoch 23/46\n",
      "140/140 [==============================] - 30s 214ms/step - loss: 1.4367e-11 - acc: 1.0000\n",
      "Epoch 24/46\n",
      "140/140 [==============================] - 28s 200ms/step - loss: 8.7459e-12 - acc: 1.0000\n",
      "Epoch 25/46\n",
      "140/140 [==============================] - 29s 210ms/step - loss: 2.6710e-11 - acc: 1.0000\n",
      "Epoch 26/46\n",
      "140/140 [==============================] - 29s 207ms/step - loss: 2.1295e-11 - acc: 1.0000\n",
      "Epoch 27/46\n",
      "140/140 [==============================] - 29s 211ms/step - loss: 5.1985e-12 - acc: 1.0000\n",
      "Epoch 28/46\n",
      "140/140 [==============================] - 29s 210ms/step - loss: 4.1347e-12 - acc: 1.0000\n",
      "Epoch 29/46\n",
      "140/140 [==============================] - 30s 213ms/step - loss: 4.6161e-12 - acc: 1.0000\n",
      "Epoch 30/46\n",
      "140/140 [==============================] - 29s 207ms/step - loss: 2.1069e-11 - acc: 1.0000\n",
      "Epoch 31/46\n",
      "140/140 [==============================] - 29s 207ms/step - loss: 6.8102e-12 - acc: 1.0000\n",
      "Epoch 32/46\n",
      "140/140 [==============================] - 30s 215ms/step - loss: 3.3883e-11 - acc: 1.0000\n",
      "Epoch 33/46\n",
      "140/140 [==============================] - 30s 213ms/step - loss: 1.4212e-11 - acc: 1.0000\n",
      "Epoch 34/46\n",
      "140/140 [==============================] - 30s 214ms/step - loss: 1.2803e-11 - acc: 1.0000\n",
      "Epoch 35/46\n",
      "140/140 [==============================] - 29s 208ms/step - loss: 7.9206e-12 - acc: 1.0000\n",
      "Epoch 36/46\n",
      "140/140 [==============================] - 30s 214ms/step - loss: 9.0250e-12 - acc: 1.0000\n",
      "Epoch 37/46\n",
      "140/140 [==============================] - 30s 211ms/step - loss: 2.5359e-12 - acc: 1.0000\n",
      "Epoch 38/46\n",
      "140/140 [==============================] - 30s 216ms/step - loss: 1.1750e-11 - acc: 1.0000\n",
      "Epoch 39/46\n",
      "140/140 [==============================] - 30s 214ms/step - loss: 2.4062e-12 - acc: 1.0000\n",
      "Epoch 40/46\n",
      "140/140 [==============================] - 29s 210ms/step - loss: 1.2564e-11 - acc: 1.0000\n",
      "Epoch 41/46\n",
      "140/140 [==============================] - 29s 209ms/step - loss: 6.3135e-12 - acc: 1.0000\n",
      "Epoch 42/46\n",
      "140/140 [==============================] - 28s 203ms/step - loss: 6.4800e-12 - acc: 1.0000\n",
      "Epoch 43/46\n",
      "140/140 [==============================] - 29s 205ms/step - loss: 8.7529e-12 - acc: 1.0000\n",
      "Epoch 44/46\n",
      "140/140 [==============================] - 30s 211ms/step - loss: 7.6247e-12 - acc: 1.0000\n",
      "Epoch 45/46\n",
      "140/140 [==============================] - 30s 216ms/step - loss: 9.2773e-12 - acc: 1.0000\n",
      "Epoch 46/46\n",
      "140/140 [==============================] - 30s 215ms/step - loss: 1.8003e-11 - acc: 1.0000\n",
      "Epoch 1/47\n",
      "140/140 [==============================] - 30s 211ms/step - loss: 1.4042e-11 - acc: 1.0000\n",
      "Epoch 2/47\n",
      "140/140 [==============================] - 29s 208ms/step - loss: 7.4316e-12 - acc: 1.0000\n",
      "Epoch 3/47\n",
      "140/140 [==============================] - 29s 205ms/step - loss: 2.5699e-11 - acc: 1.0000\n",
      "Epoch 4/47\n",
      "140/140 [==============================] - 29s 206ms/step - loss: 1.6209e-11 - acc: 1.0000\n",
      "Epoch 5/47\n",
      "140/140 [==============================] - 29s 205ms/step - loss: 2.0711e-12 - acc: 1.0000\n",
      "Epoch 6/47\n",
      "140/140 [==============================] - 28s 203ms/step - loss: 1.5306e-11 - acc: 1.0000\n",
      "Epoch 7/47\n",
      "140/140 [==============================] - 29s 206ms/step - loss: 5.7518e-12 - acc: 1.0000\n",
      "Epoch 8/47\n",
      "140/140 [==============================] - 30s 212ms/step - loss: 5.3645e-11 - acc: 1.0000\n",
      "Epoch 9/47\n",
      "140/140 [==============================] - 29s 204ms/step - loss: 6.7672e-12 - acc: 1.0000\n",
      "Epoch 10/47\n",
      "140/140 [==============================] - 29s 209ms/step - loss: 8.2952e-12 - acc: 1.0000\n",
      "Epoch 11/47\n",
      "140/140 [==============================] - 30s 211ms/step - loss: 8.9898e-12 - acc: 1.0000\n",
      "Epoch 12/47\n",
      "140/140 [==============================] - 28s 202ms/step - loss: 3.1378e-11 - acc: 1.0000\n",
      "Epoch 13/47\n",
      "140/140 [==============================] - 30s 211ms/step - loss: 9.1841e-12 - acc: 1.0000\n",
      "Epoch 14/47\n",
      "140/140 [==============================] - 29s 208ms/step - loss: 3.8319e-12 - acc: 1.0000\n",
      "Epoch 15/47\n",
      "140/140 [==============================] - 30s 213ms/step - loss: 4.6610e-12 - acc: 1.0000\n",
      "Epoch 16/47\n",
      "140/140 [==============================] - 30s 212ms/step - loss: 4.4244e-12 - acc: 1.0000\n",
      "Epoch 17/47\n",
      "140/140 [==============================] - 29s 207ms/step - loss: 5.0842e-12 - acc: 1.0000\n",
      "Epoch 18/47\n",
      "140/140 [==============================] - 30s 212ms/step - loss: 1.6566e-11 - acc: 1.0000\n",
      "Epoch 19/47\n",
      "140/140 [==============================] - 29s 210ms/step - loss: 4.8155e-12 - acc: 1.0000\n",
      "Epoch 20/47\n",
      "140/140 [==============================] - 29s 210ms/step - loss: 7.0961e-12 - acc: 1.0000\n",
      "Epoch 21/47\n",
      "140/140 [==============================] - 29s 207ms/step - loss: 1.6396e-11 - acc: 1.0000\n",
      "Epoch 22/47\n",
      "140/140 [==============================] - 30s 218ms/step - loss: 5.6627e-12 - acc: 1.0000\n",
      "Epoch 23/47\n",
      "140/140 [==============================] - 30s 217ms/step - loss: 7.5710e-12 - acc: 1.0000\n",
      "Epoch 24/47\n",
      "140/140 [==============================] - 30s 214ms/step - loss: 4.0578e-12 - acc: 1.0000\n",
      "Epoch 25/47\n",
      "140/140 [==============================] - 29s 209ms/step - loss: 4.6417e-12 - acc: 1.0000\n",
      "Epoch 26/47\n",
      "140/140 [==============================] - 29s 206ms/step - loss: 2.5718e-11 - acc: 1.0000\n",
      "Epoch 27/47\n",
      "140/140 [==============================] - 29s 207ms/step - loss: 1.3130e-11 - acc: 1.0000\n",
      "Epoch 28/47\n",
      "140/140 [==============================] - 30s 217ms/step - loss: 6.3841e-12 - acc: 1.0000\n",
      "Epoch 29/47\n",
      "140/140 [==============================] - 29s 209ms/step - loss: 6.7065e-12 - acc: 1.0000\n",
      "Epoch 30/47\n",
      "140/140 [==============================] - 30s 215ms/step - loss: 3.9627e-12 - acc: 1.0000\n",
      "Epoch 31/47\n",
      "140/140 [==============================] - 28s 203ms/step - loss: 1.0031e-11 - acc: 1.0000\n",
      "Epoch 32/47\n",
      "140/140 [==============================] - 29s 207ms/step - loss: 1.0022e-11 - acc: 1.0000\n",
      "Epoch 33/47\n",
      "140/140 [==============================] - 28s 200ms/step - loss: 5.0807e-12 - acc: 1.0000\n",
      "Epoch 34/47\n",
      "140/140 [==============================] - 28s 202ms/step - loss: 1.0724e-11 - acc: 1.0000\n",
      "Epoch 35/47\n",
      "140/140 [==============================] - 30s 211ms/step - loss: 6.3108e-12 - acc: 1.0000\n",
      "Epoch 36/47\n",
      "140/140 [==============================] - 29s 205ms/step - loss: 7.0681e-12 - acc: 1.0000\n",
      "Epoch 37/47\n",
      "140/140 [==============================] - 29s 206ms/step - loss: 1.5771e-11 - acc: 1.0000\n",
      "Epoch 38/47\n",
      "140/140 [==============================] - 29s 204ms/step - loss: 9.1171e-12 - acc: 1.0000\n",
      "Epoch 39/47\n",
      "140/140 [==============================] - 28s 203ms/step - loss: 9.9741e-12 - acc: 1.0000\n",
      "Epoch 40/47\n",
      "140/140 [==============================] - 29s 204ms/step - loss: 5.6387e-12 - acc: 1.0000\n",
      "Epoch 41/47\n",
      "140/140 [==============================] - 29s 209ms/step - loss: 1.9045e-11 - acc: 1.0000\n",
      "Epoch 42/47\n",
      "140/140 [==============================] - 30s 213ms/step - loss: 1.0665e-11 - acc: 1.0000\n",
      "Epoch 43/47\n",
      "140/140 [==============================] - 28s 203ms/step - loss: 6.5784e-12 - acc: 1.0000\n",
      "Epoch 44/47\n",
      "140/140 [==============================] - 30s 212ms/step - loss: 4.7095e-12 - acc: 1.0000\n",
      "Epoch 45/47\n",
      "140/140 [==============================] - 29s 209ms/step - loss: 6.8671e-12 - acc: 1.0000\n",
      "Epoch 46/47\n",
      "140/140 [==============================] - 30s 216ms/step - loss: 8.4979e-12 - acc: 1.0000\n",
      "Epoch 47/47\n",
      "140/140 [==============================] - 29s 209ms/step - loss: 2.3687e-12 - acc: 1.0000\n",
      "Epoch 1/48\n",
      "140/140 [==============================] - 30s 213ms/step - loss: 6.0156e-12 - acc: 1.0000\n",
      "Epoch 2/48\n",
      "140/140 [==============================] - 29s 206ms/step - loss: 5.9924e-12 - acc: 1.0000\n",
      "Epoch 3/48\n",
      "140/140 [==============================] - 29s 208ms/step - loss: 1.4163e-11 - acc: 1.0000\n",
      "Epoch 4/48\n",
      "140/140 [==============================] - 29s 206ms/step - loss: 1.0882e-11 - acc: 1.0000\n",
      "Epoch 5/48\n",
      "140/140 [==============================] - 29s 204ms/step - loss: 5.0191e-12 - acc: 1.0000\n",
      "Epoch 6/48\n",
      "140/140 [==============================] - 30s 211ms/step - loss: 1.7371e-11 - acc: 1.0000\n",
      "Epoch 7/48\n",
      "140/140 [==============================] - 29s 207ms/step - loss: 1.4097e-11 - acc: 1.0000\n",
      "Epoch 8/48\n",
      "140/140 [==============================] - 29s 206ms/step - loss: 1.4569e-11 - acc: 1.0000\n",
      "Epoch 9/48\n",
      "140/140 [==============================] - 29s 208ms/step - loss: 7.8565e-12 - acc: 1.0000\n",
      "Epoch 10/48\n",
      "140/140 [==============================] - 29s 207ms/step - loss: 7.4218e-12 - acc: 1.0000\n",
      "Epoch 11/48\n",
      "140/140 [==============================] - 29s 205ms/step - loss: 1.5656e-11 - acc: 1.0000\n",
      "Epoch 12/48\n",
      "140/140 [==============================] - 29s 210ms/step - loss: 1.2632e-11 - acc: 1.0000\n",
      "Epoch 13/48\n",
      "140/140 [==============================] - 29s 208ms/step - loss: 2.3310e-12 - acc: 1.0000\n",
      "Epoch 14/48\n",
      "140/140 [==============================] - 29s 206ms/step - loss: 1.1236e-11 - acc: 1.0000\n",
      "Epoch 15/48\n",
      "140/140 [==============================] - 29s 205ms/step - loss: 8.2108e-12 - acc: 1.0000\n",
      "Epoch 16/48\n",
      "140/140 [==============================] - 29s 207ms/step - loss: 3.8002e-11 - acc: 1.0000\n",
      "Epoch 17/48\n",
      "140/140 [==============================] - 29s 205ms/step - loss: 1.0731e-11 - acc: 1.0000\n",
      "Epoch 18/48\n",
      "140/140 [==============================] - 29s 207ms/step - loss: 6.1937e-12 - acc: 1.0000\n",
      "Epoch 19/48\n",
      "140/140 [==============================] - 29s 209ms/step - loss: 8.6275e-12 - acc: 1.0000\n",
      "Epoch 20/48\n",
      "140/140 [==============================] - 29s 205ms/step - loss: 4.3409e-12 - acc: 1.0000\n",
      "Epoch 21/48\n",
      "140/140 [==============================] - 29s 210ms/step - loss: 9.2883e-12 - acc: 1.0000\n",
      "Epoch 22/48\n",
      "140/140 [==============================] - 28s 203ms/step - loss: 7.0401e-12 - acc: 1.0000\n",
      "Epoch 23/48\n",
      "140/140 [==============================] - 29s 206ms/step - loss: 3.5633e-12 - acc: 1.0000\n",
      "Epoch 24/48\n",
      "140/140 [==============================] - 30s 213ms/step - loss: 9.7540e-12 - acc: 1.0000\n",
      "Epoch 25/48\n",
      "140/140 [==============================] - 29s 207ms/step - loss: 4.3514e-11 - acc: 1.0000\n",
      "Epoch 26/48\n",
      "140/140 [==============================] - 29s 208ms/step - loss: 6.2533e-12 - acc: 1.0000\n",
      "Epoch 27/48\n",
      "140/140 [==============================] - 30s 212ms/step - loss: 8.2736e-11 - acc: 1.0000\n",
      "Epoch 28/48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 29s 205ms/step - loss: 9.3235e-12 - acc: 1.0000\n",
      "Epoch 29/48\n",
      "140/140 [==============================] - 29s 210ms/step - loss: 1.8286e-11 - acc: 1.0000\n",
      "Epoch 30/48\n",
      "140/140 [==============================] - 29s 208ms/step - loss: 4.1259e-12 - acc: 1.0000\n",
      "Epoch 31/48\n",
      "140/140 [==============================] - 30s 214ms/step - loss: 1.4042e-11 - acc: 1.0000\n",
      "Epoch 32/48\n",
      "140/140 [==============================] - 29s 210ms/step - loss: 2.8361e-11 - acc: 1.0000\n",
      "Epoch 33/48\n",
      "140/140 [==============================] - 29s 205ms/step - loss: 1.3612e-11 - acc: 1.0000\n",
      "Epoch 34/48\n",
      "140/140 [==============================] - 30s 211ms/step - loss: 2.3155e-12 - acc: 1.0000\n",
      "Epoch 35/48\n",
      "140/140 [==============================] - 30s 211ms/step - loss: 3.0988e-12 - acc: 1.0000\n",
      "Epoch 36/48\n",
      "140/140 [==============================] - 30s 218ms/step - loss: 7.4606e-12 - acc: 1.0000\n",
      "Epoch 37/48\n",
      "140/140 [==============================] - 26s 182ms/step - loss: 4.5923e-12 - acc: 1.0000\n",
      "Epoch 38/48\n",
      "140/140 [==============================] - 25s 179ms/step - loss: 4.0565e-12 - acc: 1.0000\n",
      "Epoch 39/48\n",
      "140/140 [==============================] - 26s 183ms/step - loss: 7.7423e-12 - acc: 1.0000\n",
      "Epoch 40/48\n",
      "140/140 [==============================] - 25s 179ms/step - loss: 4.7469e-12 - acc: 1.0000\n",
      "Epoch 41/48\n",
      "140/140 [==============================] - 25s 178ms/step - loss: 1.0560e-11 - acc: 1.0000\n",
      "Epoch 42/48\n",
      "140/140 [==============================] - 26s 183ms/step - loss: 5.1797e-12 - acc: 1.0000\n",
      "Epoch 43/48\n",
      "140/140 [==============================] - 26s 185ms/step - loss: 2.5429e-12 - acc: 1.0000\n",
      "Epoch 44/48\n",
      "140/140 [==============================] - 25s 181ms/step - loss: 4.4135e-12 - acc: 1.0000\n",
      "Epoch 45/48\n",
      "140/140 [==============================] - 25s 180ms/step - loss: 5.6558e-12 - acc: 1.0000\n",
      "Epoch 46/48\n",
      "140/140 [==============================] - 25s 178ms/step - loss: 4.0642e-12 - acc: 1.0000\n",
      "Epoch 47/48\n",
      "140/140 [==============================] - 26s 183ms/step - loss: 2.9174e-12 - acc: 1.0000\n",
      "Epoch 48/48\n",
      "140/140 [==============================] - 25s 182ms/step - loss: 1.5975e-11 - acc: 1.0000\n",
      "Epoch 1/49\n",
      "140/140 [==============================] - 24s 174ms/step - loss: 3.4168e-12 - acc: 1.0000\n",
      "Epoch 2/49\n",
      "140/140 [==============================] - 25s 182ms/step - loss: 1.1572e-11 - acc: 1.0000\n",
      "Epoch 3/49\n",
      "140/140 [==============================] - 25s 178ms/step - loss: 6.8107e-12 - acc: 1.0000\n",
      "Epoch 4/49\n",
      "140/140 [==============================] - 25s 182ms/step - loss: 4.1045e-12 - acc: 1.0000\n",
      "Epoch 5/49\n",
      "140/140 [==============================] - 25s 179ms/step - loss: 1.7974e-12 - acc: 1.0000\n",
      "Epoch 6/49\n",
      "140/140 [==============================] - 25s 178ms/step - loss: 1.9992e-11 - acc: 1.0000\n",
      "Epoch 7/49\n",
      "140/140 [==============================] - 25s 182ms/step - loss: 6.5282e-12 - acc: 1.0000\n",
      "Epoch 8/49\n",
      "140/140 [==============================] - 25s 178ms/step - loss: 5.8617e-11 - acc: 1.0000\n",
      "Epoch 9/49\n",
      "140/140 [==============================] - 25s 181ms/step - loss: 2.6372e-12 - acc: 1.0000\n",
      "Epoch 10/49\n",
      "140/140 [==============================] - 25s 178ms/step - loss: 1.7232e-12 - acc: 1.0000\n",
      "Epoch 11/49\n",
      "140/140 [==============================] - 25s 177ms/step - loss: 8.2132e-12 - acc: 1.0000\n",
      "Epoch 12/49\n",
      "140/140 [==============================] - 25s 179ms/step - loss: 8.9567e-12 - acc: 1.0000\n",
      "Epoch 13/49\n",
      "140/140 [==============================] - 28s 197ms/step - loss: 7.8166e-12 - acc: 1.0000\n",
      "Epoch 14/49\n",
      "140/140 [==============================] - 30s 212ms/step - loss: 2.7418e-12 - acc: 1.0000\n",
      "Epoch 15/49\n",
      "140/140 [==============================] - 29s 210ms/step - loss: 2.7700e-12 - acc: 1.0000\n",
      "Epoch 16/49\n",
      "140/140 [==============================] - 30s 214ms/step - loss: 4.5692e-12 - acc: 1.0000\n",
      "Epoch 17/49\n",
      "140/140 [==============================] - 29s 210ms/step - loss: 3.6543e-12 - acc: 1.0000\n",
      "Epoch 18/49\n",
      "140/140 [==============================] - 30s 216ms/step - loss: 5.0386e-12 - acc: 1.0000\n",
      "Epoch 19/49\n",
      "140/140 [==============================] - 30s 213ms/step - loss: 3.9846e-12 - acc: 1.0000\n",
      "Epoch 20/49\n",
      "140/140 [==============================] - 31s 219ms/step - loss: 7.6252e-12 - acc: 1.0000\n",
      "Epoch 21/49\n",
      "140/140 [==============================] - 30s 211ms/step - loss: 2.4442e-11 - acc: 1.0000\n",
      "Epoch 22/49\n",
      "140/140 [==============================] - 29s 209ms/step - loss: 5.5618e-12 - acc: 1.0000\n",
      "Epoch 23/49\n",
      "140/140 [==============================] - 30s 211ms/step - loss: 8.7995e-12 - acc: 1.0000\n",
      "Epoch 24/49\n",
      "140/140 [==============================] - 29s 209ms/step - loss: 2.4180e-12 - acc: 1.0000\n",
      "Epoch 25/49\n",
      "140/140 [==============================] - 29s 205ms/step - loss: 1.8888e-11 - acc: 1.0000\n",
      "Epoch 26/49\n",
      "140/140 [==============================] - 29s 207ms/step - loss: 2.8524e-12 - acc: 1.0000\n",
      "Epoch 27/49\n",
      "140/140 [==============================] - 30s 212ms/step - loss: 4.9561e-12 - acc: 1.0000\n",
      "Epoch 28/49\n",
      "140/140 [==============================] - 30s 215ms/step - loss: 3.2809e-12 - acc: 1.0000\n",
      "Epoch 29/49\n",
      "140/140 [==============================] - 29s 207ms/step - loss: 3.6734e-12 - acc: 1.0000\n",
      "Epoch 30/49\n",
      "140/140 [==============================] - 30s 213ms/step - loss: 3.1615e-11 - acc: 1.0000\n",
      "Epoch 31/49\n",
      "140/140 [==============================] - 30s 211ms/step - loss: 5.5596e-12 - acc: 1.0000\n",
      "Epoch 32/49\n",
      "140/140 [==============================] - 29s 206ms/step - loss: 1.9742e-11 - acc: 1.0000\n",
      "Epoch 33/49\n",
      "140/140 [==============================] - 29s 210ms/step - loss: 2.5508e-12 - acc: 1.0000\n",
      "Epoch 34/49\n",
      "140/140 [==============================] - 29s 210ms/step - loss: 1.0877e-11 - acc: 1.0000\n",
      "Epoch 35/49\n",
      "140/140 [==============================] - 29s 210ms/step - loss: 5.5385e-12 - acc: 1.0000\n",
      "Epoch 36/49\n",
      "140/140 [==============================] - 30s 211ms/step - loss: 7.8406e-12 - acc: 1.0000\n",
      "Epoch 37/49\n",
      "140/140 [==============================] - 30s 211ms/step - loss: 3.3552e-12 - acc: 1.0000\n",
      "Epoch 38/49\n",
      "140/140 [==============================] - 29s 208ms/step - loss: 8.2686e-12 - acc: 1.0000\n",
      "Epoch 39/49\n",
      "140/140 [==============================] - 29s 205ms/step - loss: 5.4778e-12 - acc: 1.0000\n",
      "Epoch 40/49\n",
      "140/140 [==============================] - 30s 214ms/step - loss: 9.3337e-12 - acc: 1.0000\n",
      "Epoch 41/49\n",
      "140/140 [==============================] - 29s 207ms/step - loss: 8.4498e-12 - acc: 1.0000\n",
      "Epoch 42/49\n",
      "140/140 [==============================] - 30s 211ms/step - loss: 1.3383e-11 - acc: 1.0000\n",
      "Epoch 43/49\n",
      "140/140 [==============================] - 29s 209ms/step - loss: 9.9661e-12 - acc: 1.0000\n",
      "Epoch 44/49\n",
      "140/140 [==============================] - 29s 205ms/step - loss: 1.0479e-11 - acc: 1.0000\n",
      "Epoch 45/49\n",
      "140/140 [==============================] - 30s 213ms/step - loss: 4.7925e-12 - acc: 1.0000\n",
      "Epoch 46/49\n",
      "140/140 [==============================] - 29s 208ms/step - loss: 7.4100e-12 - acc: 1.0000\n",
      "Epoch 47/49\n",
      "140/140 [==============================] - 29s 209ms/step - loss: 6.6366e-12 - acc: 1.0000\n",
      "Epoch 48/49\n",
      "140/140 [==============================] - 30s 212ms/step - loss: 4.9108e-12 - acc: 1.0000\n",
      "Epoch 49/49\n",
      "140/140 [==============================] - 31s 218ms/step - loss: 7.1146e-12 - acc: 1.0000\n",
      "Epoch 1/50\n",
      "140/140 [==============================] - 29s 210ms/step - loss: 8.0342e-12 - acc: 1.0000\n",
      "Epoch 2/50\n",
      "140/140 [==============================] - 29s 209ms/step - loss: 5.3360e-12 - acc: 1.0000\n",
      "Epoch 3/50\n",
      "140/140 [==============================] - 29s 209ms/step - loss: 2.7069e-11 - acc: 1.0000\n",
      "Epoch 4/50\n",
      "140/140 [==============================] - 30s 217ms/step - loss: 5.3378e-12 - acc: 1.0000\n",
      "Epoch 5/50\n",
      "140/140 [==============================] - 29s 211ms/step - loss: 2.9420e-11 - acc: 1.0000\n",
      "Epoch 6/50\n",
      "140/140 [==============================] - 30s 212ms/step - loss: 3.3289e-11 - acc: 1.0000\n",
      "Epoch 7/50\n",
      "140/140 [==============================] - 30s 213ms/step - loss: 5.4666e-12 - acc: 1.0000\n",
      "Epoch 8/50\n",
      "140/140 [==============================] - 29s 204ms/step - loss: 3.9411e-12 - acc: 1.0000\n",
      "Epoch 9/50\n",
      "140/140 [==============================] - 29s 209ms/step - loss: 1.3375e-12 - acc: 1.0000\n",
      "Epoch 10/50\n",
      "140/140 [==============================] - 30s 212ms/step - loss: 2.4520e-12 - acc: 1.0000\n",
      "Epoch 11/50\n",
      "140/140 [==============================] - 30s 217ms/step - loss: 6.1555e-12 - acc: 1.0000\n",
      "Epoch 12/50\n",
      "140/140 [==============================] - 30s 213ms/step - loss: 8.5028e-12 - acc: 1.0000\n",
      "Epoch 13/50\n",
      "140/140 [==============================] - 29s 209ms/step - loss: 7.0654e-12 - acc: 1.0000\n",
      "Epoch 14/50\n",
      "140/140 [==============================] - 30s 212ms/step - loss: 6.0840e-12 - acc: 1.0000\n",
      "Epoch 15/50\n",
      "140/140 [==============================] - 29s 204ms/step - loss: 8.5607e-12 - acc: 1.0000\n",
      "Epoch 16/50\n",
      "140/140 [==============================] - 30s 212ms/step - loss: 8.0992e-12 - acc: 1.0000\n",
      "Epoch 17/50\n",
      "140/140 [==============================] - 29s 206ms/step - loss: 8.0954e-12 - acc: 1.0000\n",
      "Epoch 18/50\n",
      "140/140 [==============================] - 31s 218ms/step - loss: 7.2191e-12 - acc: 1.0000\n",
      "Epoch 19/50\n",
      "140/140 [==============================] - 30s 214ms/step - loss: 1.6941e-12 - acc: 1.0000\n",
      "Epoch 20/50\n",
      "140/140 [==============================] - 30s 212ms/step - loss: 3.5056e-12 - acc: 1.0000\n",
      "Epoch 21/50\n",
      "140/140 [==============================] - 29s 204ms/step - loss: 3.5871e-12 - acc: 1.0000\n",
      "Epoch 22/50\n",
      "140/140 [==============================] - 29s 209ms/step - loss: 3.3797e-12 - acc: 1.0000\n",
      "Epoch 23/50\n",
      "140/140 [==============================] - 29s 204ms/step - loss: 4.0349e-12 - acc: 1.0000\n",
      "Epoch 24/50\n",
      "140/140 [==============================] - 30s 215ms/step - loss: 2.4611e-11 - acc: 1.0000\n",
      "Epoch 25/50\n",
      "140/140 [==============================] - 29s 206ms/step - loss: 4.1164e-12 - acc: 1.0000\n",
      "Epoch 26/50\n",
      "140/140 [==============================] - 30s 214ms/step - loss: 7.9876e-12 - acc: 1.0000\n",
      "Epoch 27/50\n",
      "140/140 [==============================] - 30s 213ms/step - loss: 4.3206e-11 - acc: 1.0000\n",
      "Epoch 28/50\n",
      "140/140 [==============================] - 29s 209ms/step - loss: 1.8419e-11 - acc: 1.0000\n",
      "Epoch 29/50\n",
      "140/140 [==============================] - 29s 209ms/step - loss: 2.2170e-11 - acc: 1.0000\n",
      "Epoch 30/50\n",
      "140/140 [==============================] - 30s 217ms/step - loss: 3.9527e-12 - acc: 1.0000\n",
      "Epoch 31/50\n",
      "140/140 [==============================] - 29s 209ms/step - loss: 6.4222e-12 - acc: 1.0000\n",
      "Epoch 32/50\n",
      "140/140 [==============================] - 29s 206ms/step - loss: 4.7205e-12 - acc: 1.0000\n",
      "Epoch 33/50\n",
      "140/140 [==============================] - 29s 204ms/step - loss: 1.5412e-11 - acc: 1.0000\n",
      "Epoch 34/50\n",
      "140/140 [==============================] - 28s 204ms/step - loss: 4.6127e-12 - acc: 1.0000\n",
      "Epoch 35/50\n",
      "140/140 [==============================] - 30s 212ms/step - loss: 3.7815e-12 - acc: 1.0000\n",
      "Epoch 36/50\n",
      "140/140 [==============================] - 30s 215ms/step - loss: 3.5198e-12 - acc: 1.0000\n",
      "Epoch 37/50\n",
      "140/140 [==============================] - 30s 215ms/step - loss: 3.1326e-12 - acc: 1.0000\n",
      "Epoch 38/50\n",
      "140/140 [==============================] - 29s 208ms/step - loss: 1.6294e-11 - acc: 1.0000\n",
      "Epoch 39/50\n",
      "140/140 [==============================] - 29s 207ms/step - loss: 4.0332e-12 - acc: 1.0000\n",
      "Epoch 40/50\n",
      "140/140 [==============================] - 29s 207ms/step - loss: 8.4372e-12 - acc: 1.0000\n",
      "Epoch 41/50\n",
      "140/140 [==============================] - 30s 214ms/step - loss: 2.2865e-11 - acc: 1.0000\n",
      "Epoch 42/50\n",
      "140/140 [==============================] - 29s 210ms/step - loss: 3.3464e-12 - acc: 1.0000\n",
      "Epoch 43/50\n",
      "140/140 [==============================] - 29s 210ms/step - loss: 4.0409e-12 - acc: 1.0000\n",
      "Epoch 44/50\n",
      "140/140 [==============================] - 29s 209ms/step - loss: 3.2959e-12 - acc: 1.0000\n",
      "Epoch 45/50\n",
      "140/140 [==============================] - 30s 211ms/step - loss: 5.5276e-12 - acc: 1.0000\n",
      "Epoch 46/50\n",
      "140/140 [==============================] - 30s 212ms/step - loss: 6.6572e-12 - acc: 1.0000\n",
      "Epoch 47/50\n",
      "140/140 [==============================] - 29s 210ms/step - loss: 1.4582e-11 - acc: 1.0000\n",
      "Epoch 48/50\n",
      "140/140 [==============================] - 29s 205ms/step - loss: 2.5929e-12 - acc: 1.0000\n",
      "Epoch 49/50\n",
      "140/140 [==============================] - 30s 216ms/step - loss: 3.8242e-12 - acc: 1.0000\n",
      "Epoch 50/50\n",
      "140/140 [==============================] - 30s 213ms/step - loss: 6.4052e-12 - acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "accuracy = [['Number of epochs','Train Accuracy', 'Test Accuracy']]\n",
    "for i in range(10,51):\n",
    "    model3.fit(padding, train['sentiment'], epochs=i, batch_size=10)\n",
    "    train_loss, train_accuracy = model3.evaluate(padding, train['sentiment'], verbose=0)\n",
    "    test_loss, test_accuracy = model3.evaluate(padding_test, test['sentiment'], verbose=0)\n",
    "    accuracy.append([i,train_accuracy,test_accuracy])\n",
    "    \n",
    "accuracydf = pd.DataFrame(accuracy[1:], columns = accuracy[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of epochs</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.786667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.781667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.773333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.773333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.790000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.786667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.723333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.723333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.731667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.735000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.728333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.731667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.748333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.711667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.731667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.726667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.728333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.731667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>31</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.698333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.693333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.721667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>34</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.726667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.718333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.711667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>37</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.721667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>38</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.713333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.715000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.718333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.721667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.721667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>43</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.726667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.728333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>45</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.728333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>46</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>47</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.723333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.715000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Number of epochs  Train Accuracy  Test Accuracy\n",
       "0                 10             1.0       0.786667\n",
       "1                 11             1.0       0.781667\n",
       "2                 12             1.0       0.773333\n",
       "3                 13             1.0       0.773333\n",
       "4                 14             1.0       0.790000\n",
       "5                 15             1.0       0.786667\n",
       "6                 16             1.0       0.723333\n",
       "7                 17             1.0       0.723333\n",
       "8                 18             1.0       0.731667\n",
       "9                 19             1.0       0.735000\n",
       "10                20             1.0       0.725000\n",
       "11                21             1.0       0.728333\n",
       "12                22             1.0       0.731667\n",
       "13                23             1.0       0.748333\n",
       "14                24             1.0       0.711667\n",
       "15                25             1.0       0.731667\n",
       "16                26             1.0       0.726667\n",
       "17                27             1.0       0.728333\n",
       "18                28             1.0       0.730000\n",
       "19                29             1.0       0.725000\n",
       "20                30             1.0       0.731667\n",
       "21                31             1.0       0.698333\n",
       "22                32             1.0       0.693333\n",
       "23                33             1.0       0.721667\n",
       "24                34             1.0       0.726667\n",
       "25                35             1.0       0.718333\n",
       "26                36             1.0       0.711667\n",
       "27                37             1.0       0.721667\n",
       "28                38             1.0       0.713333\n",
       "29                39             1.0       0.715000\n",
       "30                40             1.0       0.718333\n",
       "31                41             1.0       0.721667\n",
       "32                42             1.0       0.721667\n",
       "33                43             1.0       0.726667\n",
       "34                44             1.0       0.728333\n",
       "35                45             1.0       0.728333\n",
       "36                46             1.0       0.730000\n",
       "37                47             1.0       0.723333\n",
       "38                48             1.0       0.720000\n",
       "39                49             1.0       0.730000\n",
       "40                50             1.0       0.715000"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracydf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> We get train accuracy as 1.0 for all the epochs and test accuracy is best for 14 epochs at 0.79. Hence we train the model again at 14 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/14\n",
      "140/140 [==============================] - 41s 293ms/step - loss: 3.1209e-12 - acc: 1.0000\n",
      "Epoch 2/14\n",
      "140/140 [==============================] - 41s 296ms/step - loss: 2.6095e-12 - acc: 1.0000\n",
      "Epoch 3/14\n",
      "140/140 [==============================] - 41s 291ms/step - loss: 8.8172e-12 - acc: 1.0000\n",
      "Epoch 4/14\n",
      "140/140 [==============================] - 41s 294ms/step - loss: 1.4209e-11 - acc: 1.0000\n",
      "Epoch 5/14\n",
      "140/140 [==============================] - 40s 289ms/step - loss: 4.7626e-12 - acc: 1.0000\n",
      "Epoch 6/14\n",
      "140/140 [==============================] - 41s 291ms/step - loss: 1.6962e-12 - acc: 1.0000\n",
      "Epoch 7/14\n",
      "140/140 [==============================] - 42s 301ms/step - loss: 6.4070e-12 - acc: 1.0000\n",
      "Epoch 8/14\n",
      "140/140 [==============================] - 41s 296ms/step - loss: 7.6333e-12 - acc: 1.0000\n",
      "Epoch 9/14\n",
      "140/140 [==============================] - 40s 285ms/step - loss: 1.6799e-11 - acc: 1.0000\n",
      "Epoch 10/14\n",
      "140/140 [==============================] - 38s 274ms/step - loss: 2.0095e-12 - acc: 1.0000\n",
      "Epoch 11/14\n",
      "140/140 [==============================] - 40s 286ms/step - loss: 1.1809e-11 - acc: 1.0000\n",
      "Epoch 12/14\n",
      "140/140 [==============================] - 40s 284ms/step - loss: 4.9280e-12 - acc: 1.0000\n",
      "Epoch 13/14\n",
      "140/140 [==============================] - 39s 282ms/step - loss: 4.4488e-12 - acc: 1.0000\n",
      "Epoch 14/14\n",
      "140/140 [==============================] - 40s 289ms/step - loss: 7.6518e-12 - acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model3.fit(padding, train['sentiment'], epochs=14, batch_size=10)\n",
    "train_loss, train_accuracy = model3.evaluate(padding, train['sentiment'], verbose=0)\n",
    "test_loss, test_accuracy = model3.evaluate(padding_test, test['sentiment'], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 100.000000\n",
      "Test Accuracy: 71.666664\n"
     ]
    }
   ],
   "source": [
    "print('Train Accuracy: %f' % (train_accuracy*100))\n",
    "print('Test Accuracy: %f' % (test_accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "<br>\n",
    "https://keras.rstudio.com/reference/text_tokenizer.html<br>\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit<br>\n",
    "https://faroit.com/keras-docs/1.0.1/getting-started/sequential-model-guide/<br>\n",
    "https://stackabuse.com/python-for-nlp-word-embeddings-for-deep-learning-in-keras/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
